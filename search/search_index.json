{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"STACK | Online assessment STACK is the world-leading open-source online assessment system for mathematics and STEM. It is available for Moodle, ILIAS and as an integration through LTI. Why use STACK? Algebraic answers Students can answer algebraic expressions, like \\(x^2+y\\), and answers are graded based on mathematical properties. Separate validation and assessment Answers are validated before they are marked, so students are not penalised for poor programming skills. Specific feedback Students are given feedback that refers to their specific answer and mistake, as if marked by hand. Randomisation STACK can generate random questions so students are shown different variants of questions, and can repeat quizzes with new variants. Language support STACK is available in most European languages and many more, including Hebrew and Japanese. Open-source STACK is free to use and is developed by educators like yourself. Contributions are welcomed and encouraged. Learn more Get Started Who uses STACK? STACK is used by universities, commercial partners, developers and more, in over 15 countries. To read about the many ways STACK is used around the world, please visit our Case Studies page. Case Studies Training and Events We host regular training workshops and a yearly international STACK conference. To sign up for one of our future events, or see materials from our past events, go to our Training and Events page. Training and Events Documentation STACK has extensive documentation available locally through GitHub and online. To get started, see the Authoring quick start or the self-contained \"Getting started with STACK\" guide . Documentation","title":"Home"},{"location":"About/","text":"About STACK STACK is an online assessment system for mathematics and STEM, designed to enable students to answer questions with a mathematical expression, such as a polynomial. STACK helps students learn from their mistakes through specific feedback. Computer Algebra Support STACK uses the Computer Algebra System Maxima to evaluate expressions. Mathematical answers: questions are not limited to multiple choice. Randomise questions: so different students see different variants of a quiz. Graphical support: make your questions stand out by integrating Maxima plots, JSXGraphs or Google Charts. Validation of answers Before answers are graded, students confirm their answer is interpreted correctly by the system. Invalid answers, like ones with mismatched brackets, are rejected. Fair: students are not penalised for poor computer skills. Flexible: the teacher decides what a valid answer looks like. Intelligent marking Teachers write grading trees that mark answers based on mathematical properties, like \"is it factored?\" Specific feedback tailored to each student's answer. Multipart questions with follow-through marking. Give-example style questions with many correct answers. Diverse question types involving scientific units, numerical accuracy, line-by-line reasoning and more. Open-source As an open-source project, users help improve STACK by adding features, translations, bug reports and more. Many users share STACK materials, for example through the ABACUS material bank. Credits and contributions ABACUS material bank Commercial hosting We appreciate some people prefer hosted services as an alternative to running their own server. We are pleased to work with EDINA at the University of Edinburgh as a recommended hosting partner. Hosted STACK Trusted user base STACK is trusted by many respected institutions. More users","title":"About"},{"location":"About/#about-stack","text":"STACK is an online assessment system for mathematics and STEM, designed to enable students to answer questions with a mathematical expression, such as a polynomial. STACK helps students learn from their mistakes through specific feedback.","title":"About STACK"},{"location":"About/#validation-of-answers","text":"Before answers are graded, students confirm their answer is interpreted correctly by the system. Invalid answers, like ones with mismatched brackets, are rejected. Fair: students are not penalised for poor computer skills. Flexible: the teacher decides what a valid answer looks like.","title":"Validation of answers"},{"location":"About/#intelligent-marking","text":"Teachers write grading trees that mark answers based on mathematical properties, like \"is it factored?\" Specific feedback tailored to each student's answer. Multipart questions with follow-through marking. Give-example style questions with many correct answers. Diverse question types involving scientific units, numerical accuracy, line-by-line reasoning and more.","title":"Intelligent marking"},{"location":"About/#open-source","text":"As an open-source project, users help improve STACK by adding features, translations, bug reports and more. Many users share STACK materials, for example through the ABACUS material bank. Credits and contributions ABACUS material bank","title":"Open-source"},{"location":"About/#commercial-hosting","text":"We appreciate some people prefer hosted services as an alternative to running their own server. We are pleased to work with EDINA at the University of Edinburgh as a recommended hosting partner. Hosted STACK","title":"Commercial hosting"},{"location":"About/#trusted-user-base","text":"STACK is trusted by many respected institutions. More users","title":"Trusted user base"},{"location":"Community/","text":"Community Development team Continuously developed and used since 2004. Chris Sangwin The University of Edinburgh, UK C.J.Sangwin@ed.ac.uk Chairperson of the International Advisory Board Tim Hunt The Open University, UK Matti Harjula Aalto, Finland Jes\u00fas Copado Friedrich-Alexander-Universit\u00e4t jesus.copado@fau.de ILIAS developer Saif Salaudeen The University of Edinburgh msalaude@ed.ac.uk STACK Engineer STACK International Advisory Board The International Advisory Board encourages engagement from the community of users of the STACK online assessment system and helps to oversee strategic developments of the system. The Advisory Board promotes the long-term stainability of the software and invites contributions from diverse stakeholders. Meike Akveld ETH Z\u00fcrich akveld@math.ethz.ch Ian Jones Department of Mathematics Education, Loughborough University I.Jones@lboro.ac.uk David Stern IDEMS International d.a.stern@idems.international Michael Obiero Oyengo Masseno University, Kenya obiero@maseno.ac.ke Oksana Labanova TTK University of Applied Sciences oksana.labanova@tktk.ee Chairperson of the 2023 conference Antti Rasila Guangdong Technion-Israel Institute of Technology antti.rasila@gtiit.edu.cn Founder of the Abacus Consortium Tim.Lowe The Open University, UK tim.lowe@open.ac.uk Michael Weinmann Ostbayerische Technische Hochschule (OTH) Amberg-Weiden m.weinmann@oth-aw.de Chairperson of the 2024 conference Katja Dechant-Herrera Ostbayerische Technische Hochschule (OTH) Amberg-Weiden k.dechant@oth-aw.de STACK Professionals Network Konstantina Zerva The University of Edinburgh, UK k.zerva@ed.ac.uk George-Ionut Ionita ETH Z\u00fcrich georgeionut.ionita@math.ethz.ch Andreas Steiger ETH Z\u00fcrich andreas.steiger@math.ethz.ch Maciej Matuszewski Durham University, UK m.t.matuszewski@durham.ac.uk Sam Fearn Durham University, UK s.m.fearn@durham.ac.uk Santiago Borio IDEMS International, UK smborio@idems.international Georg Osang IDEMS International, UK gosang@idems.international Kinga Sipos Bern University, Switzerland kinga.sipos@unibe.ch Luke Longworth University of Canterbury, New Zealand luke.longworth@canterbury.ac.nz Speedy Jiang University of Canterbury, New Zealand speedy.jiang@canterbury.ac.nz Ruth Reynolds University College London, UK ruth.reynolds@ucl.ac.uk","title":"Community"},{"location":"Community/#community","text":"","title":"Community"},{"location":"Community/#development-team","text":"Continuously developed and used since 2004.","title":"Development team"},{"location":"Community/#stack-international-advisory-board","text":"The International Advisory Board encourages engagement from the community of users of the STACK online assessment system and helps to oversee strategic developments of the system. The Advisory Board promotes the long-term stainability of the software and invites contributions from diverse stakeholders.","title":"STACK International Advisory Board"},{"location":"Community/#stack-professionals-network","text":"","title":"STACK Professionals Network"},{"location":"Conference/","text":"Annual International STACK Conference The International Meeting of the STACK Community 2023 will take place on 24 - 26 of April 2023 in Tallinn, Estonia. The annual International Meeting of the STACK Community is a forum for all STACK users to exchange experiences, ideas and research topics. Conference website: stack2023.com . Previous conferences Title Date Location Description International Meeting of the STACK Community 2022 24-28 April 2022 Leoben, Austria unileoben.ac.at/stack22 A forum for all STACK users to exchange experiences, ideas and research topics The 4th International STACK Conference 26-29 April 2021 TTK University of Applied Sciences, Tallinn, Estonia stack21.edu.ee Proceedings This conference aims to act as a forum for the exchange of experience, ideas and research associated with implementing STACK. The target group is academics who teach undergraduate and postgraduate STEM courses in higher education institutions. The 3rd International STACK Conference 27 April 2020 Online. 3rd International STACK Conference Website The aim of the conference is to provide a platform for academics, researchers, and scholars, to address common challenges, share knowledge and ideas as well as recent trends and brainstorm creative solutions in the field of STACK. The 2nd International STACK Conference 30 April 2019 The University of Edinburgh, Edinburgh, UK This conference was day two of a wider meeting. The 1st International STACK Conference 15-16 November 2018 Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, F\u00fcrth, Germany www.stack-konferenz.de The mission of the Conference is to offer a forum for the STACK Community, to exchange ideas about possibilities and challenges in creating questions, to get closer to solving technical questions and to shape the future of STACK.","title":"Annual conference"},{"location":"Conference/#annual-international-stack-conference","text":"The International Meeting of the STACK Community 2023 will take place on 24 - 26 of April 2023 in Tallinn, Estonia. The annual International Meeting of the STACK Community is a forum for all STACK users to exchange experiences, ideas and research topics. Conference website: stack2023.com .","title":"Annual International STACK Conference"},{"location":"Conference/#previous-conferences","text":"Title Date Location Description International Meeting of the STACK Community 2022 24-28 April 2022 Leoben, Austria unileoben.ac.at/stack22 A forum for all STACK users to exchange experiences, ideas and research topics The 4th International STACK Conference 26-29 April 2021 TTK University of Applied Sciences, Tallinn, Estonia stack21.edu.ee Proceedings This conference aims to act as a forum for the exchange of experience, ideas and research associated with implementing STACK. The target group is academics who teach undergraduate and postgraduate STEM courses in higher education institutions. The 3rd International STACK Conference 27 April 2020 Online. 3rd International STACK Conference Website The aim of the conference is to provide a platform for academics, researchers, and scholars, to address common challenges, share knowledge and ideas as well as recent trends and brainstorm creative solutions in the field of STACK. The 2nd International STACK Conference 30 April 2019 The University of Edinburgh, Edinburgh, UK This conference was day two of a wider meeting. The 1st International STACK Conference 15-16 November 2018 Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, F\u00fcrth, Germany www.stack-konferenz.de The mission of the Conference is to offer a forum for the STACK Community, to exchange ideas about possibilities and challenges in creating questions, to get closer to solving technical questions and to shape the future of STACK.","title":"Previous conferences"},{"location":"GetStarted/","text":"I am a... Teacher Explore STACKs features by visiting our Demo site. If you have STACK installed and want to write your first question, see our question authoring quick start guide. Demo site \u2003 Quick start guide Student Read the information for students on our documentation, including accessibility and FAQ, or get used to STACK syntax with our syntax quiz. Info for students \u2003 Syntax quiz Site administrator STACK can be used via a hosted partner, installed within Moodle or ILIAS, or integrated into other Learning Management Systems via LTI. Hosted STACK \u2003 Install STACK \u2003 Integrate via LTI Developer STACK is open-source and welcomes contributions: added features, integrations, translations, bug reports and more. Contribute to STACK","title":"Get Started"},{"location":"Training_and_events/","text":"Training and Events We regularly host conferences and training workshops for STACK. You can find videos from previous events on our YouTube channel. STACK videos Upcoming events Here is a list of upcoming events: Title Date Location Description Using STACK in more advanced courses April 2023 (dates TBC) Hybrid event: The University of Edinburgh, James Clerk Maxwell building and online International Meeting of the STACK Community 2023 24 - 26 April 2023 Tallinn, Estonia stack2023.com A forum for all STACK users to exchange experiences, ideas and research topics The 1st Northern e-Assessment Meeting 31 May - 2 June 2023 Trondheim, Norway uia.no An informal conference for people interested in e-Assessment in Mathematical Sciences at higher education level African STACK Conference for Undergraduate Mathematics 19 - 23 June 2023 Masinde Muliro University of Science and Technology, Kakamega, Kenya A conference to enable African educators with experience on STACK to define a roadmap for transformation of African Undergraduate Maths Education International Meeting of the STACK Community 2024 April 2024 Ostbayerische Technische Hochschule (OTH), Amberg-Weiden, Germany A forum for all STACK users to exchange experiences, ideas and research topics. Workshops in 2020 During 2020 we ran a series of online workshops, with support from the LMS, Universitas 21, and the School of Mathematics at the University of Edinburgh. You can access recordings and materials from these workshops through the links below: Title Date Location Description Workshop: Effective use of Maxima 2 Dec 2020 15:00-17:00 GMT Online. Course page - effective use of Maxima Learn how mathematics educators use Maxima effectively with STACK, and how to use more advanced Maxima techniques to improve your own STACK questions. Workshop: Addressing common student errors 25 Nov 2020 15:00-17:00 GMT Online. Course page - student errors 25-11-20 Gain insight into common student errors based on mathematics education research, and get practical experience of using STACK to detect and give feedback on errors. Workshop: Assessment of proofs in STACK 7 September 2020 15:00-16:30 BST Online. Course page - assessment of proofs Learn about important practical findings from educational research on how to teach mathematical proof effectively, and hear about practical approaches to assessing proof online using tools like STACK. Workshop: Getting started with STACK 20 July 2020 10:00-12:00 BST Online. Course page - getting started 20-07-20 Learn about the features of STACK and write your first STACK question with experts on hand to help. Workshop: addressing common student errors \u2003 3 July 2020 14:00-16:00 BST\u2003 Online. Course page - student errors \u2003 Gain insight into common student errors based on mathematics education research, and get practical experience of using STACK to detect and give feedback on errors. Workshop: quality questions and assessing proof 19 June 2020 10:00-12:00 BST Online. Course page - quality questions Learn about advanced features of STACK that help to make sure your questions work reliably, and get tips from experienced authors on how to write polished questions. In the second half, learn about ways to assess proof using STACK. Workshop: getting started with STACK 15 June 2020 10:00-15:00 BST Online. Course page - getting started Hear from some experienced users about how they use STACK in variety of courses, then write your first STACK question with experts on hand to help. Past events A list of past STACK workshops and conferences: Title Date Location Description Using JSX graphs in STACK 8 Dec 2022 Hybrid event: The University of Edinburgh, James Clerk Maxwell building and online This workshop will provide hands-on practise on how to create JSXGraphs and how to use JSXGraph in STACK assessments. Using STACK to put the \"book inside the quiz\" 16 Nov 2022 Hybrid event: The University of Edinburgh, James Clerk Maxwell building and online This workshop discusses how we have used a metaphore of \"putting the book inside automatically assessed online quizzes\" in a variety of university mathematics courses. Mathematics STACK Workshop 4th-8th Jul 2022 Maseno University, Kenya The goal of this workshop is to help lecturers prepare the courses they will be teaching at their institutions using STACK. There will be a parallel session on authoring STACK questions. EAMS 2022 13 - 24 Jun 2022 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. International Meeting of the STACK Community 2022 24-28 Apr 2022 Leoben, Austria unileoben.ac.at/stack22 A forum for all STACK users to exchange experiences, ideas and research topics EAMS 2021 21 Jun - 2 July 2021 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. The 4th International STACK Conference 26-29 Apr 2021 TTK University of Applied Sciences, Tallinn, Estonia stack21.edu.ee Proceedings This conference aims to act as a forum for the exchange of experience, ideas and research associated with implementing STACK. The target group is academics who teach undergraduate and postgraduate STEM courses in higher education institutions. EAMS 2020 Week of 22 Jun 2020 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. The 3rd International STACK Conference 27 Apr 2020 Online. 3rd International STACK Conference Website The aim of the conference is to provide a platform for academics, researchers, and scholars, to address common challenges, share knowledge and ideas as well as recent trends and brainstorm creative solutions in the field of STACK. Putting educational research into practice in HE Mathematics and Statistics teaching 29-30 April 2019 The University of Edinburgh, Edinburgh, UK Putting research into practice conference website Day 1: Putting educational research into practice in HE Mathematics and Statistics teaching. Day 2: The 2nd International STACK Conference. The 1st International STACK Conference 15-16 Nov 2018 Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, F\u00fcrth, Germany www.stack-konferenz.de The mission of the Conference is to offer a forum for the STACK Community, to exchange ideas about possibilities and challenges in creating questions, to get closer to solving technical questions and to shape the future of STACK.","title":"Overview"},{"location":"Training_and_events/#training-and-events","text":"We regularly host conferences and training workshops for STACK. You can find videos from previous events on our YouTube channel. STACK videos","title":"Training and Events"},{"location":"Training_and_events/#upcoming-events","text":"Here is a list of upcoming events: Title Date Location Description Using STACK in more advanced courses April 2023 (dates TBC) Hybrid event: The University of Edinburgh, James Clerk Maxwell building and online International Meeting of the STACK Community 2023 24 - 26 April 2023 Tallinn, Estonia stack2023.com A forum for all STACK users to exchange experiences, ideas and research topics The 1st Northern e-Assessment Meeting 31 May - 2 June 2023 Trondheim, Norway uia.no An informal conference for people interested in e-Assessment in Mathematical Sciences at higher education level African STACK Conference for Undergraduate Mathematics 19 - 23 June 2023 Masinde Muliro University of Science and Technology, Kakamega, Kenya A conference to enable African educators with experience on STACK to define a roadmap for transformation of African Undergraduate Maths Education International Meeting of the STACK Community 2024 April 2024 Ostbayerische Technische Hochschule (OTH), Amberg-Weiden, Germany A forum for all STACK users to exchange experiences, ideas and research topics.","title":"Upcoming events"},{"location":"Training_and_events/#workshops-in-2020","text":"During 2020 we ran a series of online workshops, with support from the LMS, Universitas 21, and the School of Mathematics at the University of Edinburgh. You can access recordings and materials from these workshops through the links below: Title Date Location Description Workshop: Effective use of Maxima 2 Dec 2020 15:00-17:00 GMT Online. Course page - effective use of Maxima Learn how mathematics educators use Maxima effectively with STACK, and how to use more advanced Maxima techniques to improve your own STACK questions. Workshop: Addressing common student errors 25 Nov 2020 15:00-17:00 GMT Online. Course page - student errors 25-11-20 Gain insight into common student errors based on mathematics education research, and get practical experience of using STACK to detect and give feedback on errors. Workshop: Assessment of proofs in STACK 7 September 2020 15:00-16:30 BST Online. Course page - assessment of proofs Learn about important practical findings from educational research on how to teach mathematical proof effectively, and hear about practical approaches to assessing proof online using tools like STACK. Workshop: Getting started with STACK 20 July 2020 10:00-12:00 BST Online. Course page - getting started 20-07-20 Learn about the features of STACK and write your first STACK question with experts on hand to help. Workshop: addressing common student errors \u2003 3 July 2020 14:00-16:00 BST\u2003 Online. Course page - student errors \u2003 Gain insight into common student errors based on mathematics education research, and get practical experience of using STACK to detect and give feedback on errors. Workshop: quality questions and assessing proof 19 June 2020 10:00-12:00 BST Online. Course page - quality questions Learn about advanced features of STACK that help to make sure your questions work reliably, and get tips from experienced authors on how to write polished questions. In the second half, learn about ways to assess proof using STACK. Workshop: getting started with STACK 15 June 2020 10:00-15:00 BST Online. Course page - getting started Hear from some experienced users about how they use STACK in variety of courses, then write your first STACK question with experts on hand to help.","title":"Workshops in 2020"},{"location":"Training_and_events/#past-events","text":"A list of past STACK workshops and conferences: Title Date Location Description Using JSX graphs in STACK 8 Dec 2022 Hybrid event: The University of Edinburgh, James Clerk Maxwell building and online This workshop will provide hands-on practise on how to create JSXGraphs and how to use JSXGraph in STACK assessments. Using STACK to put the \"book inside the quiz\" 16 Nov 2022 Hybrid event: The University of Edinburgh, James Clerk Maxwell building and online This workshop discusses how we have used a metaphore of \"putting the book inside automatically assessed online quizzes\" in a variety of university mathematics courses. Mathematics STACK Workshop 4th-8th Jul 2022 Maseno University, Kenya The goal of this workshop is to help lecturers prepare the courses they will be teaching at their institutions using STACK. There will be a parallel session on authoring STACK questions. EAMS 2022 13 - 24 Jun 2022 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. International Meeting of the STACK Community 2022 24-28 Apr 2022 Leoben, Austria unileoben.ac.at/stack22 A forum for all STACK users to exchange experiences, ideas and research topics EAMS 2021 21 Jun - 2 July 2021 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. The 4th International STACK Conference 26-29 Apr 2021 TTK University of Applied Sciences, Tallinn, Estonia stack21.edu.ee Proceedings This conference aims to act as a forum for the exchange of experience, ideas and research associated with implementing STACK. The target group is academics who teach undergraduate and postgraduate STEM courses in higher education institutions. EAMS 2020 Week of 22 Jun 2020 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. The 3rd International STACK Conference 27 Apr 2020 Online. 3rd International STACK Conference Website The aim of the conference is to provide a platform for academics, researchers, and scholars, to address common challenges, share knowledge and ideas as well as recent trends and brainstorm creative solutions in the field of STACK. Putting educational research into practice in HE Mathematics and Statistics teaching 29-30 April 2019 The University of Edinburgh, Edinburgh, UK Putting research into practice conference website Day 1: Putting educational research into practice in HE Mathematics and Statistics teaching. Day 2: The 2nd International STACK Conference. The 1st International STACK Conference 15-16 Nov 2018 Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, F\u00fcrth, Germany www.stack-konferenz.de The mission of the Conference is to offer a forum for the STACK Community, to exchange ideas about possibilities and challenges in creating questions, to get closer to solving technical questions and to shape the future of STACK.","title":"Past events"},{"location":"CaseStudies/","text":"Who uses STACK? STACK has users all over the world. To highlight some of the ways STACK is used and developed around the world, we have written a number of case studies. Explore the map, or see the full list of case studies below. stars Case studies place Other key users 2022 Question Answering in STACK Applying String Similarity Using the Damerau-Levenshtein distance between strings to develop assessment of short free-text answers. 2021 Using STACK in Real Analysis Using STACK in Real Analysis at the University of Warwick. Translating the HELM workbooks to STACK Converting the \"Helping Engineers Learn Mathematics\" workbooks into STACK quizzes for self-study. 2020 Diagnostics Testing With STACK The MINTFIT Math Test is an online diagnostics test that uses STACK. Extra-occupational bridging courses for non-traditional students OTH Amberg-Weiden uses STACK in extra-occupational maths bridging courses for non-traditional students. 2019 In 2019, a project was carried out to write an initial collection of STACK case studies. The case studies were edited by Malthe Sporring and Chris Sangwin, and funded by CATE. Case Studies Booklet Developing a Fully Online Course \"Fundamentals of Algebra and Calculus\" is a fully online course that uses STACK. STACK for a Physics Textbook Physics Curriculum & Instruction have developed STACK questions to accompany a Physics textbook. Adaptive Self-learning Exercises The Ruhr-Universit\u00e4t Bochum uses STACK in online courses designed for self-study. Some questions are adaptive, and guide students through complex tasks. A Flick Interface for Maths Input Developers at Nagoya University are building a \"flick interface\" for STACK, similar to the popular Japanese keyboard mode. Innovating Education in Maseno, Kenya IDEMS international is working with Maseno University to implement online assessment for their mathematics courses. optes: Optimising Self-study With STACK The optes project uses STACK in their pre-course, designed to help students improve their self-studying skills. Technical Integration of STACK Into ILIAS STACK was integrated into the ILIAS learning management system to support projects for learning content. STACK at Scale: The Open University The Open University uses STACK for large-scale online courses. STACK for Engineering Mathematics and the Abacus Material Bank Aalto University uses STACK for their Engineering Mathematics courses, and they have also developed the material bank Abacus. Promoting STACK Across Disciplines at Loughborough University At Loughborough University, STACK has been implemented across many disciplines. Institutional Support for STACK in Edinburgh The University of Edinburgh has in-house support for online assessment, mostly with STACK, for most year one and two mathematics modules, and many more.","title":"Overview"},{"location":"CaseStudies/#who-uses-stack","text":"STACK has users all over the world. To highlight some of the ways STACK is used and developed around the world, we have written a number of case studies. Explore the map, or see the full list of case studies below. stars Case studies place Other key users","title":"Who uses STACK?"},{"location":"CaseStudies/#2022","text":"","title":"2022"},{"location":"CaseStudies/#2021","text":"","title":"2021"},{"location":"CaseStudies/#2020","text":"","title":"2020"},{"location":"CaseStudies/#2019","text":"In 2019, a project was carried out to write an initial collection of STACK case studies. The case studies were edited by Malthe Sporring and Chris Sangwin, and funded by CATE. Case Studies Booklet","title":"2019"},{"location":"CaseStudies/2019/ABACUS/","text":"STACK for Engineering Mathematics and the Abacus Material Bank Aalto University Antti Rasila, Guangdong Technion - Israel Institute of Technology Abstract Since 2006, Aalto University has been using STACK to run online assessments within their Engineering Mathematics courses. Initially, the University was running a STACK version developed in-house specifically for the University, but this was later merged back into the main STACK branch in version 3.0. After receiving funding, the material bank Abacus was created, with the purpose of helping institutions collaborate and share STACK questions. The project's agreement was written in a way that ensured question authors kept their copyright, while still encouraging collaboration. Abacus has 30 members and its courses cover most of undergraduate mathematics and many parts of physics. Motivation The MatTa group (\"Matematiikkaa tietokoneavusteisesti\"; \"mathematics by using computers\") was founded in 1990s by lecturer Emeritus Simo K. Kivel\u00e4 at the Department of Mathematics and Systems Analysis at Aalto University, formerly known as Helsinki University of Technology. The purpose of the group was to investigate the use of computers and information technology to teach engineering mathematics. Initially, the projects involved, for example, using visualisations, multimedia and symbolic computation to make mathematical content more interesting and accessible for students. The group also produced a number of free Finnish language electronic lecture notes with interactive content and a substantial database of traditional pen and paper exercise assignments called Euler. In 2006, the group started to take interest in automatic assessment, as they believed computer-aided methodologies could achieve a practical impact in teaching activities there. There was also hope at the University that Computer Aided Assessment could reduce the number of students assistants required to grade homework, both to save cost and because a sufficient number of qualified graders was not always available. Initially, the group focused on the Maple T.A. system, however it was found lacking in several aspects. The most important of these were performance issues and an incompatibility with various browsers, in particular ones available for the Linux operating system. The high licensing fees were also a problem, as they could undo all the savings that the University hoped to achieve by using the system. In spring of 2006, the group started gaining interest in STACK, which has an open source license. This license would allow the University to use its in-house software development skills to improve the platform where needed, and it would also guarantee that licence fees would not be imposed in the future. After deciding to use STACK, which was running its standalone version 1.x at the time, the group spent the summer of 2006 modifying the software to better suit the University's needs. This included replacing the rendering code of mathematical formulas to support browsers other than Microsoft Internet Explorer, translating the software to Finnish and a Shibboleth based integration with the Finnish national Haka single-sign-in system. Implementing STACK Figure: An interactive STACK question from Aalto University's \"Multivariable Calculus\" course, where students drag points along a contour line. After modifying the system, the University started testing STACK. The initial test was with the university's Basic Course in Engineering Mathematics KP3. A. Rasila wrote four STACK assignments for each week of the course, all of which were relatively simple questions involving numerical or algebraic input. The system had numerous small technical issues, but the students were generally happy with the system as evidenced both by student feedback and general usage statistics [1]. Encouraged by the positive results, it was decided to test the system more comprehensively to convince the teaching community that automatic assessment was worth of the effort in teaching engineering mathematics. It was important to show that the online assessment could be used by teachers with little programming skill, and that it would not cause a large increase in their workload. This was crucial for the long-term success of the project, as MatTa's previously developed materials were often only used by a handful of teachers, most of whom where developers themselves. Furthermore, the group needed to demonstrate that the system had real cost savings, as well as good learning outcomes compared to traditional types of assignments. The University set up an experimental course \"Discrete Mathematics\", where STACK would form a significant portion of the final grade [2]. Following the positive results of this course, the use of STACK began to spread at the University, and within three years, most basic courses in Engineering Mathematics at Aalto University were using STACK. STACK Developments A key ingredient in the success of STACK at Aalto University were the in-house developments by programmer Matti Harjula, also wrote his Master\u2019s Thesis on this work [3]. His initial work included analysing the data of the first 2006 experiment and further developing the system to address any shortcomings. His project was successful, as it led to a system that many lecturers at the department were willing to use, and no major issues were identified in the subsequent use of the system. However, it also led to a new problem. Independently from Aalto University, the British STACK developers had been developing STACK 2.0, which was very different from the 1.x series Aalto University had been using for their work. The in-house developments by Aalto University were not easily implemented into STACK 2.0, but merging the Aalto University code back into the trunk of STACK was still necessary for a number of reasons. Firstly, a unified code base would speed up the overall development of STACK, and the Department at Aalto University did not intend to permanently commit many resources to maintaining the system. Secondly, there was interest from other Finnish universities to try the system, however they preferred to use the \u201cofficial\u201d British version of STACK, which would prevent them from using the materials developed at Aalto University. Because of this, the Finnish and British developers agreed to join forces in combining their work into STACK 3.0. During the STACK 3.0 merge, experimental features of STACK were also being added to the Aalto University version, as documented in section 7.8 of [4]. These features were related to several pedagogical ideas, detailed in [5,6,7]. Creating Abacus There were two key advancements in 2015. Firstly, STACK 3.0 was completed and Aalto University had finalised their plans to the deploy the system as a replacement to their old in-house version. Since the University was now using the official STACK version, it was easier to collaborate with other Universities on STACK material. Secondly, the consortium of the seven Finnish technology universities called for proposals in developing collaborative practices in education. A draft proposal for joint development of electronic materials for mathematics education was proposed and selected as a pilot project with over half a million euros of funding. A. Rasila was chosen as the national coordinator of this project, which become known as the Abacus consortium [8]. Figure: The Abacus logo. Abacus is a database of teaching materials, mainly STACK questions, covering most basic topics in undergraduate mathematics. Its mission statement is to help lecturers find high quality and free learning materials, achieved through facilitating the sharing of online teaching resources between institutions. National and international collaboration is at the heart of the project, as it helps standardise the platform, minimise the necessary contribution of each institution and contribute to the overall market share of the platform. Language differences between courses is not a concern, since adding translations to individual questions are almost trivial compared to the expense of actually programming the mathematics e-content. In drafting the initial consortium agreement, Abacus drew from two other related projects, namely a 2009 e-learning collaboration project with the Bavarian Virtual University VHB, which was funded by the later discontinued Finnish Virtual University, and the MatTa material bank Euler. Fair Use In projects largely developed through public and institutional funding, fair use is a common problem. Some partners may feel they are contributing more than the rest, and hence will not be interested in collaboration and instead push for in-house development. Furthermore, collaborators who develop materials without being paid are often unhappy when someone else makes even minor monetary gains from their work, which has led to a widespread use of non-commercial licenses for academic work. While understandable, these restrictions hinder the acceptance of platforms like Abacus, and lead to divisions in the community. Furthermore, non-commercial licenses can be confusing, as the exact nature of commercial activity is not clearly defined in academia. For example, is \"free\" work done by a salaried lecturer commercial use? Finally, it can be necessary for institutions to share the sources of assignments due to international differences in notation, course content and language. On the other hand, a pure open source model is not particularly attractive for e-assessment materials, since students should not be able to search online for the teachers' answers. To solve these problems, the Abacus consortium agreement was written such that there are no strict legal restrictions on what kind of institutions can join the consortium or what kinds of materials can be included. The materials are shared in a way such that each partner gets substantial rights to develop them based on a license similar to open source, but is not allowed to share the source code with third parties. The original developers retain their copyright of the materials and are allowed to give them other licenses besides the one required by Abacus. Since new members are reviewed by the consortium's steering group and are required to make a one-time contribution to the consortium, the agreement encourages collaboration and guarantees that existing partners benefit from the growth of the consortium. Outlook As of July 2019, the Abacus consortium consists of 30 members, 17 of which are from Finland, as well as three from Estonia and two from both Germany and Norway. Other countries present in the consortium are China, France, Ireland, Portugal, Ukraine, and the United Kingdom. There are ongoing discussions with several other potential partners, mainly from Europe. The database currently contains problem assignments for most bachelor level courses in mathematics, as well as a substantial number of physics assignments. Although Abacus accepts contributions in any language, most materials are available in English. Translations of the remaining Finnish-only materials are ongoing, and are expected to be completed in 2020. References [1] A. Rasila, M. Harjula, and K. Zenger. Automatic assessment of mathematics exercises: Experiences and future prospects. In ReekTori 2007: Symposium of Engineering Education, 70-80. Helsinki University of Technology, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2007. [2] A. Rasila, L. Havola, H. Majander, and J. Malinen. Automatic assessment in engineering mathematics: evaluation of the impact. In ReekTori 2010: Symposium of Engineering Education. Aalto University, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2010. [3] M. Harjula. Mathematics exercise system with automatic assessment. Master's thesis, Helsinki University of Technology, 2008. [4] C. J. Sangwin. Computer Aided Assessment of Mathematics. Oxford University Press, Oxford, UK, 2013. [5] H. Majander and A. Rasila. Tutkimus suuntaamassa 2010-luvun matemaattisten aineiden opetusta, Experiences of continuous formative assessment in engineering mathematics, 197-214. Tampereen yliopistopaino Oy - Juvenes Print, 2011. [6] A. Rasila, J. Malinen, and H. Tiitu. Automatic assement and conceptual understanding. Teaching Mathematics and its Applications, 34(3):149-159, 2015. [7] T. Pelkola, A. Rasila, and C. J. Sangwin. Investigating Bloom's learning for mastery in mathematics with online assessment. Informatics in Education, 17(2), 363-380, 2018. [8] A. Rasila. E-assessment material bank abacus. In Proceedings of EDILEARN16, 8th Annual International Conference on Education and New Learning Technologies, July 2016. STACK at Scale: The Open University Promoting STACK Across Disciplines at Loughborough University","title":"STACK for Engineering Mathematics and the Abacus Material Bank"},{"location":"CaseStudies/2019/ABACUS/#stack-for-engineering-mathematics-and-the-abacus-material-bank","text":"","title":"STACK for Engineering Mathematics and the Abacus Material Bank"},{"location":"CaseStudies/2019/ABACUS/#aalto-university","text":"Antti Rasila, Guangdong Technion - Israel Institute of Technology","title":"Aalto University"},{"location":"CaseStudies/2019/ABACUS/#abstract","text":"Since 2006, Aalto University has been using STACK to run online assessments within their Engineering Mathematics courses. Initially, the University was running a STACK version developed in-house specifically for the University, but this was later merged back into the main STACK branch in version 3.0. After receiving funding, the material bank Abacus was created, with the purpose of helping institutions collaborate and share STACK questions. The project's agreement was written in a way that ensured question authors kept their copyright, while still encouraging collaboration. Abacus has 30 members and its courses cover most of undergraduate mathematics and many parts of physics.","title":"Abstract"},{"location":"CaseStudies/2019/ABACUS/#motivation","text":"The MatTa group (\"Matematiikkaa tietokoneavusteisesti\"; \"mathematics by using computers\") was founded in 1990s by lecturer Emeritus Simo K. Kivel\u00e4 at the Department of Mathematics and Systems Analysis at Aalto University, formerly known as Helsinki University of Technology. The purpose of the group was to investigate the use of computers and information technology to teach engineering mathematics. Initially, the projects involved, for example, using visualisations, multimedia and symbolic computation to make mathematical content more interesting and accessible for students. The group also produced a number of free Finnish language electronic lecture notes with interactive content and a substantial database of traditional pen and paper exercise assignments called Euler. In 2006, the group started to take interest in automatic assessment, as they believed computer-aided methodologies could achieve a practical impact in teaching activities there. There was also hope at the University that Computer Aided Assessment could reduce the number of students assistants required to grade homework, both to save cost and because a sufficient number of qualified graders was not always available. Initially, the group focused on the Maple T.A. system, however it was found lacking in several aspects. The most important of these were performance issues and an incompatibility with various browsers, in particular ones available for the Linux operating system. The high licensing fees were also a problem, as they could undo all the savings that the University hoped to achieve by using the system. In spring of 2006, the group started gaining interest in STACK, which has an open source license. This license would allow the University to use its in-house software development skills to improve the platform where needed, and it would also guarantee that licence fees would not be imposed in the future. After deciding to use STACK, which was running its standalone version 1.x at the time, the group spent the summer of 2006 modifying the software to better suit the University's needs. This included replacing the rendering code of mathematical formulas to support browsers other than Microsoft Internet Explorer, translating the software to Finnish and a Shibboleth based integration with the Finnish national Haka single-sign-in system.","title":"Motivation"},{"location":"CaseStudies/2019/ABACUS/#implementing-stack","text":"Figure: An interactive STACK question from Aalto University's \"Multivariable Calculus\" course, where students drag points along a contour line. After modifying the system, the University started testing STACK. The initial test was with the university's Basic Course in Engineering Mathematics KP3. A. Rasila wrote four STACK assignments for each week of the course, all of which were relatively simple questions involving numerical or algebraic input. The system had numerous small technical issues, but the students were generally happy with the system as evidenced both by student feedback and general usage statistics [1]. Encouraged by the positive results, it was decided to test the system more comprehensively to convince the teaching community that automatic assessment was worth of the effort in teaching engineering mathematics. It was important to show that the online assessment could be used by teachers with little programming skill, and that it would not cause a large increase in their workload. This was crucial for the long-term success of the project, as MatTa's previously developed materials were often only used by a handful of teachers, most of whom where developers themselves. Furthermore, the group needed to demonstrate that the system had real cost savings, as well as good learning outcomes compared to traditional types of assignments. The University set up an experimental course \"Discrete Mathematics\", where STACK would form a significant portion of the final grade [2]. Following the positive results of this course, the use of STACK began to spread at the University, and within three years, most basic courses in Engineering Mathematics at Aalto University were using STACK.","title":"Implementing STACK"},{"location":"CaseStudies/2019/ABACUS/#stack-developments","text":"A key ingredient in the success of STACK at Aalto University were the in-house developments by programmer Matti Harjula, also wrote his Master\u2019s Thesis on this work [3]. His initial work included analysing the data of the first 2006 experiment and further developing the system to address any shortcomings. His project was successful, as it led to a system that many lecturers at the department were willing to use, and no major issues were identified in the subsequent use of the system. However, it also led to a new problem. Independently from Aalto University, the British STACK developers had been developing STACK 2.0, which was very different from the 1.x series Aalto University had been using for their work. The in-house developments by Aalto University were not easily implemented into STACK 2.0, but merging the Aalto University code back into the trunk of STACK was still necessary for a number of reasons. Firstly, a unified code base would speed up the overall development of STACK, and the Department at Aalto University did not intend to permanently commit many resources to maintaining the system. Secondly, there was interest from other Finnish universities to try the system, however they preferred to use the \u201cofficial\u201d British version of STACK, which would prevent them from using the materials developed at Aalto University. Because of this, the Finnish and British developers agreed to join forces in combining their work into STACK 3.0. During the STACK 3.0 merge, experimental features of STACK were also being added to the Aalto University version, as documented in section 7.8 of [4]. These features were related to several pedagogical ideas, detailed in [5,6,7].","title":"STACK Developments"},{"location":"CaseStudies/2019/ABACUS/#creating-abacus","text":"There were two key advancements in 2015. Firstly, STACK 3.0 was completed and Aalto University had finalised their plans to the deploy the system as a replacement to their old in-house version. Since the University was now using the official STACK version, it was easier to collaborate with other Universities on STACK material. Secondly, the consortium of the seven Finnish technology universities called for proposals in developing collaborative practices in education. A draft proposal for joint development of electronic materials for mathematics education was proposed and selected as a pilot project with over half a million euros of funding. A. Rasila was chosen as the national coordinator of this project, which become known as the Abacus consortium [8]. Figure: The Abacus logo. Abacus is a database of teaching materials, mainly STACK questions, covering most basic topics in undergraduate mathematics. Its mission statement is to help lecturers find high quality and free learning materials, achieved through facilitating the sharing of online teaching resources between institutions. National and international collaboration is at the heart of the project, as it helps standardise the platform, minimise the necessary contribution of each institution and contribute to the overall market share of the platform. Language differences between courses is not a concern, since adding translations to individual questions are almost trivial compared to the expense of actually programming the mathematics e-content. In drafting the initial consortium agreement, Abacus drew from two other related projects, namely a 2009 e-learning collaboration project with the Bavarian Virtual University VHB, which was funded by the later discontinued Finnish Virtual University, and the MatTa material bank Euler.","title":"Creating Abacus"},{"location":"CaseStudies/2019/ABACUS/#fair-use","text":"In projects largely developed through public and institutional funding, fair use is a common problem. Some partners may feel they are contributing more than the rest, and hence will not be interested in collaboration and instead push for in-house development. Furthermore, collaborators who develop materials without being paid are often unhappy when someone else makes even minor monetary gains from their work, which has led to a widespread use of non-commercial licenses for academic work. While understandable, these restrictions hinder the acceptance of platforms like Abacus, and lead to divisions in the community. Furthermore, non-commercial licenses can be confusing, as the exact nature of commercial activity is not clearly defined in academia. For example, is \"free\" work done by a salaried lecturer commercial use? Finally, it can be necessary for institutions to share the sources of assignments due to international differences in notation, course content and language. On the other hand, a pure open source model is not particularly attractive for e-assessment materials, since students should not be able to search online for the teachers' answers. To solve these problems, the Abacus consortium agreement was written such that there are no strict legal restrictions on what kind of institutions can join the consortium or what kinds of materials can be included. The materials are shared in a way such that each partner gets substantial rights to develop them based on a license similar to open source, but is not allowed to share the source code with third parties. The original developers retain their copyright of the materials and are allowed to give them other licenses besides the one required by Abacus. Since new members are reviewed by the consortium's steering group and are required to make a one-time contribution to the consortium, the agreement encourages collaboration and guarantees that existing partners benefit from the growth of the consortium.","title":"Fair Use"},{"location":"CaseStudies/2019/ABACUS/#outlook","text":"As of July 2019, the Abacus consortium consists of 30 members, 17 of which are from Finland, as well as three from Estonia and two from both Germany and Norway. Other countries present in the consortium are China, France, Ireland, Portugal, Ukraine, and the United Kingdom. There are ongoing discussions with several other potential partners, mainly from Europe. The database currently contains problem assignments for most bachelor level courses in mathematics, as well as a substantial number of physics assignments. Although Abacus accepts contributions in any language, most materials are available in English. Translations of the remaining Finnish-only materials are ongoing, and are expected to be completed in 2020.","title":"Outlook"},{"location":"CaseStudies/2019/ABACUS/#references","text":"[1] A. Rasila, M. Harjula, and K. Zenger. Automatic assessment of mathematics exercises: Experiences and future prospects. In ReekTori 2007: Symposium of Engineering Education, 70-80. Helsinki University of Technology, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2007. [2] A. Rasila, L. Havola, H. Majander, and J. Malinen. Automatic assessment in engineering mathematics: evaluation of the impact. In ReekTori 2010: Symposium of Engineering Education. Aalto University, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2010. [3] M. Harjula. Mathematics exercise system with automatic assessment. Master's thesis, Helsinki University of Technology, 2008. [4] C. J. Sangwin. Computer Aided Assessment of Mathematics. Oxford University Press, Oxford, UK, 2013. [5] H. Majander and A. Rasila. Tutkimus suuntaamassa 2010-luvun matemaattisten aineiden opetusta, Experiences of continuous formative assessment in engineering mathematics, 197-214. Tampereen yliopistopaino Oy - Juvenes Print, 2011. [6] A. Rasila, J. Malinen, and H. Tiitu. Automatic assement and conceptual understanding. Teaching Mathematics and its Applications, 34(3):149-159, 2015. [7] T. Pelkola, A. Rasila, and C. J. Sangwin. Investigating Bloom's learning for mastery in mathematics with online assessment. Informatics in Education, 17(2), 363-380, 2018. [8] A. Rasila. E-assessment material bank abacus. In Proceedings of EDILEARN16, 8th Annual International Conference on Education and New Learning Technologies, July 2016. STACK at Scale: The Open University Promoting STACK Across Disciplines at Loughborough University","title":"References"},{"location":"CaseStudies/2019/Adaptive/","text":"Adaptive Self-learning Exercises Ruhr-Universit\u00e4t Bochum Michael Kallweit Abstract At the Ruhr-Universit\u00e4t Bochum, students from all disciplines are offered digital mathematics tasks in an e-learning course for self-study in order to prepare and revise. These questions make intensive use of the randomisation and differentiated feedback options of the STACK question type. Some tasks have been supplemented by adaptive exercises, which guide the students through complex tasks. These adaptive tasks have had great success, are shown to have the same level of student engagement as paper-based tasks and be a better predictor of exam performance. Introduction At the Ruhr University Bochum, digital exercises have been used in courses at the Faculty of Mathematics since 2011, and since 2013 this has included STACK. In 2015, a cross-curricular e-learning course was set up, in which students can repeat and process selected topics for exam preparation by themselves. The course takes advantages of Moodle's gamification features: students gain points for engaging with quizzes, contributing to a \"level\". They also earn badges for completing material in a short time or with a high mark. Additionally, students have access to digital tutorial support. In addition to these features, the University wanted to add learning exercises that adapt to students' needs. Motivation In online assessment, weekly digital exercises are often done in \"examination mode\", that is, where students complete tasks in a given timeframe without interacting with the teachers in the meantime. Normally students are only allowed one attempt at the question, and differentiated feedback is only available for the students after the deadline. However, experience shows that students rarely use the detailed written feedback provided and are satisfied with just seeing their score. This observation is consistent with the students' responses to manually graded paper-based homework. Additionally, often valuable reflective loops that promote learning are omitted. As highlighted by Hattie's meta-analysis [2 and 3], it is important to increase students' interactivity with the feedback on their solutions. According to [4], good feedback should show concrete possibilities of how gaps in skills can be closed by students. Contrast this with tutorial lessons, where teachers often help students find a solution path. In the form of minimal assistance, teachers will intervene to help students achieve steady progress in dealing with a problem. If the students take an erroneous path to a solution, the teacher not just corrects the error, but will instead take the student on the path through the task. After being steered on the right path, the student will often fix the error by themselves. This procedure is known as instructional scaffolding: with just minimal support from the teacher, the students can master the individual tasks themselves, and can actively reflect on difficulties and mistakes during the process to close gaps in their knowledge. The developers at Ruhr-Universit\u00e4t Bochum wanted to bring this concept to online assessment: to build an online assessment system that can carry out instructional scaffolding to help students find a solution path. STACK was ideal for this, as its features in providing specific feedback depending on the properties of students answers provide a great foundation for an adaptive system. Adaptive self-learning approach Instead of being confronted by a teacher in a tutorial group, students can process adaptive digital self-learning tasks. Following the above principles, students follow an adaptive path of intermediate step tasks in small steps after submitting an incorrectly answered task. The intermediate steps focus on concrete knowledge and skills that must be combined to solve the original task. The adaptive methods were tested in entrance exams at secondary level II schools, through diagnostic error analysis tools [5,6,7]. The goal of this was to isolate the underlying errors behind why students incorrectly process digital tasks. Using digital tasks with STACK and a complex composition of digital tasks, the researchers achieved a considerable error detection rate of about 90%. Development of adaptive self-learning tasks Adaptive self-learning tasks follow the scaffolding principle. The error analysis and subsequent presentation of intermediate steps take place within the potential response trees of a STACK question, and offer added value compared to traditional digital tasks: In contrast to tasks in \"examination mode\", students actively deal with difficulties and errors. These are independently overcome by support in small steps and aim at a lasting learning success and increased motivation. Even with randomized STACK tasks, intermediate exercises refer to the task set at the beginning. A reference to the initial problem remains visible along the entire learning path. There are no limits on the design and variety of adaptive paths through the task. With each intermediate step, the next step can be selected on the basis of the student's individual input. The individual paths through the task are included in the source code of the individual STACK task, which allows questions to be easily shared between courses. The STACK Response Analysis Tool gives teachers insight into the paths taken by students. Technical implementation Moodle currently only offers limited possibilities for adaptively designing a sequence of tasks in tests. Hence, the adaptive tasks were introduced at the level of individual STACK questions. For each question, the potential response tree analyses the student's solution, and if they have made an error, shows a link to the starting point of an individual path. By including an externally stored Javascript file, the next intermediate step exercise becomes visible only by clicking on a button. The analysis of the input for this intermediate step is also stored in a response tree which adaptively defines the subsequent tasks. By repeating steps and integrating additional ones, the adaptive procedure can simulate real tutorial support. Example The following elementary example for matrix multiplication illustrates the central principles of the adaptive task format: Figure: An adaptable question about matrix multiplication. If the input of the solution is incorrect, the student is informed that they can work on the task again in guided intermediate steps via the \"Weiter\" (\"Next\") button. Figure: In the feedback, students may be told to work through the problem again, step-by-step. The first intermediate step then opens directly below the actual task, in this case asking students to identify the rule that is used when calculating matrix products. Subsequent steps will be available each time a step is correctly completed and the student clicks \"Next\" Figure: The three intermediate problem-solving steps for this question about matrix multiplication. The entire adaptive path with all intermediate step tasks has the following structure. Figure: An overview of the adaptive path for the matrix multiplication question. It is also possible to ask students to make a decision about which direction they want to take. Branches at which students make decisions about which direction they want to take are also possible. Overall, the feedback can be structured in a variety of ways according to Zech's hierarchy levels, with a focus on motivation, strategy or content help [8]. Results When comparing the University's new online assessment to their old, multiple-choice based system, several improvements become apparent. In multiple choice questions, you can only have a finite number of \"distractors\", but in STACK you can give feedback on an unlimited number of answers. In particular, the developers compared a question about expanding (2x+3y)^2, and found that while the old system had only 9 distractor options, the STACK system had registered 41 different answers over its lifetime, which could be grouped into 28 different types of mistakes. This is a major improvement on the number of mistakes students can receive specific feedback about. Additionally, the developers wanted to compare the performance of paper-based and digital homework. Across all courses, they did not find any significant difference in how many tasks students complete between the two systems. This is encouraging; the University saves resources by not relying on human markers for homework, and this confirms that they have not lost any functionality or student engagement by moving towards online assessment. For the course \"Mathematics for Chemistry\", the correlation between paper-based homework scores and exam scores was found to be 0.56, but the correlation between online homework scores and exam scores was 0.63. Similar results were found for the other courses at the University. Hence, online quiz scores are a better predictor for exam scores. Figure: Comparing both paper-based and online homework scores with exam scores, for the course \"Mathematics for Chemistry\". Challenges One of the main challenges of STACK integration was keeping up with new versions. It was important to convince administrators that going through the trouble of updating STACK was worth it, as new updates and features could be important to question authors. Additionally, there was a challenge in distributing the questions to new users, since Moodle's options for managing and distributing questions were found lacking. To solve this, a database for managing STACK questions in moodleXML files was created, which included more sophisticated search options. For each question, the system generates an overview pdf file with a short description, information on available languages, screenshots and an automatically generated overview of the potential response trees. About 700 questions are in the database, and because of its usability, it is easy to convince new users that it is simple to find good STACK questions. Enablers It was helpful to have a strong community of STACK users to help with projects. For example, one of the lecturers held a seminar to teach effective STACK usage to students training to become school teachers. The students of this class became a valuable community of STACK users willing to help with other projects. Additionally, it was valuable that STACK had been translated to German, as this allowed the University to easily spread STACK to other German institutions and build good partners. What's Next? The STACK courses at Ruhr-Universit\u00e4t Bochum continue to be improved on. Future additions may include using more sophisticated features in questions, such as equivalence reasoning inputs and interactive JSXGraph visuals. References [1] M. Kallweit and E. Glasmachers. Adaptive selbstlernaufgaben mit STACK. 2019. [2] J. Hattie. Visible learning: A synthesis of over 800 meta analyses relating to achievement. Routledge, 2009. [3] J. Hattie and H. Timperley. The power of feedback. Review of Educational Research , 77(1):91-112, 2007. [4] D.J. Nicol and D. Macfarlane-Dick. Formative assessment and self-regulated learning: a model and seven principles of good feedback practice. Studies in Higher Education, 31(2):199-218, 2006. [5] R. Bruder, N. Feldt Caesar, A. Pallack, G. Pinkernell, and A. Wynands. Mathematisches grundwissen und grundk\u007fonnen in der sekundarstufe ii. W. Blum et al. (Hrsg.) , Bildungsstandards aktuell: Mathematik in der Sekundarstufe II, pages 108-124, 2015. [6] M. Schaub. Einsatz des elementarisierenden testens im ein- und ausgangstest des online vorkurses vemint. Beitr\u00e4ge zum Mathematikunterricht 2018., pages 1567-1570, 2018. [7] F. Zech. Grundkurs Mathematikdidaktik. Theoretische und praktische Anleitungen f\u00fcr das Lehren und Lernen von Mathematik. 1978. STACK for a Physics Textbook A Flick Interface for Maths Input","title":"Adaptive Self-learning Exercises"},{"location":"CaseStudies/2019/Adaptive/#adaptive-self-learning-exercises","text":"","title":"Adaptive Self-learning Exercises"},{"location":"CaseStudies/2019/Adaptive/#ruhr-universitat-bochum","text":"Michael Kallweit","title":"Ruhr-Universit\u00e4t Bochum"},{"location":"CaseStudies/2019/Adaptive/#abstract","text":"At the Ruhr-Universit\u00e4t Bochum, students from all disciplines are offered digital mathematics tasks in an e-learning course for self-study in order to prepare and revise. These questions make intensive use of the randomisation and differentiated feedback options of the STACK question type. Some tasks have been supplemented by adaptive exercises, which guide the students through complex tasks. These adaptive tasks have had great success, are shown to have the same level of student engagement as paper-based tasks and be a better predictor of exam performance.","title":"Abstract"},{"location":"CaseStudies/2019/Adaptive/#introduction","text":"At the Ruhr University Bochum, digital exercises have been used in courses at the Faculty of Mathematics since 2011, and since 2013 this has included STACK. In 2015, a cross-curricular e-learning course was set up, in which students can repeat and process selected topics for exam preparation by themselves. The course takes advantages of Moodle's gamification features: students gain points for engaging with quizzes, contributing to a \"level\". They also earn badges for completing material in a short time or with a high mark. Additionally, students have access to digital tutorial support. In addition to these features, the University wanted to add learning exercises that adapt to students' needs.","title":"Introduction"},{"location":"CaseStudies/2019/Adaptive/#motivation","text":"In online assessment, weekly digital exercises are often done in \"examination mode\", that is, where students complete tasks in a given timeframe without interacting with the teachers in the meantime. Normally students are only allowed one attempt at the question, and differentiated feedback is only available for the students after the deadline. However, experience shows that students rarely use the detailed written feedback provided and are satisfied with just seeing their score. This observation is consistent with the students' responses to manually graded paper-based homework. Additionally, often valuable reflective loops that promote learning are omitted. As highlighted by Hattie's meta-analysis [2 and 3], it is important to increase students' interactivity with the feedback on their solutions. According to [4], good feedback should show concrete possibilities of how gaps in skills can be closed by students. Contrast this with tutorial lessons, where teachers often help students find a solution path. In the form of minimal assistance, teachers will intervene to help students achieve steady progress in dealing with a problem. If the students take an erroneous path to a solution, the teacher not just corrects the error, but will instead take the student on the path through the task. After being steered on the right path, the student will often fix the error by themselves. This procedure is known as instructional scaffolding: with just minimal support from the teacher, the students can master the individual tasks themselves, and can actively reflect on difficulties and mistakes during the process to close gaps in their knowledge. The developers at Ruhr-Universit\u00e4t Bochum wanted to bring this concept to online assessment: to build an online assessment system that can carry out instructional scaffolding to help students find a solution path. STACK was ideal for this, as its features in providing specific feedback depending on the properties of students answers provide a great foundation for an adaptive system.","title":"Motivation"},{"location":"CaseStudies/2019/Adaptive/#adaptive-self-learning-approach","text":"Instead of being confronted by a teacher in a tutorial group, students can process adaptive digital self-learning tasks. Following the above principles, students follow an adaptive path of intermediate step tasks in small steps after submitting an incorrectly answered task. The intermediate steps focus on concrete knowledge and skills that must be combined to solve the original task. The adaptive methods were tested in entrance exams at secondary level II schools, through diagnostic error analysis tools [5,6,7]. The goal of this was to isolate the underlying errors behind why students incorrectly process digital tasks. Using digital tasks with STACK and a complex composition of digital tasks, the researchers achieved a considerable error detection rate of about 90%.","title":"Adaptive self-learning approach"},{"location":"CaseStudies/2019/Adaptive/#development-of-adaptive-self-learning-tasks","text":"Adaptive self-learning tasks follow the scaffolding principle. The error analysis and subsequent presentation of intermediate steps take place within the potential response trees of a STACK question, and offer added value compared to traditional digital tasks: In contrast to tasks in \"examination mode\", students actively deal with difficulties and errors. These are independently overcome by support in small steps and aim at a lasting learning success and increased motivation. Even with randomized STACK tasks, intermediate exercises refer to the task set at the beginning. A reference to the initial problem remains visible along the entire learning path. There are no limits on the design and variety of adaptive paths through the task. With each intermediate step, the next step can be selected on the basis of the student's individual input. The individual paths through the task are included in the source code of the individual STACK task, which allows questions to be easily shared between courses. The STACK Response Analysis Tool gives teachers insight into the paths taken by students.","title":"Development of adaptive self-learning tasks"},{"location":"CaseStudies/2019/Adaptive/#technical-implementation","text":"Moodle currently only offers limited possibilities for adaptively designing a sequence of tasks in tests. Hence, the adaptive tasks were introduced at the level of individual STACK questions. For each question, the potential response tree analyses the student's solution, and if they have made an error, shows a link to the starting point of an individual path. By including an externally stored Javascript file, the next intermediate step exercise becomes visible only by clicking on a button. The analysis of the input for this intermediate step is also stored in a response tree which adaptively defines the subsequent tasks. By repeating steps and integrating additional ones, the adaptive procedure can simulate real tutorial support.","title":"Technical implementation"},{"location":"CaseStudies/2019/Adaptive/#example","text":"The following elementary example for matrix multiplication illustrates the central principles of the adaptive task format: Figure: An adaptable question about matrix multiplication. If the input of the solution is incorrect, the student is informed that they can work on the task again in guided intermediate steps via the \"Weiter\" (\"Next\") button. Figure: In the feedback, students may be told to work through the problem again, step-by-step. The first intermediate step then opens directly below the actual task, in this case asking students to identify the rule that is used when calculating matrix products. Subsequent steps will be available each time a step is correctly completed and the student clicks \"Next\" Figure: The three intermediate problem-solving steps for this question about matrix multiplication. The entire adaptive path with all intermediate step tasks has the following structure. Figure: An overview of the adaptive path for the matrix multiplication question. It is also possible to ask students to make a decision about which direction they want to take. Branches at which students make decisions about which direction they want to take are also possible. Overall, the feedback can be structured in a variety of ways according to Zech's hierarchy levels, with a focus on motivation, strategy or content help [8].","title":"Example"},{"location":"CaseStudies/2019/Adaptive/#results","text":"When comparing the University's new online assessment to their old, multiple-choice based system, several improvements become apparent. In multiple choice questions, you can only have a finite number of \"distractors\", but in STACK you can give feedback on an unlimited number of answers. In particular, the developers compared a question about expanding (2x+3y)^2, and found that while the old system had only 9 distractor options, the STACK system had registered 41 different answers over its lifetime, which could be grouped into 28 different types of mistakes. This is a major improvement on the number of mistakes students can receive specific feedback about. Additionally, the developers wanted to compare the performance of paper-based and digital homework. Across all courses, they did not find any significant difference in how many tasks students complete between the two systems. This is encouraging; the University saves resources by not relying on human markers for homework, and this confirms that they have not lost any functionality or student engagement by moving towards online assessment. For the course \"Mathematics for Chemistry\", the correlation between paper-based homework scores and exam scores was found to be 0.56, but the correlation between online homework scores and exam scores was 0.63. Similar results were found for the other courses at the University. Hence, online quiz scores are a better predictor for exam scores. Figure: Comparing both paper-based and online homework scores with exam scores, for the course \"Mathematics for Chemistry\".","title":"Results"},{"location":"CaseStudies/2019/Adaptive/#challenges","text":"One of the main challenges of STACK integration was keeping up with new versions. It was important to convince administrators that going through the trouble of updating STACK was worth it, as new updates and features could be important to question authors. Additionally, there was a challenge in distributing the questions to new users, since Moodle's options for managing and distributing questions were found lacking. To solve this, a database for managing STACK questions in moodleXML files was created, which included more sophisticated search options. For each question, the system generates an overview pdf file with a short description, information on available languages, screenshots and an automatically generated overview of the potential response trees. About 700 questions are in the database, and because of its usability, it is easy to convince new users that it is simple to find good STACK questions.","title":"Challenges"},{"location":"CaseStudies/2019/Adaptive/#enablers","text":"It was helpful to have a strong community of STACK users to help with projects. For example, one of the lecturers held a seminar to teach effective STACK usage to students training to become school teachers. The students of this class became a valuable community of STACK users willing to help with other projects. Additionally, it was valuable that STACK had been translated to German, as this allowed the University to easily spread STACK to other German institutions and build good partners.","title":"Enablers"},{"location":"CaseStudies/2019/Adaptive/#whats-next","text":"The STACK courses at Ruhr-Universit\u00e4t Bochum continue to be improved on. Future additions may include using more sophisticated features in questions, such as equivalence reasoning inputs and interactive JSXGraph visuals.","title":"What's Next?"},{"location":"CaseStudies/2019/Adaptive/#references","text":"[1] M. Kallweit and E. Glasmachers. Adaptive selbstlernaufgaben mit STACK. 2019. [2] J. Hattie. Visible learning: A synthesis of over 800 meta analyses relating to achievement. Routledge, 2009. [3] J. Hattie and H. Timperley. The power of feedback. Review of Educational Research , 77(1):91-112, 2007. [4] D.J. Nicol and D. Macfarlane-Dick. Formative assessment and self-regulated learning: a model and seven principles of good feedback practice. Studies in Higher Education, 31(2):199-218, 2006. [5] R. Bruder, N. Feldt Caesar, A. Pallack, G. Pinkernell, and A. Wynands. Mathematisches grundwissen und grundk\u007fonnen in der sekundarstufe ii. W. Blum et al. (Hrsg.) , Bildungsstandards aktuell: Mathematik in der Sekundarstufe II, pages 108-124, 2015. [6] M. Schaub. Einsatz des elementarisierenden testens im ein- und ausgangstest des online vorkurses vemint. Beitr\u00e4ge zum Mathematikunterricht 2018., pages 1567-1570, 2018. [7] F. Zech. Grundkurs Mathematikdidaktik. Theoretische und praktische Anleitungen f\u00fcr das Lehren und Lernen von Mathematik. 1978. STACK for a Physics Textbook A Flick Interface for Maths Input","title":"References"},{"location":"CaseStudies/2019/Edinburgh/","text":"Institutional Support for STACK in Edinburgh University of Edinburgh Interview with Chris Sangwin Abstract At the University of Edinburgh, online assessment has been consolidated with in-house support, mostly with STACK, for the majority of year one and two mathematics modules and for many other mathematics and general science courses. A dedicated learning-technologist post was created to help course organisers implement online assessment. Replacing the current online assessment with human marking is currently estimated to save the School over 6100 hours of work marking students' work each year. Motivation The School of Mathematics at the University of Edinburgh had, over the years, grown to use a number of separate online assessment systems. However, there was growing concern that using separate systems created a number of problems, for example students had to learn the syntax of many different systems. It was also problematic that students needed to purchase access to the online systems provided by publishers. At the same time, student numbers in the UK continued to grow [1], and there were growing expectations from students for more frequent formative assessment in their courses. This motivated the school to bring all assessments in-house with STACK. Execution Figure: A typical Introduction to Linear Algebra question. STACK was first used in Edinburgh at a small scale for the Lothian Equal Access Programme for Schools (LEAPS) summer school in 2016. Following the success with LEAPS, STACK was used in larger courses such as Introduction to Linear Algebra, a year one module with over 600 students, in the 2016-17 academic year. The University's primary learning environment is Blackboard \"LEARN\", so students gain access to a dedicated STACK service via the LTI protocol through their normal LEARN pages. Having identified the need for additional support, the School of Mathematics created a dedicated \"Learning Technologist\" post. The primary goal of this post was to transform existing (largely paper-based) problem sets into online assessments and to develop alternatives to existing external online assessments. The Technologist used the following process to transform these assessments. Before the year started, current forms of assessment were reviewed, and suitable STACK questions were written together with course organisers. During the academic year, quizzes were made available, and their usage monitored. When the year was over, this monitoring data was analysed and questions were updated where appropriate. Creating online assessments is significant additional work, but once the quizzes have been created they require minimal work to maintain and can last for the lifetime of the course. Because of this cost-benefit relationship, employing a Learning Technologist has been an effective strategy in ensuring change actually took place. Results In 2019, many courses have online assessments using STACK. A course will typically have weekly or fortnightly assessment, many using a combination of flipped classroom \"reading quizzes\" (RQ), formative \"practice quizzes\" (PQ) and summative \"assessed quizzes\" (AQ). Some courses also make an optional mock online exam available to students. The following table provides an overview from the 18/19 year, including the number of students, how often quizzes were given out (per week W or semester S), the average number of questions per quiz (#Q/quiz) and the total number of questions (#Qs). Year Course Students Quizzes #Q/quiz #Qs 1 Introduction to Linear Algebra 604 2 RQ/W 2-3 1 AQ/W 6-8 110 1 Calculus and its Applications 594 1 RQ/W 4 1 AQ/W 10 150 1 Proofs and Problem Solving 344 1 RQ/W 2 20 1 Engineering Mathematics 1a 393 3 PQ/W 5 Mathematics for Natural Sciences 1a 138 1 AQ/W 7-10 240 1 Engineering Mathematics 1b 401 3 PQ/W 3-5 Mathematics for Natural Sciences 1b 136 1 AQ/W 7-10 200 1 Mathematics for Physics 1 193 5 AQ/S 5 25 1 Mathematics for Physics 2 202 5 AQ/S 6 30 1 Fundamentals of Algebra and Calculus 113 5 PQ/W 10-20 3 AQ/W 6-12 950 2 Probability 312 1 AQ/W 3-5 36 2 Several Variable Calculus and DEs 287 1 PQ/W 5-12 1 AQ/W 5-10 180 3 Honours Algebra 202 9 AQ/S 1-8 46 3 Combinatorics and Graph Theory 60 2 RQ/W 2 4 AQ/S 1-6 45 3 Symmetry and Geometry 36 1 AQ/W 4-7 45 4 Galois Theory 27 1 RQ/W 2 22 PG Fundamentals of Optimization 190 3 AQ/S 4-8 16 PG Introduction to Probability and Statistics 23 1 PQ/W 6-8 5 AQ/S 4 62 Table: Courses using STACK assessments at The University of Edinburgh 2018-19. Cost Over the course of this project, the Learning Technologist estimates that developing a fully functioning quiz of 8 questions took about two person-days, or 16 hours of work, to create. As an example, consider the large first-year course \"Introduction to Linear Algebra\", with around 600 students in 65 tutorial groups. Replacing half of the weekly hand-ins with online assessments has saved each tutor over one hour of marking per week. Hence, over 65 hours of work is saved each week as a result. In addition, the students now complete more than double the number of practice problems, providing them with enhanced formative feedback which would be impossible to resource otherwise. Since online quizzes can be reused each year, this will be a consistent saving for as long as the course remains. Overall, it is estimated that STACK saves the University over 6100 hours of work each year [2]. Figure: Many School of Mathematics courses are taken at the James Clerk Maxwell Building. Barriers The goal was to have the first 4-6 weeks of quizzes ready before the beginning of a semester. However, as the term progressed, it was not unusual for the last few quizzes to be ready only \"at the last moment\". This did not give the question authors a lot of time to review their questions, but does reflect the realities of teaching. It was also important that the course organiser were fully involved in the authoring process. They had to give clear and explicit guidance on the learning objectives and help review the mathematical content. Finally, when working with large question banks, organising became difficult. Large Moodle question banks are tricky to browse, and maintenance becomes tedious when questions are duplicated between similar courses. Enablers The most significant factor in the success of this project was the dedicated Learning Technologist post. This was essential, as it assured course organisers had practical support, and that online quizzes could have a consistently high level of quality. It was helpful to be able to work closely with STACK developers when designing quizzes, in a way that is difficult with non-open-source programs. For example, the \"numerical\" input type which helps students enter answers at a pre-specified level of numerical accuracy, was designed to help cope with the difficulties of assessing vague student answers in statistics questions [3]. What's Next? The School of Mathematics continues to expand the use STACK at the University of Edinburgh. Future challenges involve modifying STACK to suit more conceptual courses, such as group theory and real analysis, as well as expanding into statistics and computer programming using the CodeRunner system [4]. There are also plans for wider use of STACK in summative assessments, with the possibility of using it in online examinations. References [1] Patterns and trends in UK higher education 2018. Universities UK, September 2018. ISBN: 978-1-84036-409-5. [2] C. J. Sangwin and K. Zerva. Developing online learning materials to support undergraduate education at the University of Edinburgh. Mathematics Today, 2019. [3] K. Zerva. Developing STACK assessments in Edinburgh , 2017-2019. In Contributions to the 1st International STACK conference 2018 in F\u007furth, Germany. Zenodo, 2019. [4] R. Lobb and J. Harlow. Coderunner: a tool for assessing computer programming skills. ACM Inroads, 7(1):47{51, March 2016. Promoting STACK Across Disciplines at Loughborough University Diagnostics Testing With STACK","title":"Institutional Support for STACK in Edinburgh"},{"location":"CaseStudies/2019/Edinburgh/#institutional-support-for-stack-in-edinburgh","text":"","title":"Institutional Support for STACK in Edinburgh"},{"location":"CaseStudies/2019/Edinburgh/#university-of-edinburgh","text":"Interview with Chris Sangwin","title":"University of Edinburgh"},{"location":"CaseStudies/2019/Edinburgh/#abstract","text":"At the University of Edinburgh, online assessment has been consolidated with in-house support, mostly with STACK, for the majority of year one and two mathematics modules and for many other mathematics and general science courses. A dedicated learning-technologist post was created to help course organisers implement online assessment. Replacing the current online assessment with human marking is currently estimated to save the School over 6100 hours of work marking students' work each year.","title":"Abstract"},{"location":"CaseStudies/2019/Edinburgh/#motivation","text":"The School of Mathematics at the University of Edinburgh had, over the years, grown to use a number of separate online assessment systems. However, there was growing concern that using separate systems created a number of problems, for example students had to learn the syntax of many different systems. It was also problematic that students needed to purchase access to the online systems provided by publishers. At the same time, student numbers in the UK continued to grow [1], and there were growing expectations from students for more frequent formative assessment in their courses. This motivated the school to bring all assessments in-house with STACK.","title":"Motivation"},{"location":"CaseStudies/2019/Edinburgh/#execution","text":"Figure: A typical Introduction to Linear Algebra question. STACK was first used in Edinburgh at a small scale for the Lothian Equal Access Programme for Schools (LEAPS) summer school in 2016. Following the success with LEAPS, STACK was used in larger courses such as Introduction to Linear Algebra, a year one module with over 600 students, in the 2016-17 academic year. The University's primary learning environment is Blackboard \"LEARN\", so students gain access to a dedicated STACK service via the LTI protocol through their normal LEARN pages. Having identified the need for additional support, the School of Mathematics created a dedicated \"Learning Technologist\" post. The primary goal of this post was to transform existing (largely paper-based) problem sets into online assessments and to develop alternatives to existing external online assessments. The Technologist used the following process to transform these assessments. Before the year started, current forms of assessment were reviewed, and suitable STACK questions were written together with course organisers. During the academic year, quizzes were made available, and their usage monitored. When the year was over, this monitoring data was analysed and questions were updated where appropriate. Creating online assessments is significant additional work, but once the quizzes have been created they require minimal work to maintain and can last for the lifetime of the course. Because of this cost-benefit relationship, employing a Learning Technologist has been an effective strategy in ensuring change actually took place.","title":"Execution"},{"location":"CaseStudies/2019/Edinburgh/#results","text":"In 2019, many courses have online assessments using STACK. A course will typically have weekly or fortnightly assessment, many using a combination of flipped classroom \"reading quizzes\" (RQ), formative \"practice quizzes\" (PQ) and summative \"assessed quizzes\" (AQ). Some courses also make an optional mock online exam available to students. The following table provides an overview from the 18/19 year, including the number of students, how often quizzes were given out (per week W or semester S), the average number of questions per quiz (#Q/quiz) and the total number of questions (#Qs). Year Course Students Quizzes #Q/quiz #Qs 1 Introduction to Linear Algebra 604 2 RQ/W 2-3 1 AQ/W 6-8 110 1 Calculus and its Applications 594 1 RQ/W 4 1 AQ/W 10 150 1 Proofs and Problem Solving 344 1 RQ/W 2 20 1 Engineering Mathematics 1a 393 3 PQ/W 5 Mathematics for Natural Sciences 1a 138 1 AQ/W 7-10 240 1 Engineering Mathematics 1b 401 3 PQ/W 3-5 Mathematics for Natural Sciences 1b 136 1 AQ/W 7-10 200 1 Mathematics for Physics 1 193 5 AQ/S 5 25 1 Mathematics for Physics 2 202 5 AQ/S 6 30 1 Fundamentals of Algebra and Calculus 113 5 PQ/W 10-20 3 AQ/W 6-12 950 2 Probability 312 1 AQ/W 3-5 36 2 Several Variable Calculus and DEs 287 1 PQ/W 5-12 1 AQ/W 5-10 180 3 Honours Algebra 202 9 AQ/S 1-8 46 3 Combinatorics and Graph Theory 60 2 RQ/W 2 4 AQ/S 1-6 45 3 Symmetry and Geometry 36 1 AQ/W 4-7 45 4 Galois Theory 27 1 RQ/W 2 22 PG Fundamentals of Optimization 190 3 AQ/S 4-8 16 PG Introduction to Probability and Statistics 23 1 PQ/W 6-8 5 AQ/S 4 62 Table: Courses using STACK assessments at The University of Edinburgh 2018-19.","title":"Results"},{"location":"CaseStudies/2019/Edinburgh/#cost","text":"Over the course of this project, the Learning Technologist estimates that developing a fully functioning quiz of 8 questions took about two person-days, or 16 hours of work, to create. As an example, consider the large first-year course \"Introduction to Linear Algebra\", with around 600 students in 65 tutorial groups. Replacing half of the weekly hand-ins with online assessments has saved each tutor over one hour of marking per week. Hence, over 65 hours of work is saved each week as a result. In addition, the students now complete more than double the number of practice problems, providing them with enhanced formative feedback which would be impossible to resource otherwise. Since online quizzes can be reused each year, this will be a consistent saving for as long as the course remains. Overall, it is estimated that STACK saves the University over 6100 hours of work each year [2]. Figure: Many School of Mathematics courses are taken at the James Clerk Maxwell Building.","title":"Cost"},{"location":"CaseStudies/2019/Edinburgh/#barriers","text":"The goal was to have the first 4-6 weeks of quizzes ready before the beginning of a semester. However, as the term progressed, it was not unusual for the last few quizzes to be ready only \"at the last moment\". This did not give the question authors a lot of time to review their questions, but does reflect the realities of teaching. It was also important that the course organiser were fully involved in the authoring process. They had to give clear and explicit guidance on the learning objectives and help review the mathematical content. Finally, when working with large question banks, organising became difficult. Large Moodle question banks are tricky to browse, and maintenance becomes tedious when questions are duplicated between similar courses.","title":"Barriers"},{"location":"CaseStudies/2019/Edinburgh/#enablers","text":"The most significant factor in the success of this project was the dedicated Learning Technologist post. This was essential, as it assured course organisers had practical support, and that online quizzes could have a consistently high level of quality. It was helpful to be able to work closely with STACK developers when designing quizzes, in a way that is difficult with non-open-source programs. For example, the \"numerical\" input type which helps students enter answers at a pre-specified level of numerical accuracy, was designed to help cope with the difficulties of assessing vague student answers in statistics questions [3].","title":"Enablers"},{"location":"CaseStudies/2019/Edinburgh/#whats-next","text":"The School of Mathematics continues to expand the use STACK at the University of Edinburgh. Future challenges involve modifying STACK to suit more conceptual courses, such as group theory and real analysis, as well as expanding into statistics and computer programming using the CodeRunner system [4]. There are also plans for wider use of STACK in summative assessments, with the possibility of using it in online examinations.","title":"What's Next?"},{"location":"CaseStudies/2019/Edinburgh/#references","text":"[1] Patterns and trends in UK higher education 2018. Universities UK, September 2018. ISBN: 978-1-84036-409-5. [2] C. J. Sangwin and K. Zerva. Developing online learning materials to support undergraduate education at the University of Edinburgh. Mathematics Today, 2019. [3] K. Zerva. Developing STACK assessments in Edinburgh , 2017-2019. In Contributions to the 1st International STACK conference 2018 in F\u007furth, Germany. Zenodo, 2019. [4] R. Lobb and J. Harlow. Coderunner: a tool for assessing computer programming skills. ACM Inroads, 7(1):47{51, March 2016. Promoting STACK Across Disciplines at Loughborough University Diagnostics Testing With STACK","title":"References"},{"location":"CaseStudies/2019/FAC/","text":"Developing a Fully Online Course The University of Edinburgh, UK Interview with George Kinnear and Richard Gratwick Abstract STACK is used in the completely online course \"Fundamentals of Algebra and Calculus\". The course is designed to prepare students for Higher Education (HE) study at the University of Edinburgh, where incoming students have a wide range of mathematical backgrounds. The main barriers were the risk of students using online answer engines to answer questions, and the lack of community. The organizers attempted to address this by clever question design and creating \"autonomous learning groups\". The course was enabled by University support, both in the form of a dedicated learning-technologist post and assistance from colleagues. Subsequent diagnostics test results indicate this course was successful. Introduction Approximately six hundred students typically study first-year mathematics courses at the University of Edinburgh. They have a wide range of mathematical backgrounds and attainments. \"Fundamentals of Algebra and Calculus\" (FAC) was introduced as an additional course, approximately covering SQA Advanced Higher Mathematics and A-Level Further Mathematics, to address the needs of this diverse group. Since some incoming students do not have the chance to take these higher qualifications before coming to university, the course fulfils a role as part of the University\u2019s Widening Participation strategy, enabling access to mathematics courses for a wider range of students, e.g. students admitted through contextual admissions. This also was an attempt to address a concern from the University that one reason for undergraduate non-continuation was a lack of preparation for the mathematical components of students\u2019 degree programmes, particularly those students on non-mathematics degrees within the College of Science and Engineering. Increasingly, the second-semester year 1 \"Calculus and its Applications\" course had been adapted to address these problems. However, staff and students felt that it recently contained too much material. FAC aimed to relieve some of the pressure on this course. FAC was delivered as a completely online course to make it scalable, since the above issues are not unique to the School or the University. FAC plays a role in addressing the so-called \u201cmathematics gap\u201d of attainment, preparing students from a wide range of mathematical backgrounds for HE study, and as such could easily see demand both across the University and beyond. Why Use STACK? FAC is essentially a course in mathematical techniques, assessing routine computation. STACK precisely lets teachers assess such questions automatically and give tailored feedback to students. Quite sophisticated questions can be implemented, for example \u201cgive an example\u201d type questions, asking students to provide examples of e.g. a quadratic with given roots, or a sequence with certain monotonicity or boundedness properties. These are important for \"retrieval practice\", that is, encouraging students to recall previous topics. Execution The course is worth 10 ECTS credits, and consists of approximately 200 hours of work for the student. The course is delivered in ten weekly units, each comprising a number of quizzes intended for students to work through during that week. Each week ends with a 90-minute \"Practice Quiz\" the student can take an unlimited number of times, and a 90-minute \"Final Test\" only allowing one attempt. The test is either given a grade of fail (0-80%), mastery (80-95%) or distinction (95%-100%). The high pass mark encourages students to master a topic before moving on. The final grade is determined by combining the results of the 10 \"Final Tests\" (worth 80%) with a final 2-hour test covering the whole course (worth 20%). The development involved a substantial up-front time investment: writing the material in these quizzes, including over 900 STACK questions. Although some existing questions were borrowed from other courses, the majority of these questions were authored from scratch. The quizzes interleave textbook-style exposition with videos of worked examples, interactive applets and practice questions, and as a result, the questions have a polished and varied look. Two lecturers were involved, each responsible for five units, with final cross-checking and occasional extra contributions. Research Figure: A FAC question aimed at both retrieval practice and building a strong example space. The design of the course was heavily influenced by educational research. Firstly, the course uses \"faded worked examples\", that is, presenting a sequence of problems with different amounts of the solution already worked out. For example, a topic might begin with a full worked solution of a problem, followed by a worked solution with the final step as a STACK input, followed by a worked solution with the last two steps as STACK input, and so on. There is evidence that this is helpful for students [2]. Additionally, given the literature on the importance of \"retrieval practice\" [3], FAC gives plenty of chances for students to recall what they have learned, for example by having quizzes draw on skills from previous weeks. Weeks alternate between algebra and calculus, spacing out practice of the two topics. Furthermore, the lecturers decided not to make feedback for the final tests available to students until after the deadline, since there is evidence suggesting delaying feedback is helpful for learning [5]. Finally, FAC gives students a chance to create strong \"example spaces\" [4], that is, sets of examples that a student can recall for a given topic. Example spaces are developed through \"give-an-example\" style questions, which are easy to write in STACK. Visuals FAC uses a lot of graphs and interactive applets to make questions visually appealing. Visual intuition is an important part of learning about functions, so it is appropriate for graphical components to play a significant part in this course. FAC uses both JSX graphs (which can be coded directly in STACK) and external plugins, like GeoGebra. The advantage of JSX graphs is that they are self-contained; there is no need to worry about changes to external programs, or licensing rights. There is, however, a large cost-benefit analysis to consider. JSX graphs are time-consuming and have a steep learning curve, while external applets are often quick to set up and have simple drag-and-drop features. Figure: FAC uses graphs and other visuals to aid learning. Results The six hundred students taking the first-semester year 1 \"Introduction to Linear Algebra\" course sat a diagnostic test (also delivered through STACK) in September 2018. In January 2019, the students sat the test again with the same questions but different random variants. In the September test, students also enrolled on FAC scored on average fifteen percentage points lower than their peers. This is not surprising; FAC will have been recommended to students who felt like they needed more practice in mathematics fundamentals. However, in January after studying FAC, they had gained these fifteen percentage points and were scoring in line with their peers. This is quantitative evidence that FAC has done exactly what was hoped: removed the discrepancy in attainment between the two groups of students. The lecturers also wanted to know if taking FAC had improved student performance in other maths courses such as \"Introduction to Linear Algebra\" (ILA) and \"Calculus and its Applications\" (CAP). Of students scoring similarly in the September diagnostics test, students who took FAC were scoring better than their peers in online quizzes for CAP. They also scored at a similar level to students who did not take FAC in the exams for ILA and CAP. Figure: Diagnostic results in September (pre) and January (post). Challenges While it is true that authoring a simple STACK question is ultimately straightforward, there was nonetheless a technological hurdle to be cleared. One lecturer was entirely new not only to STACK, but to Maxima and any form of online assessment, and therefore was confronted with quite an intimidating prospect. However, they ended up authoring hundreds of questions without trouble, and are now confident in undertaking significantly more demanding questions. This hurdle was easier to overcome given STACK requires no programming expertise. The lecturers were mindful of the possibility that students could be working through assessed quizzes in one browser tab, with a tool like WolframAlpha open in another. While ultimately this does no benefit to the student, and it remains their responsibility to ensure submitted answers are their own work, the potential of this kind of abuse should be minimised. This just required a bit of cunning at the level of question-setting: turning \u201cfind the derivative of this given function at this given point\u201d into \u201cat what point is the value of the derivative of this given function this given number?\u201d The limitations of an online course include the difficulties of forming meaningful staff-student and student-student interaction. The lack of real staff-student interaction made it hard to gauge whether the level and volume of material was suitable \u2013 anecdotal feedback indicates this was misjudged in at least one of the weekly units. Student-student interaction is important to foster a sense of community. This was addressed by setting up \u201cautonomous learning groups\u201d in which the students could study, in person, once a week, without staff input. Furthermore, students could ask questions in the online forum Piazza, and get in-person help in the MathsBase study room if needed. Enablers The University had created a dedicated learning-technologist post to help design the online assessment and write STACK questions. Their work was invaluable for authoring some of the questions, often given only a one-line sketch of the desired question. The capacity in STACK to clone questions and export questions from other courses was also very useful, making it possible to produce multiple related questions, sharing, for example, a grading structure, without duplicating any work. Finally, it was an advantage that there is substantial \u201cin-house\u201d support at the University, since STACK is now used across the entire first-year curriculum and increasingly beyond. Hence, there are a number of members of staff with experience of authoring questions, and the students are familiar with it. What's Next? A lot of data has been collected in FAC's first year. Quiz responses will be analysed to determine if any questions should be modified. There are also plans to have interviews with students on the effectiveness of the course, which will help identify areas that need work. The course organiser will be looking at improving the \"autonomous learning groups\". Since groups were given weekly tasks and asked to upload solutions to a shared Dropbox, the lecturers can see how much students interacted with these groups. Initially, the engagement was very strong, but half-way through the course, a lot of groups seemed to stop meeting. The course organiser will look at ways to improve turnout for these groups. The course continues to be worked on. The lecturers are considering options for more interactive questions, for example using equivalence reasoning to assess line-by-line arguments, or interactive JSX graphs that ask a student to, for example, \"drag a vector so it is perpendicular to another vector\". The success of FAC paves the way for similar methods to be used in different courses. Other schools have shown interest in creating similar online courses, and some students may find it helpful to have an online course teaching even less advanced maths. References [1] George Kinnear. Delivering an online course using STACK. In Proceedings of the STACK Conference, 2018. [2] A. Renkl, R. K. Atkinson, U. H. Maier, and R. Staley. From Example Study to Problem Solving: Smooth Transitions Help Learning. The Journal of Experimental Education, 70(4):293-315, 2002. [3] H. L. Roediger and A. C. Butler. The critical role of retrieval practice in longterm retention. Trends in Cognitive Sciences, 15(1):20-27, 2011. [4] P. Goldenberg and J. Mason. Shedding light on and with example spaces. Educational Studies in Mathematics, 65(2):183-194, 2008. [5] H. G. Mullet, A. C. Butler, B. Verdin, R. Borries, and E. J. Marsh. Delaying feedback promotes transfer of knowledge despite student preferences to receive feedback immediately. Journal of Applied Research in Memory and Cognition, 3(3):222-229, 2014. Extra-Occupational Bridging Courses STACK for a Physics Textbook","title":"Developing a Fully Online Course"},{"location":"CaseStudies/2019/FAC/#developing-a-fully-online-course","text":"","title":"Developing a Fully Online Course"},{"location":"CaseStudies/2019/FAC/#the-university-of-edinburgh-uk","text":"Interview with George Kinnear and Richard Gratwick","title":"The University of Edinburgh, UK"},{"location":"CaseStudies/2019/FAC/#abstract","text":"STACK is used in the completely online course \"Fundamentals of Algebra and Calculus\". The course is designed to prepare students for Higher Education (HE) study at the University of Edinburgh, where incoming students have a wide range of mathematical backgrounds. The main barriers were the risk of students using online answer engines to answer questions, and the lack of community. The organizers attempted to address this by clever question design and creating \"autonomous learning groups\". The course was enabled by University support, both in the form of a dedicated learning-technologist post and assistance from colleagues. Subsequent diagnostics test results indicate this course was successful.","title":"Abstract"},{"location":"CaseStudies/2019/FAC/#introduction","text":"Approximately six hundred students typically study first-year mathematics courses at the University of Edinburgh. They have a wide range of mathematical backgrounds and attainments. \"Fundamentals of Algebra and Calculus\" (FAC) was introduced as an additional course, approximately covering SQA Advanced Higher Mathematics and A-Level Further Mathematics, to address the needs of this diverse group. Since some incoming students do not have the chance to take these higher qualifications before coming to university, the course fulfils a role as part of the University\u2019s Widening Participation strategy, enabling access to mathematics courses for a wider range of students, e.g. students admitted through contextual admissions. This also was an attempt to address a concern from the University that one reason for undergraduate non-continuation was a lack of preparation for the mathematical components of students\u2019 degree programmes, particularly those students on non-mathematics degrees within the College of Science and Engineering. Increasingly, the second-semester year 1 \"Calculus and its Applications\" course had been adapted to address these problems. However, staff and students felt that it recently contained too much material. FAC aimed to relieve some of the pressure on this course. FAC was delivered as a completely online course to make it scalable, since the above issues are not unique to the School or the University. FAC plays a role in addressing the so-called \u201cmathematics gap\u201d of attainment, preparing students from a wide range of mathematical backgrounds for HE study, and as such could easily see demand both across the University and beyond.","title":"Introduction"},{"location":"CaseStudies/2019/FAC/#why-use-stack","text":"FAC is essentially a course in mathematical techniques, assessing routine computation. STACK precisely lets teachers assess such questions automatically and give tailored feedback to students. Quite sophisticated questions can be implemented, for example \u201cgive an example\u201d type questions, asking students to provide examples of e.g. a quadratic with given roots, or a sequence with certain monotonicity or boundedness properties. These are important for \"retrieval practice\", that is, encouraging students to recall previous topics.","title":"Why Use STACK?"},{"location":"CaseStudies/2019/FAC/#execution","text":"The course is worth 10 ECTS credits, and consists of approximately 200 hours of work for the student. The course is delivered in ten weekly units, each comprising a number of quizzes intended for students to work through during that week. Each week ends with a 90-minute \"Practice Quiz\" the student can take an unlimited number of times, and a 90-minute \"Final Test\" only allowing one attempt. The test is either given a grade of fail (0-80%), mastery (80-95%) or distinction (95%-100%). The high pass mark encourages students to master a topic before moving on. The final grade is determined by combining the results of the 10 \"Final Tests\" (worth 80%) with a final 2-hour test covering the whole course (worth 20%). The development involved a substantial up-front time investment: writing the material in these quizzes, including over 900 STACK questions. Although some existing questions were borrowed from other courses, the majority of these questions were authored from scratch. The quizzes interleave textbook-style exposition with videos of worked examples, interactive applets and practice questions, and as a result, the questions have a polished and varied look. Two lecturers were involved, each responsible for five units, with final cross-checking and occasional extra contributions.","title":"Execution"},{"location":"CaseStudies/2019/FAC/#research","text":"Figure: A FAC question aimed at both retrieval practice and building a strong example space. The design of the course was heavily influenced by educational research. Firstly, the course uses \"faded worked examples\", that is, presenting a sequence of problems with different amounts of the solution already worked out. For example, a topic might begin with a full worked solution of a problem, followed by a worked solution with the final step as a STACK input, followed by a worked solution with the last two steps as STACK input, and so on. There is evidence that this is helpful for students [2]. Additionally, given the literature on the importance of \"retrieval practice\" [3], FAC gives plenty of chances for students to recall what they have learned, for example by having quizzes draw on skills from previous weeks. Weeks alternate between algebra and calculus, spacing out practice of the two topics. Furthermore, the lecturers decided not to make feedback for the final tests available to students until after the deadline, since there is evidence suggesting delaying feedback is helpful for learning [5]. Finally, FAC gives students a chance to create strong \"example spaces\" [4], that is, sets of examples that a student can recall for a given topic. Example spaces are developed through \"give-an-example\" style questions, which are easy to write in STACK.","title":"Research"},{"location":"CaseStudies/2019/FAC/#visuals","text":"FAC uses a lot of graphs and interactive applets to make questions visually appealing. Visual intuition is an important part of learning about functions, so it is appropriate for graphical components to play a significant part in this course. FAC uses both JSX graphs (which can be coded directly in STACK) and external plugins, like GeoGebra. The advantage of JSX graphs is that they are self-contained; there is no need to worry about changes to external programs, or licensing rights. There is, however, a large cost-benefit analysis to consider. JSX graphs are time-consuming and have a steep learning curve, while external applets are often quick to set up and have simple drag-and-drop features. Figure: FAC uses graphs and other visuals to aid learning.","title":"Visuals"},{"location":"CaseStudies/2019/FAC/#results","text":"The six hundred students taking the first-semester year 1 \"Introduction to Linear Algebra\" course sat a diagnostic test (also delivered through STACK) in September 2018. In January 2019, the students sat the test again with the same questions but different random variants. In the September test, students also enrolled on FAC scored on average fifteen percentage points lower than their peers. This is not surprising; FAC will have been recommended to students who felt like they needed more practice in mathematics fundamentals. However, in January after studying FAC, they had gained these fifteen percentage points and were scoring in line with their peers. This is quantitative evidence that FAC has done exactly what was hoped: removed the discrepancy in attainment between the two groups of students. The lecturers also wanted to know if taking FAC had improved student performance in other maths courses such as \"Introduction to Linear Algebra\" (ILA) and \"Calculus and its Applications\" (CAP). Of students scoring similarly in the September diagnostics test, students who took FAC were scoring better than their peers in online quizzes for CAP. They also scored at a similar level to students who did not take FAC in the exams for ILA and CAP. Figure: Diagnostic results in September (pre) and January (post).","title":"Results"},{"location":"CaseStudies/2019/FAC/#challenges","text":"While it is true that authoring a simple STACK question is ultimately straightforward, there was nonetheless a technological hurdle to be cleared. One lecturer was entirely new not only to STACK, but to Maxima and any form of online assessment, and therefore was confronted with quite an intimidating prospect. However, they ended up authoring hundreds of questions without trouble, and are now confident in undertaking significantly more demanding questions. This hurdle was easier to overcome given STACK requires no programming expertise. The lecturers were mindful of the possibility that students could be working through assessed quizzes in one browser tab, with a tool like WolframAlpha open in another. While ultimately this does no benefit to the student, and it remains their responsibility to ensure submitted answers are their own work, the potential of this kind of abuse should be minimised. This just required a bit of cunning at the level of question-setting: turning \u201cfind the derivative of this given function at this given point\u201d into \u201cat what point is the value of the derivative of this given function this given number?\u201d The limitations of an online course include the difficulties of forming meaningful staff-student and student-student interaction. The lack of real staff-student interaction made it hard to gauge whether the level and volume of material was suitable \u2013 anecdotal feedback indicates this was misjudged in at least one of the weekly units. Student-student interaction is important to foster a sense of community. This was addressed by setting up \u201cautonomous learning groups\u201d in which the students could study, in person, once a week, without staff input. Furthermore, students could ask questions in the online forum Piazza, and get in-person help in the MathsBase study room if needed.","title":"Challenges"},{"location":"CaseStudies/2019/FAC/#enablers","text":"The University had created a dedicated learning-technologist post to help design the online assessment and write STACK questions. Their work was invaluable for authoring some of the questions, often given only a one-line sketch of the desired question. The capacity in STACK to clone questions and export questions from other courses was also very useful, making it possible to produce multiple related questions, sharing, for example, a grading structure, without duplicating any work. Finally, it was an advantage that there is substantial \u201cin-house\u201d support at the University, since STACK is now used across the entire first-year curriculum and increasingly beyond. Hence, there are a number of members of staff with experience of authoring questions, and the students are familiar with it.","title":"Enablers"},{"location":"CaseStudies/2019/FAC/#whats-next","text":"A lot of data has been collected in FAC's first year. Quiz responses will be analysed to determine if any questions should be modified. There are also plans to have interviews with students on the effectiveness of the course, which will help identify areas that need work. The course organiser will be looking at improving the \"autonomous learning groups\". Since groups were given weekly tasks and asked to upload solutions to a shared Dropbox, the lecturers can see how much students interacted with these groups. Initially, the engagement was very strong, but half-way through the course, a lot of groups seemed to stop meeting. The course organiser will look at ways to improve turnout for these groups. The course continues to be worked on. The lecturers are considering options for more interactive questions, for example using equivalence reasoning to assess line-by-line arguments, or interactive JSX graphs that ask a student to, for example, \"drag a vector so it is perpendicular to another vector\". The success of FAC paves the way for similar methods to be used in different courses. Other schools have shown interest in creating similar online courses, and some students may find it helpful to have an online course teaching even less advanced maths.","title":"What's Next?"},{"location":"CaseStudies/2019/FAC/#references","text":"[1] George Kinnear. Delivering an online course using STACK. In Proceedings of the STACK Conference, 2018. [2] A. Renkl, R. K. Atkinson, U. H. Maier, and R. Staley. From Example Study to Problem Solving: Smooth Transitions Help Learning. The Journal of Experimental Education, 70(4):293-315, 2002. [3] H. L. Roediger and A. C. Butler. The critical role of retrieval practice in longterm retention. Trends in Cognitive Sciences, 15(1):20-27, 2011. [4] P. Goldenberg and J. Mason. Shedding light on and with example spaces. Educational Studies in Mathematics, 65(2):183-194, 2008. [5] H. G. Mullet, A. C. Butler, B. Verdin, R. Borries, and E. J. Marsh. Delaying feedback promotes transfer of knowledge despite student preferences to receive feedback immediately. Journal of Applied Research in Memory and Cognition, 3(3):222-229, 2014. Extra-Occupational Bridging Courses STACK for a Physics Textbook","title":"References"},{"location":"CaseStudies/2019/FlickInterface/","text":"A Flick Interface for Maths Input Graduate School of Informatics, Nagoya University, Japan Yasuyuki Nakamura Sangensha LLC., Japan Takahiro Nakahara Abstract Typing mathematical expressions into mobile devices can be time-consuming. To solve this problem, developers at Nagoya University are developing a \"flick interface\" for STACK, similar to the popular Japanese keyboard mode. Students can pick a common integer or variable and flick in a direction to quickly turn, for example, x into \\sqrt(x) . A survey of usability suggests students prefer this input type to their traditional keyboard. Motivation As smartphones become increasingly used in schools and universities, it is important to find a reliable way to input mathematical expressions. Inputting mathematics on a computer is not a problem, but on smartphones and other mobile devices it can be much more time-consuming. For example, to type an answer to the question \"Expand (x+2)(x+3)\", students have to enter the expression x^2+5*x+6 into the answer space. On a mobile device, this requires several switches between the alphabetical and numerical views of the keyboard, resulting in 19 key touches for this simple answer. Recently, a flick keyboard for Japanese characters has become very popular in Japan, especially amongst young students. Japanese has three character systems. Hiragana is mostly used for simple and native Japanese words, katakana mostly for foreign words and kanji for all other words. The keyboard shows only a limited number of hiragana[^hiragana] characters, but students can hold and \"flick\" on a key to choose a similar character. Characters are grouped together by sound, for example grouping together na, ni, nu, ne and no. The keyboard will then suggest related kanji and/or katakana characters that share similar sounds. It was the popularity of this keyboard that motivated the developers to create a similar interface for inputting mathematics, as a STACK input type. Execution Figure: The flick interface in action. The flick interface was developed by Yasuyuki Nakamura and Takahiro Nakahara, funded by a grant from the Japan Society for the Promotion of Science. Like the Japanese character keyboard, students are faced with a small set of common inputs. Students can switch between numerical values and common variables by pressing \"123\" and \"xy\", respectively, or see a full keyboard view by clicking the keyboard logo. Pressing on a number reveals some common manipulations, and students can then flick in one direction to turn, for example, \"2\" into \"2x\". The input is compatible with normal keyboards, and will automatically be selected for the type of device being used. The interface is programmed in JavaScript to minimise the dependency on mobile device operating systems. The interface uses MathDox to describe expressions, and the input is then converted to the Maxima format by a conversion filter previously created by the developers. Developing an interface suitable for all different screen sizes was one of the biggest challenges of the project, but now the interface is suitable for most devices of sizes around 5-6 inches. Results The flick interface is estimated to significantly reduce the number of keypresses required to type an expression. The following table shows an estimated comparison for a few common expressions [1]. Mathematical expression Direct input taps Flick input taps x^2+5x+6 19 8 3x^2-\\frac{2x}{(x^2+1)^2} 36 13 2x \\cos(x^2) 23 7 Table: A comparison of the number of taps needed to type an expression. To analyse the usability of the interface, the developers conducted a usability test at Nagoya University, Japan. 29 students where asked to enter five common maths expressions by using both a traditional keyboard and the new flick input keyboard. After they entered these math expressions, they were given a survey on usability and satisfaction levels. The survey questions were based on the following five parameters, originally from Jakob Nielsen\u2019s five goals of usability [2]: learnability, efficiency, difficulty or ease in making corrections, rememberability, and the intent to reuse. For each parameter, students were asked to give each input type a score from 0.0 to 5.0. The following table shows the results [1], including both the averages, as well as the standard deviations in parentheses. The survey suggests that the usability and satisfaction levels are higher when the flick input method is used to enter mathematical expressions, rather than the direct input method. Question Direct input score Flick input score It is easy to learn how to input math. 3.0 (1.2) 3.5 (1.0) I can input math quickly and easily. 2.6 (1.1) 3.2 (1.3) It is not confusing and easy to correct. 3.0 (1.2) 3.1 (1.1) I remember the method that I learnt at the rehearsal. 3.0 (1.1) 3.1 (1.1) I will use this method to input math the next time 2.9 (1.3) 3.2 (1.4) Table: Responses from the interface survey. Standard deviations are given in parentheses. What's Next? The next step for the developers is to merge the flick interface into STACK as a new input type. This will include refactoring the flick interface code and working with STACK developers to best implement it into the question type. References [1] Y. Nakamura and T. Nakahara. A new mathematics input interface with flick operation for mobile devices. 15(2), 2017. [2] J. Nielsen. Usability Engineering. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1993. Adaptive Self-learning Exercises Innovating Education in Maseno, Kenya","title":"A Flick Interface for Maths Input"},{"location":"CaseStudies/2019/FlickInterface/#a-flick-interface-for-maths-input","text":"","title":"A Flick Interface for Maths Input"},{"location":"CaseStudies/2019/FlickInterface/#graduate-school-of-informatics-nagoya-university-japan","text":"Yasuyuki Nakamura Sangensha LLC., Japan Takahiro Nakahara","title":"Graduate School of Informatics, Nagoya University, Japan"},{"location":"CaseStudies/2019/FlickInterface/#abstract","text":"Typing mathematical expressions into mobile devices can be time-consuming. To solve this problem, developers at Nagoya University are developing a \"flick interface\" for STACK, similar to the popular Japanese keyboard mode. Students can pick a common integer or variable and flick in a direction to quickly turn, for example, x into \\sqrt(x) . A survey of usability suggests students prefer this input type to their traditional keyboard.","title":"Abstract"},{"location":"CaseStudies/2019/FlickInterface/#motivation","text":"As smartphones become increasingly used in schools and universities, it is important to find a reliable way to input mathematical expressions. Inputting mathematics on a computer is not a problem, but on smartphones and other mobile devices it can be much more time-consuming. For example, to type an answer to the question \"Expand (x+2)(x+3)\", students have to enter the expression x^2+5*x+6 into the answer space. On a mobile device, this requires several switches between the alphabetical and numerical views of the keyboard, resulting in 19 key touches for this simple answer. Recently, a flick keyboard for Japanese characters has become very popular in Japan, especially amongst young students. Japanese has three character systems. Hiragana is mostly used for simple and native Japanese words, katakana mostly for foreign words and kanji for all other words. The keyboard shows only a limited number of hiragana[^hiragana] characters, but students can hold and \"flick\" on a key to choose a similar character. Characters are grouped together by sound, for example grouping together na, ni, nu, ne and no. The keyboard will then suggest related kanji and/or katakana characters that share similar sounds. It was the popularity of this keyboard that motivated the developers to create a similar interface for inputting mathematics, as a STACK input type.","title":"Motivation"},{"location":"CaseStudies/2019/FlickInterface/#execution","text":"Figure: The flick interface in action. The flick interface was developed by Yasuyuki Nakamura and Takahiro Nakahara, funded by a grant from the Japan Society for the Promotion of Science. Like the Japanese character keyboard, students are faced with a small set of common inputs. Students can switch between numerical values and common variables by pressing \"123\" and \"xy\", respectively, or see a full keyboard view by clicking the keyboard logo. Pressing on a number reveals some common manipulations, and students can then flick in one direction to turn, for example, \"2\" into \"2x\". The input is compatible with normal keyboards, and will automatically be selected for the type of device being used. The interface is programmed in JavaScript to minimise the dependency on mobile device operating systems. The interface uses MathDox to describe expressions, and the input is then converted to the Maxima format by a conversion filter previously created by the developers. Developing an interface suitable for all different screen sizes was one of the biggest challenges of the project, but now the interface is suitable for most devices of sizes around 5-6 inches.","title":"Execution"},{"location":"CaseStudies/2019/FlickInterface/#results","text":"The flick interface is estimated to significantly reduce the number of keypresses required to type an expression. The following table shows an estimated comparison for a few common expressions [1]. Mathematical expression Direct input taps Flick input taps x^2+5x+6 19 8 3x^2-\\frac{2x}{(x^2+1)^2} 36 13 2x \\cos(x^2) 23 7 Table: A comparison of the number of taps needed to type an expression. To analyse the usability of the interface, the developers conducted a usability test at Nagoya University, Japan. 29 students where asked to enter five common maths expressions by using both a traditional keyboard and the new flick input keyboard. After they entered these math expressions, they were given a survey on usability and satisfaction levels. The survey questions were based on the following five parameters, originally from Jakob Nielsen\u2019s five goals of usability [2]: learnability, efficiency, difficulty or ease in making corrections, rememberability, and the intent to reuse. For each parameter, students were asked to give each input type a score from 0.0 to 5.0. The following table shows the results [1], including both the averages, as well as the standard deviations in parentheses. The survey suggests that the usability and satisfaction levels are higher when the flick input method is used to enter mathematical expressions, rather than the direct input method. Question Direct input score Flick input score It is easy to learn how to input math. 3.0 (1.2) 3.5 (1.0) I can input math quickly and easily. 2.6 (1.1) 3.2 (1.3) It is not confusing and easy to correct. 3.0 (1.2) 3.1 (1.1) I remember the method that I learnt at the rehearsal. 3.0 (1.1) 3.1 (1.1) I will use this method to input math the next time 2.9 (1.3) 3.2 (1.4) Table: Responses from the interface survey. Standard deviations are given in parentheses.","title":"Results"},{"location":"CaseStudies/2019/FlickInterface/#whats-next","text":"The next step for the developers is to merge the flick interface into STACK as a new input type. This will include refactoring the flick interface code and working with STACK developers to best implement it into the question type.","title":"What's Next?"},{"location":"CaseStudies/2019/FlickInterface/#references","text":"[1] Y. Nakamura and T. Nakahara. A new mathematics input interface with flick operation for mobile devices. 15(2), 2017. [2] J. Nielsen. Usability Engineering. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1993. Adaptive Self-learning Exercises Innovating Education in Maseno, Kenya","title":"References"},{"location":"CaseStudies/2019/ILIAS/","text":"Technical Integration of STACK into ILIAS Innovation in Learning Institute Interview with Fred Neumann and Jesus Copado Abstract STACK was integrated into the ILIAS learning management system to support projects for learning content. This was done by creating an integrated question type directly in ILIAS. The biggest challenges were decoupling the dependencies on Moodle, and an increasing number of user queries following a quickly growing community. Motivation ILIAS is one of the most popular Learning Management Systems (LMS) used in German universities. It has been available under an open-source license since 2000, and since then has grown in popularity in a number of countries, especially Germany and Switzerland. In the last decade, the ILIAS community started a special-interest group related to mathematical assessment. The main driver for this was the \"optes\" project, a federally funded project to create open learning content for mathematics and natural science. It was key for this project to have a sophisticated question system that uses CAS to evaluate students' input. In 2013, the group compared different systems for CAS based questions and finally decided to use STACK. STACK was initially built for the learning management system Moodle, and it would not be trivial to implement STACK into ILIAS. A crowd funding initiative was started to port the STACK plugin from Moodle to ILIAS, and the Innovation in Learning Institute at the Friedrich-Alexander-University Erlangen-Nuremberg (FAU) was asked to implement and maintain it. This would also be an advantage to FAU, as it could then establish STACK as an innovative element of e-learning and e-assessment at the University. Execution It was important to create an integrated question type that works like all the others in ILIAS, instead of trying to dynamically connect a separate STACK platform to ILIAS. Initially, a 2-day meeting with lead STACK developer Chris Sangwin was held at Loughborough University in December 2013, where the basic architecture and principles of the question type were laid out. In the following months, the ILIAS question type was created. The developers set up a Moodle installation with STACK, examined the code and analysed how it works. Then the \u2018library-like\u2019 Moodle core was extracted and integrated into the template of an ILIAS question plugin. The techniques used followed the open source nature of STACK and were supported by the fact that STACK uses the same technology (PHP/mySQL) as ILIAS. Initially, the only way to add questions was to create them in Moodle, then import the moodleXML file into ILIAS. However, authoring provisions and an authoring interface were later created in ILIAS, using the GUI classes. Results From the beginning, the ILIAS community has shown a great interest in using the integration of STACK. To date, nine separate institutions have participated in the crowd funding of the plugin. Over time, several workshops have been organized by the community. A German user manual and workshops to teach the creation of STACK questions was created at FAU and ported to an online module by the University of G\u00f6ttingen. In 2018, the first international STACK conference was held at the Innovation in Learning Institute, bringing together around 65 participants from the Moodle and ILIAS communities. As hoped, STACK is now being used extensively at FAU for innovative e-assessment. The ILIAS installation at FAU contains around 3000 questions from over 100 different authors. Additionally, a local \u2018STACK user group\u2019 was founded with 40 members from various disciplines, including mathematics, natural sciences, engineering, and economics. Based on external and internal funding, it is possible to permanently provide new major versions of the plugin for each major ILIAS release every year, as well as several minor bug fix versions in between. The core of STACK used by the plugin is also updated every year. The ILIAS questions are fully compatible with the Moodle version and can be exchanged between the two Learning Management Systems through the moodleXML format. Figure: A typical ILIAS question about simplification.. Challenges The biggest challenge for the initial integration of STACK into ILIAS was the decoupling of all dependencies from Moodle in the STACK core. Currently, around 50 patches are maintained for that. Furthermore, there were major differences in ILIAS and Moodle regarding the definition and display of feedback and various test player options. The completely different GUIs of Moodle and ILIAS meant the whole authoring interface of STACK had to be redesigned. When the community of STACK users in ILIAS grew, the number of bug reports related to exotic edge cases of STACK usage also grew. This could, for example, be issues relating to questions with a huge number of inputs. Furthermore, an increasing community of users brought in very different opinions about the styles of a question, its validation and feedback. Dealing with these issues was a significant challenge. A barrier that had to be evaluated is time. The initial work in integrating STACK into ILIAS took significant effort, and the project has to be continually maintained as bug fixes and project features are applied. It is estimated that, on average, 70% of a full-time employee's time is required to maintain the STACK developments for ILIAS. This is currently partially funded by the ILIAS community and the Innovation in Learning Institute. Server performance was an issue when it came to using STACK in large institutions. Maxima was designed as a desktop application, and so lacks a set of \u201cgood practice\u201d recommendations for hardware and configuration options depending on the expected load. To solve this, there are some initiatives such as the GoMaxima project from HAW Hamburg and an initiative at the University of G\u00f6ttingen for a docker swarm of Maxima pools. Enablers The meeting with the lead STACK developer was a major help in getting the project off on the right track. The comprehensive STACK documentation was also invaluable for understanding the question type. Additionally, the support from the ILIAS special interest group was invaluable. This group helped sketch the authoring interface in ILIAS, write documentation and organise the first workshops. It also helped moderate the discussion of feature requests from the ILIAS community and organise crowd funding for the maintenance of the plugin. Furthermore, since the Innovation in Learning Institution is not a mathematics institution, it was invaluable to get help from mathematicians to write good demonstration questions. Finally, the port was supported by the common technology of ILIAS and STACK and the fact Moodle and ILIAS have very similar quiz structures, and both treat STACK as a question plugin type. Implementation differences aside, the main principles are the same. What's Next? The ILIAS question type will continue to be updated as STACK, Moodle and ILIAS get updated. In particular, the way question types in ILIAS are implemented will change in a future ILIAS patch, which means the question type will have to be adapted accordingly. There are also plans to make STACK less dependent on the Moodle library. If this is successful, the ILIAS plugin will have to be largely rewritten (since it depends on the Moodle library), however the developers are optimistic. From writing the question type the first time around, they have gained invaluable experience. Furthermore, the authoring interface will not have to be rewritten. There are many wishes from the ILIAS community for new features to be implemented. Some of these are step-wise feedback, as well as more control of the feedback style, for example the colour of feedback boxes. These may be added to the STACK question type in the future. Finally, the maintenance relies heavily on crowdfunding managed between institutions (typically the Innovation in Learning Institution and another University). This means contracts have to be written between the heads of each institution, which can be difficult to manage. There are therefore considerations to transfer the maintenance of the question type to an ILIAS service provider, as it would then be easier to get crowdfunding contracts from Universities. optes: Optimising Self-study With STACK STACK at Scale: The Open University","title":"Technical Integration of STACK into ILIAS"},{"location":"CaseStudies/2019/ILIAS/#technical-integration-of-stack-into-ilias","text":"","title":"Technical Integration of STACK into ILIAS"},{"location":"CaseStudies/2019/ILIAS/#innovation-in-learning-institute","text":"Interview with Fred Neumann and Jesus Copado","title":"Innovation in Learning Institute"},{"location":"CaseStudies/2019/ILIAS/#abstract","text":"STACK was integrated into the ILIAS learning management system to support projects for learning content. This was done by creating an integrated question type directly in ILIAS. The biggest challenges were decoupling the dependencies on Moodle, and an increasing number of user queries following a quickly growing community.","title":"Abstract"},{"location":"CaseStudies/2019/ILIAS/#motivation","text":"ILIAS is one of the most popular Learning Management Systems (LMS) used in German universities. It has been available under an open-source license since 2000, and since then has grown in popularity in a number of countries, especially Germany and Switzerland. In the last decade, the ILIAS community started a special-interest group related to mathematical assessment. The main driver for this was the \"optes\" project, a federally funded project to create open learning content for mathematics and natural science. It was key for this project to have a sophisticated question system that uses CAS to evaluate students' input. In 2013, the group compared different systems for CAS based questions and finally decided to use STACK. STACK was initially built for the learning management system Moodle, and it would not be trivial to implement STACK into ILIAS. A crowd funding initiative was started to port the STACK plugin from Moodle to ILIAS, and the Innovation in Learning Institute at the Friedrich-Alexander-University Erlangen-Nuremberg (FAU) was asked to implement and maintain it. This would also be an advantage to FAU, as it could then establish STACK as an innovative element of e-learning and e-assessment at the University.","title":"Motivation"},{"location":"CaseStudies/2019/ILIAS/#execution","text":"It was important to create an integrated question type that works like all the others in ILIAS, instead of trying to dynamically connect a separate STACK platform to ILIAS. Initially, a 2-day meeting with lead STACK developer Chris Sangwin was held at Loughborough University in December 2013, where the basic architecture and principles of the question type were laid out. In the following months, the ILIAS question type was created. The developers set up a Moodle installation with STACK, examined the code and analysed how it works. Then the \u2018library-like\u2019 Moodle core was extracted and integrated into the template of an ILIAS question plugin. The techniques used followed the open source nature of STACK and were supported by the fact that STACK uses the same technology (PHP/mySQL) as ILIAS. Initially, the only way to add questions was to create them in Moodle, then import the moodleXML file into ILIAS. However, authoring provisions and an authoring interface were later created in ILIAS, using the GUI classes.","title":"Execution"},{"location":"CaseStudies/2019/ILIAS/#results","text":"From the beginning, the ILIAS community has shown a great interest in using the integration of STACK. To date, nine separate institutions have participated in the crowd funding of the plugin. Over time, several workshops have been organized by the community. A German user manual and workshops to teach the creation of STACK questions was created at FAU and ported to an online module by the University of G\u00f6ttingen. In 2018, the first international STACK conference was held at the Innovation in Learning Institute, bringing together around 65 participants from the Moodle and ILIAS communities. As hoped, STACK is now being used extensively at FAU for innovative e-assessment. The ILIAS installation at FAU contains around 3000 questions from over 100 different authors. Additionally, a local \u2018STACK user group\u2019 was founded with 40 members from various disciplines, including mathematics, natural sciences, engineering, and economics. Based on external and internal funding, it is possible to permanently provide new major versions of the plugin for each major ILIAS release every year, as well as several minor bug fix versions in between. The core of STACK used by the plugin is also updated every year. The ILIAS questions are fully compatible with the Moodle version and can be exchanged between the two Learning Management Systems through the moodleXML format. Figure: A typical ILIAS question about simplification..","title":"Results"},{"location":"CaseStudies/2019/ILIAS/#challenges","text":"The biggest challenge for the initial integration of STACK into ILIAS was the decoupling of all dependencies from Moodle in the STACK core. Currently, around 50 patches are maintained for that. Furthermore, there were major differences in ILIAS and Moodle regarding the definition and display of feedback and various test player options. The completely different GUIs of Moodle and ILIAS meant the whole authoring interface of STACK had to be redesigned. When the community of STACK users in ILIAS grew, the number of bug reports related to exotic edge cases of STACK usage also grew. This could, for example, be issues relating to questions with a huge number of inputs. Furthermore, an increasing community of users brought in very different opinions about the styles of a question, its validation and feedback. Dealing with these issues was a significant challenge. A barrier that had to be evaluated is time. The initial work in integrating STACK into ILIAS took significant effort, and the project has to be continually maintained as bug fixes and project features are applied. It is estimated that, on average, 70% of a full-time employee's time is required to maintain the STACK developments for ILIAS. This is currently partially funded by the ILIAS community and the Innovation in Learning Institute. Server performance was an issue when it came to using STACK in large institutions. Maxima was designed as a desktop application, and so lacks a set of \u201cgood practice\u201d recommendations for hardware and configuration options depending on the expected load. To solve this, there are some initiatives such as the GoMaxima project from HAW Hamburg and an initiative at the University of G\u00f6ttingen for a docker swarm of Maxima pools.","title":"Challenges"},{"location":"CaseStudies/2019/ILIAS/#enablers","text":"The meeting with the lead STACK developer was a major help in getting the project off on the right track. The comprehensive STACK documentation was also invaluable for understanding the question type. Additionally, the support from the ILIAS special interest group was invaluable. This group helped sketch the authoring interface in ILIAS, write documentation and organise the first workshops. It also helped moderate the discussion of feature requests from the ILIAS community and organise crowd funding for the maintenance of the plugin. Furthermore, since the Innovation in Learning Institution is not a mathematics institution, it was invaluable to get help from mathematicians to write good demonstration questions. Finally, the port was supported by the common technology of ILIAS and STACK and the fact Moodle and ILIAS have very similar quiz structures, and both treat STACK as a question plugin type. Implementation differences aside, the main principles are the same.","title":"Enablers"},{"location":"CaseStudies/2019/ILIAS/#whats-next","text":"The ILIAS question type will continue to be updated as STACK, Moodle and ILIAS get updated. In particular, the way question types in ILIAS are implemented will change in a future ILIAS patch, which means the question type will have to be adapted accordingly. There are also plans to make STACK less dependent on the Moodle library. If this is successful, the ILIAS plugin will have to be largely rewritten (since it depends on the Moodle library), however the developers are optimistic. From writing the question type the first time around, they have gained invaluable experience. Furthermore, the authoring interface will not have to be rewritten. There are many wishes from the ILIAS community for new features to be implemented. Some of these are step-wise feedback, as well as more control of the feedback style, for example the colour of feedback boxes. These may be added to the STACK question type in the future. Finally, the maintenance relies heavily on crowdfunding managed between institutions (typically the Innovation in Learning Institution and another University). This means contracts have to be written between the heads of each institution, which can be difficult to manage. There are therefore considerations to transfer the maintenance of the question type to an ILIAS service provider, as it would then be easier to get crowdfunding contracts from Universities. optes: Optimising Self-study With STACK STACK at Scale: The Open University","title":"What's Next?"},{"location":"CaseStudies/2019/Loughborough/","text":"Promoting STACK Across Disciplines at Loughborough University Loughborough University Ian Jones Abstract At Loughborough University, STACK has been implemented across many disciplines. Courses are created by module leaders, who prepare paper-based problems, and academics and students who implement these problems in STACK. To promote STACK to lecturers across the University, a showcase module page was developed that makes it easy to navigate and browse good STACK examples across disciplines. Introduction STACK was installed at Loughborough University in 2014. Since then, a programme of development and dissemination led by Loughborough\u2019s Mathematics Education Centre has resulted in widespread use across the University. The University has encouraged multidisciplinary take up beyond the mathematics department, and now 57 modules across six degree programmes include STACK content. STACK is used for assessment in topics including mathematics, business, statistics, chemical engineering, physics and foundation programmes. Execution Initially, questions were developed in conjunction with module leaders. Typically a module leader provided the developers with paper-based problem sheets. The developers, who included academics as well as PhD and undergraduate mathematics students working on projects, adapted the problems into STACK questions. The example below illustrates how the developers paid special attention to making use of STACK\u2019s unique feedback feature to provide personalised feedback to students. Figure: A paper-based question and its STACK equivalent. Alongside development, the STACK content was promoted and disseminated to lecturers across the University via internal workshops. This included workshops to train module leaders in developing their own content. Additionally, a module page was developed, viewable to all teaching staff, that acts as a showcase for STACK content. Figure: The University developed a showcase module page. The showcase module page is designed to be easy to use and navigate, even for beginners. This is because newcomers often find navigating, selecting and exporting questions off-putting. To overcome this, all questions within a topic have been wrapped into a downloadable .zip file, and only a few navigable example questions have been provided. The download screen for business-based STACK questions is shown below. Business questions have been a particular success, and a new project to develop further STACK content for the School of Business and Economics begins in Autumn 2019. Figure: The download screen for a collection of business STACK questions. What's Next? STACK development continues at Loughborough. The University continues to be particularly interested in promoting STACK in areas where it is not commonly used. This development includes developing STACK content for degree programmes beyond mathematics, such as statistics for psychologists, as well as areas within mathematics that are traditionally difficult to assess automatically. A particularly exciting area being explored is assessing proof comprehension, and an example prototype question is shown below. Figure: A STACK question assessing some skills in proof comprehension. STACK for Engineering Mathematics and the Abacus Material Bank Institutional Support for STACK in Edinburgh","title":"Promoting STACK Across Disciplines at Loughborough University"},{"location":"CaseStudies/2019/Loughborough/#promoting-stack-across-disciplines-at-loughborough-university","text":"","title":"Promoting STACK Across Disciplines at Loughborough University"},{"location":"CaseStudies/2019/Loughborough/#loughborough-university","text":"Ian Jones","title":"Loughborough University"},{"location":"CaseStudies/2019/Loughborough/#abstract","text":"At Loughborough University, STACK has been implemented across many disciplines. Courses are created by module leaders, who prepare paper-based problems, and academics and students who implement these problems in STACK. To promote STACK to lecturers across the University, a showcase module page was developed that makes it easy to navigate and browse good STACK examples across disciplines.","title":"Abstract"},{"location":"CaseStudies/2019/Loughborough/#introduction","text":"STACK was installed at Loughborough University in 2014. Since then, a programme of development and dissemination led by Loughborough\u2019s Mathematics Education Centre has resulted in widespread use across the University. The University has encouraged multidisciplinary take up beyond the mathematics department, and now 57 modules across six degree programmes include STACK content. STACK is used for assessment in topics including mathematics, business, statistics, chemical engineering, physics and foundation programmes.","title":"Introduction"},{"location":"CaseStudies/2019/Loughborough/#execution","text":"Initially, questions were developed in conjunction with module leaders. Typically a module leader provided the developers with paper-based problem sheets. The developers, who included academics as well as PhD and undergraduate mathematics students working on projects, adapted the problems into STACK questions. The example below illustrates how the developers paid special attention to making use of STACK\u2019s unique feedback feature to provide personalised feedback to students. Figure: A paper-based question and its STACK equivalent. Alongside development, the STACK content was promoted and disseminated to lecturers across the University via internal workshops. This included workshops to train module leaders in developing their own content. Additionally, a module page was developed, viewable to all teaching staff, that acts as a showcase for STACK content. Figure: The University developed a showcase module page. The showcase module page is designed to be easy to use and navigate, even for beginners. This is because newcomers often find navigating, selecting and exporting questions off-putting. To overcome this, all questions within a topic have been wrapped into a downloadable .zip file, and only a few navigable example questions have been provided. The download screen for business-based STACK questions is shown below. Business questions have been a particular success, and a new project to develop further STACK content for the School of Business and Economics begins in Autumn 2019. Figure: The download screen for a collection of business STACK questions.","title":"Execution"},{"location":"CaseStudies/2019/Loughborough/#whats-next","text":"STACK development continues at Loughborough. The University continues to be particularly interested in promoting STACK in areas where it is not commonly used. This development includes developing STACK content for degree programmes beyond mathematics, such as statistics for psychologists, as well as areas within mathematics that are traditionally difficult to assess automatically. A particularly exciting area being explored is assessing proof comprehension, and an example prototype question is shown below. Figure: A STACK question assessing some skills in proof comprehension. STACK for Engineering Mathematics and the Abacus Material Bank Institutional Support for STACK in Edinburgh","title":"What's Next?"},{"location":"CaseStudies/2019/Maseno/","text":"Innovating Education in Maseno, Kenya Maseno University, Kenya Santiago Borio, IDEMS Michael Obiero Oyengo, Maseno University Abstract IDEMS International is working with Maseno University to implement online assessment for their mathematics courses. Developers from IDEMS and Maseno University created online quizzes for two courses during the pilot of the project, running on servers at the University of Edinburgh. The main challenges of the project were related to poor student access to WiFi and time pressure for the question authors. The feedback from the students was mostly positive, and the pilot paves the way for more similar work in the future. This includes online assessment for many more courses at Maseno University, as well as collaborations with other African universities and secondary schools. Introduction IDEMS International (Innovations on Development, Education and the Mathematical Sciences) is a Community Interest Company working to support different development causes, mostly in Africa, in fields of education and mathematical sciences. The non-profit organisation generates open education resources and offers services to Universities and other institutions. One of their projects was to help implement Computer Aided Assessment (CAA) in African Universities, of which Maseno University was chosen as a pilot. Maseno University, Kenya, has a large number of students in its undergraduate mathematics courses, many courses having 800 enrolled students and some more than 1000, but there is little support for lecturers in terms of marking. This puts pressure on their ability to reliably do weekly assessments for students. By changing the continuous assessment from a paper format to an electronic system, the hope was that lecturers would have more opportunities to concentrate on their teaching and supporting students in other ways. Figure: Maseno University. Why Use STACK? There were a number of reasons for why STACK was chosen for this project. Firstly, there was already some familiarity with the STACK system within IDEMS, as one of the contributors had previously worked with STACK question authoring. Secondly, the main STACK developer offered assistance, including the opportunity to run the service on servers at the University of Edinburgh. Finally, having compared STACK with other systems, the developers found that the flexibility in answer tests, recognition of mistakes through potential response trees and the ability to have questions that require numerical or algebraic input for answers made STACK more powerful than the alternatives. Execution Figure: A STACK question from \"Calculus I\" involving continuity and L'H\u00f4pital's rule. The developers from IDEMS and Maseno University created online STACK quizzes for the courses \"Calculus I\" and \"Introduction to Linear Algebra\". In the case of \"Calculus I\", the main lecturer provided a written quiz structure and list of questions, so the main work was just typing these into STACK and implementing randomisation. In contrast, the quizzes of \"Introduction to Linear Algebra\" were written mostly from scratch, only using a few questions from the STACK sample materials. Initially, students are given a syntax quiz to learn the STACK syntax, and then in each of the following 10 weeks they are given a formative \"mastery quiz\" and a summative \"test quiz\". The mastery quiz can be taken as many times as the students wants, but they must get a score of 80% in the mastery quiz to unlock the respective test quiz, where students are only given one attempt. In \"Introduction to Linear Algebra\", this restriction was later reduced to 70%, as lecturers felt students were having a hard time keeping up with materials. The mastery and test quizzes together count for 30% of the students course grade. Towards the end of the course there is also a review week with STACK questions, and in \"Introduction to Linear Algebra\" students can take an online practice exam. Feedback After the first year, the students of the two courses were asked to fill out a survey about their experience with STACK. The first few questions regarded accessing the course. Maseno University does not have reliable WiFi, and it is not common for students' accommodation to have WiFi either. As a result, most students had to use either their own or a friends' phone, and purchase a data package to access the course. Indeed, when asked to rate the difficulty of different aspects, many students ranked \"accessing the internet\" in the range of \"slightly challenging\" to \"very challenging\". Figure: Responses to the survey for \"Introductory Linear Algebra\". When asked to rate how helpful they found different aspects of the assessments, many students ranked getting feedback, being able to have multiple attempts at mastery quizzes, having weekly quizzes and having the mastery quizzes open all semester as useful. Most students did not seem to have too much difficulty with the STACK syntax, ranking it in a range of \"not a challenge\" to \"moderately challenging\". This was surely helped by the attempts to ensure students were learning the syntax, for example through the introductory syntax quiz. However, it also seems there is room for improvement here. The students were also given an opportunity to add any general comments or suggestions. The majority of these answers were from students who were happy with STACK and said it was useful for getting a deeper understanding of the material. With regards to quizzes, many students requested more than one attempt at test quizzes, with extended deadlines. They requested more mastery quizzes, suggesting they found them helpful, and some students suggested access to harder, exam-style questions. There were also some comments about the feedback for questions. Due to time constraints, the calculus course only had feedback in the form of worked solutions, and for linear algebra, students were only given outlines to solutions. Students said that they wanted better feedback, and so one of the goals for the next iteration will be to add tailored feedback to all questions. Finally, there was a call to improve accessibility for the visually impaired. Challenges As is evident from the survey responses, there was a challenge regarding the students' access to internet. However, this did not end up being as big a problem as anticipated, as students seemed able and willing to pay for data packages to access the course. Furthermore, due to the short term allocation of courses and lecturers, there was a significant time pressure for writing the quizzes. As a result, there was no time to implement tailored feedback, and a number of quizzes were delivered late. However, this did not seem to discourage students or create major issues in the completion of quizzes. Enablers A major enabler for the project was the ability of IDEMS to assist the University in question authoring. The questions were written by Michael Obiero Oyengo and David Ambogo from Maseno University and Santiago Borio, Danny Parsons and David Stern from IDEMS. Additionally, the main STACK developer C. Sangwin helped give crash courses in using STACK, which sped up the learning process. The course was also run on a server at the University of Edinburgh, which meant the developers did not have to worry about setting up a server and could focus entirely on question authoring. Finally, the STACK sample questions helped speed up the question authoring process, as the developers could use them as templates when writing similar questions. What's Next? Following the success of this pilot course, IDEMS is looking to expand into similar projects. The first step will be improving the two initial courses. Once the analysis of the data from the pilot course is finished, it will be possible to identify the main areas that need work. These two courses have been transferred to an IDEMS server, so they can be easily used for online assessment at other universities. The server will be built to cope with universities with many students, as IDEMS expects to use it for some courses with more than 1000 students. A number of Universities have expressed interest in this project, including universities from Kenya, Ethiopia, Rwanda, Tanzania and Uganda. In particular, the mathematics department at Bahir Dar University, Ethiopia has agreed to investigate implementing a number of IDEMS' courses. In August 2019, IDEMS is holding a workshop , where representatives from these universities will discuss STACK and how to best implement e-assessment at their institutions. The 5-day workshop will include talks on the advantages of using online assessment, as well as practical work to prepare lecturers who want to use IDEMS' online course material. The workshop is funded by a grant from the Commission for Developing Countries (CDC) of the International Mathematical Union. IDEMS is also helping Maseno University create online materials for several of its other courses. In the 19/20 term, Maseno University will run the improved \"Calculus I\", as well as five other courses with online assessment: \"Descriptive Statistics\", \"Introduction to Probability Theory\", \"Basic Mathematics\", \"Calculus II\" and \"Vector Analysis\". For these courses, IDEMS will be training some lecturers to author their own questions, which will increase their control of the online quizzes. As with the two pilot courses, these courses are planned to be piloted at Maseno University first, then refined based on feedback and made available as an OER for other universities. Finally, IDEMS is looking at using STACK in secondary schools. There are plans to develop an e-book for African schools with accompanying STACK questions, including an offline system for schools with poor WiFi. IDEMS is also evaluating opportunities to develop an open assessment system for English schools. A Flick Interface for Maths Input optes: Optimising Self-study With STACK","title":"Innovating Education in Maseno, Kenya"},{"location":"CaseStudies/2019/Maseno/#innovating-education-in-maseno-kenya","text":"","title":"Innovating Education in Maseno, Kenya"},{"location":"CaseStudies/2019/Maseno/#maseno-university-kenya","text":"Santiago Borio, IDEMS Michael Obiero Oyengo, Maseno University","title":"Maseno University, Kenya"},{"location":"CaseStudies/2019/Maseno/#abstract","text":"IDEMS International is working with Maseno University to implement online assessment for their mathematics courses. Developers from IDEMS and Maseno University created online quizzes for two courses during the pilot of the project, running on servers at the University of Edinburgh. The main challenges of the project were related to poor student access to WiFi and time pressure for the question authors. The feedback from the students was mostly positive, and the pilot paves the way for more similar work in the future. This includes online assessment for many more courses at Maseno University, as well as collaborations with other African universities and secondary schools.","title":"Abstract"},{"location":"CaseStudies/2019/Maseno/#introduction","text":"IDEMS International (Innovations on Development, Education and the Mathematical Sciences) is a Community Interest Company working to support different development causes, mostly in Africa, in fields of education and mathematical sciences. The non-profit organisation generates open education resources and offers services to Universities and other institutions. One of their projects was to help implement Computer Aided Assessment (CAA) in African Universities, of which Maseno University was chosen as a pilot. Maseno University, Kenya, has a large number of students in its undergraduate mathematics courses, many courses having 800 enrolled students and some more than 1000, but there is little support for lecturers in terms of marking. This puts pressure on their ability to reliably do weekly assessments for students. By changing the continuous assessment from a paper format to an electronic system, the hope was that lecturers would have more opportunities to concentrate on their teaching and supporting students in other ways. Figure: Maseno University.","title":"Introduction"},{"location":"CaseStudies/2019/Maseno/#why-use-stack","text":"There were a number of reasons for why STACK was chosen for this project. Firstly, there was already some familiarity with the STACK system within IDEMS, as one of the contributors had previously worked with STACK question authoring. Secondly, the main STACK developer offered assistance, including the opportunity to run the service on servers at the University of Edinburgh. Finally, having compared STACK with other systems, the developers found that the flexibility in answer tests, recognition of mistakes through potential response trees and the ability to have questions that require numerical or algebraic input for answers made STACK more powerful than the alternatives.","title":"Why Use STACK?"},{"location":"CaseStudies/2019/Maseno/#execution","text":"Figure: A STACK question from \"Calculus I\" involving continuity and L'H\u00f4pital's rule. The developers from IDEMS and Maseno University created online STACK quizzes for the courses \"Calculus I\" and \"Introduction to Linear Algebra\". In the case of \"Calculus I\", the main lecturer provided a written quiz structure and list of questions, so the main work was just typing these into STACK and implementing randomisation. In contrast, the quizzes of \"Introduction to Linear Algebra\" were written mostly from scratch, only using a few questions from the STACK sample materials. Initially, students are given a syntax quiz to learn the STACK syntax, and then in each of the following 10 weeks they are given a formative \"mastery quiz\" and a summative \"test quiz\". The mastery quiz can be taken as many times as the students wants, but they must get a score of 80% in the mastery quiz to unlock the respective test quiz, where students are only given one attempt. In \"Introduction to Linear Algebra\", this restriction was later reduced to 70%, as lecturers felt students were having a hard time keeping up with materials. The mastery and test quizzes together count for 30% of the students course grade. Towards the end of the course there is also a review week with STACK questions, and in \"Introduction to Linear Algebra\" students can take an online practice exam.","title":"Execution"},{"location":"CaseStudies/2019/Maseno/#feedback","text":"After the first year, the students of the two courses were asked to fill out a survey about their experience with STACK. The first few questions regarded accessing the course. Maseno University does not have reliable WiFi, and it is not common for students' accommodation to have WiFi either. As a result, most students had to use either their own or a friends' phone, and purchase a data package to access the course. Indeed, when asked to rate the difficulty of different aspects, many students ranked \"accessing the internet\" in the range of \"slightly challenging\" to \"very challenging\". Figure: Responses to the survey for \"Introductory Linear Algebra\". When asked to rate how helpful they found different aspects of the assessments, many students ranked getting feedback, being able to have multiple attempts at mastery quizzes, having weekly quizzes and having the mastery quizzes open all semester as useful. Most students did not seem to have too much difficulty with the STACK syntax, ranking it in a range of \"not a challenge\" to \"moderately challenging\". This was surely helped by the attempts to ensure students were learning the syntax, for example through the introductory syntax quiz. However, it also seems there is room for improvement here. The students were also given an opportunity to add any general comments or suggestions. The majority of these answers were from students who were happy with STACK and said it was useful for getting a deeper understanding of the material. With regards to quizzes, many students requested more than one attempt at test quizzes, with extended deadlines. They requested more mastery quizzes, suggesting they found them helpful, and some students suggested access to harder, exam-style questions. There were also some comments about the feedback for questions. Due to time constraints, the calculus course only had feedback in the form of worked solutions, and for linear algebra, students were only given outlines to solutions. Students said that they wanted better feedback, and so one of the goals for the next iteration will be to add tailored feedback to all questions. Finally, there was a call to improve accessibility for the visually impaired.","title":"Feedback"},{"location":"CaseStudies/2019/Maseno/#challenges","text":"As is evident from the survey responses, there was a challenge regarding the students' access to internet. However, this did not end up being as big a problem as anticipated, as students seemed able and willing to pay for data packages to access the course. Furthermore, due to the short term allocation of courses and lecturers, there was a significant time pressure for writing the quizzes. As a result, there was no time to implement tailored feedback, and a number of quizzes were delivered late. However, this did not seem to discourage students or create major issues in the completion of quizzes.","title":"Challenges"},{"location":"CaseStudies/2019/Maseno/#enablers","text":"A major enabler for the project was the ability of IDEMS to assist the University in question authoring. The questions were written by Michael Obiero Oyengo and David Ambogo from Maseno University and Santiago Borio, Danny Parsons and David Stern from IDEMS. Additionally, the main STACK developer C. Sangwin helped give crash courses in using STACK, which sped up the learning process. The course was also run on a server at the University of Edinburgh, which meant the developers did not have to worry about setting up a server and could focus entirely on question authoring. Finally, the STACK sample questions helped speed up the question authoring process, as the developers could use them as templates when writing similar questions.","title":"Enablers"},{"location":"CaseStudies/2019/Maseno/#whats-next","text":"Following the success of this pilot course, IDEMS is looking to expand into similar projects. The first step will be improving the two initial courses. Once the analysis of the data from the pilot course is finished, it will be possible to identify the main areas that need work. These two courses have been transferred to an IDEMS server, so they can be easily used for online assessment at other universities. The server will be built to cope with universities with many students, as IDEMS expects to use it for some courses with more than 1000 students. A number of Universities have expressed interest in this project, including universities from Kenya, Ethiopia, Rwanda, Tanzania and Uganda. In particular, the mathematics department at Bahir Dar University, Ethiopia has agreed to investigate implementing a number of IDEMS' courses. In August 2019, IDEMS is holding a workshop , where representatives from these universities will discuss STACK and how to best implement e-assessment at their institutions. The 5-day workshop will include talks on the advantages of using online assessment, as well as practical work to prepare lecturers who want to use IDEMS' online course material. The workshop is funded by a grant from the Commission for Developing Countries (CDC) of the International Mathematical Union. IDEMS is also helping Maseno University create online materials for several of its other courses. In the 19/20 term, Maseno University will run the improved \"Calculus I\", as well as five other courses with online assessment: \"Descriptive Statistics\", \"Introduction to Probability Theory\", \"Basic Mathematics\", \"Calculus II\" and \"Vector Analysis\". For these courses, IDEMS will be training some lecturers to author their own questions, which will increase their control of the online quizzes. As with the two pilot courses, these courses are planned to be piloted at Maseno University first, then refined based on feedback and made available as an OER for other universities. Finally, IDEMS is looking at using STACK in secondary schools. There are plans to develop an e-book for African schools with accompanying STACK questions, including an offline system for schools with poor WiFi. IDEMS is also evaluating opportunities to develop an open assessment system for English schools. A Flick Interface for Maths Input optes: Optimising Self-study With STACK","title":"What's Next?"},{"location":"CaseStudies/2019/PhysicsCurriculum/","text":"STACK for a Physics Textbook Physics Curriculum & Instruction David Hilsen Abstract The commercial textbook publisher, Physics Curriculum & Instruction have developed STACK questions to accompany a Physics textbook [1]. These make significant use of random variants and intermediate problem-solving steps. It was important to have feedback on problem design from academic colleagues, and to have support for significant figures and scientific units in STACK. The question bank will contain 3500 questions by the start of the 2019/20 school year. Motivation Physics Curriculum & Instruction is a Minnesota-based company providing schools with learning resources for Physics. With a lot of open-source options becoming available, putting resources into developing a commercial textbook can carry a significant risk. Physics Curriculum hopes to address this by directing their development efforts towards online physics educational resources. It was important to have a system that allowed them to address the wide variety of needs of instructors and that utilised randomization of numerical values. This makes it nearly impossible to search online for the answer to a particular problem; a major concern for publishers. Execution Figure: A Physics Curriculum question involving intermediate problem-solving steps. A large collection of online STACK questions were developed to accompany the book Physics Fundamentals [1]. Access to the online homework package can be purchased along with the book for an extra fee. The online questions are managed in the online learning environment Physics LE, which runs on Moodle. Moodle was picked for its Enrolment key feature and its Adaptive mode question behaviour that allows students to make multiple question attempts with immediate feedback. The team had four people authoring STACK questions, and two additional people working on Moodle and the cloud servers. Authoring questions required an average of just over one hour per question with a significant portion of that time devoted to quality control and testing. Ultimately the development sums to a significant financial investment, but also one that leaves an end product of high quality. A significant focus in the authoring of questions was on intermediate problem-solving steps, and which ones would be most beneficial to help the student formulate a problem-solving strategy. It was important to go beyond a system in which students simply enters a final numerical value that is marked right or wrong with no additional feedback. The intermediate problem-solving steps used are of the following type: multiple-choice questions, using text or diagrams, checking for understanding and problem-solving approach, input of relevant equations or algebraic expressions, input of intermediate numerical values which need to be calculated to obtain the final answer. Results The service went live in January 2019. Since then, 15 schools, both high schools and colleges, have urchased the online question package. Instructors gave positive feedback, especially appreciating the multiple-part question structure where students are given specific feedback. Barriers Figure: A Physics Curriculum question involving potential energy. Initially, there was no provision in STACK for handling significant figures, and limited support for physical units. This was a big barrier for Physics question authoring, and hence a more robust system was developed for this purpose. Additionally, high school students sometimes struggle with the syntax for equation input, especially those with minimal computer background. This continues to improve within STACK and may not be a concern in the future. Enablers Instructors and colleagues provided feedback from an outside perspective indicating where students might have difficulty. This encouraged the authoring of additional PRT nodes, for example checking for a particular misconception. What's Next? There are many additional schools evaluating the Physics Curriculum online homework system, and additional schools are expected to join. Furthermore, the question bank continues to grow. By the start of the 2019/20 school year, Physics Curriculum plans to have 3500 STACK problems in their system, many of these multiple-part. There are also plans to partner up with OpenStax, a company producing high quality College Physics textbooks, to bring them an affordable online homework solution as well. References [1] V. P. Coletta. Physics Fundamentals. Physics Curriculum and Instruction Inc., Lakeville, Minessota, 2nd edition, 2010. Developing a Fully Online Course Adaptive Self-learning Exercises","title":"STACK for a Physics Textbook"},{"location":"CaseStudies/2019/PhysicsCurriculum/#stack-for-a-physics-textbook","text":"","title":"STACK for a Physics Textbook"},{"location":"CaseStudies/2019/PhysicsCurriculum/#physics-curriculum-instruction","text":"David Hilsen","title":"Physics Curriculum &amp; Instruction"},{"location":"CaseStudies/2019/PhysicsCurriculum/#abstract","text":"The commercial textbook publisher, Physics Curriculum & Instruction have developed STACK questions to accompany a Physics textbook [1]. These make significant use of random variants and intermediate problem-solving steps. It was important to have feedback on problem design from academic colleagues, and to have support for significant figures and scientific units in STACK. The question bank will contain 3500 questions by the start of the 2019/20 school year.","title":"Abstract"},{"location":"CaseStudies/2019/PhysicsCurriculum/#motivation","text":"Physics Curriculum & Instruction is a Minnesota-based company providing schools with learning resources for Physics. With a lot of open-source options becoming available, putting resources into developing a commercial textbook can carry a significant risk. Physics Curriculum hopes to address this by directing their development efforts towards online physics educational resources. It was important to have a system that allowed them to address the wide variety of needs of instructors and that utilised randomization of numerical values. This makes it nearly impossible to search online for the answer to a particular problem; a major concern for publishers.","title":"Motivation"},{"location":"CaseStudies/2019/PhysicsCurriculum/#execution","text":"Figure: A Physics Curriculum question involving intermediate problem-solving steps. A large collection of online STACK questions were developed to accompany the book Physics Fundamentals [1]. Access to the online homework package can be purchased along with the book for an extra fee. The online questions are managed in the online learning environment Physics LE, which runs on Moodle. Moodle was picked for its Enrolment key feature and its Adaptive mode question behaviour that allows students to make multiple question attempts with immediate feedback. The team had four people authoring STACK questions, and two additional people working on Moodle and the cloud servers. Authoring questions required an average of just over one hour per question with a significant portion of that time devoted to quality control and testing. Ultimately the development sums to a significant financial investment, but also one that leaves an end product of high quality. A significant focus in the authoring of questions was on intermediate problem-solving steps, and which ones would be most beneficial to help the student formulate a problem-solving strategy. It was important to go beyond a system in which students simply enters a final numerical value that is marked right or wrong with no additional feedback. The intermediate problem-solving steps used are of the following type: multiple-choice questions, using text or diagrams, checking for understanding and problem-solving approach, input of relevant equations or algebraic expressions, input of intermediate numerical values which need to be calculated to obtain the final answer.","title":"Execution"},{"location":"CaseStudies/2019/PhysicsCurriculum/#results","text":"The service went live in January 2019. Since then, 15 schools, both high schools and colleges, have urchased the online question package. Instructors gave positive feedback, especially appreciating the multiple-part question structure where students are given specific feedback.","title":"Results"},{"location":"CaseStudies/2019/PhysicsCurriculum/#barriers","text":"Figure: A Physics Curriculum question involving potential energy. Initially, there was no provision in STACK for handling significant figures, and limited support for physical units. This was a big barrier for Physics question authoring, and hence a more robust system was developed for this purpose. Additionally, high school students sometimes struggle with the syntax for equation input, especially those with minimal computer background. This continues to improve within STACK and may not be a concern in the future.","title":"Barriers"},{"location":"CaseStudies/2019/PhysicsCurriculum/#enablers","text":"Instructors and colleagues provided feedback from an outside perspective indicating where students might have difficulty. This encouraged the authoring of additional PRT nodes, for example checking for a particular misconception.","title":"Enablers"},{"location":"CaseStudies/2019/PhysicsCurriculum/#whats-next","text":"There are many additional schools evaluating the Physics Curriculum online homework system, and additional schools are expected to join. Furthermore, the question bank continues to grow. By the start of the 2019/20 school year, Physics Curriculum plans to have 3500 STACK problems in their system, many of these multiple-part. There are also plans to partner up with OpenStax, a company producing high quality College Physics textbooks, to bring them an affordable online homework solution as well.","title":"What's Next?"},{"location":"CaseStudies/2019/PhysicsCurriculum/#references","text":"[1] V. P. Coletta. Physics Fundamentals. Physics Curriculum and Instruction Inc., Lakeville, Minessota, 2nd edition, 2010. Developing a Fully Online Course Adaptive Self-learning Exercises","title":"References"},{"location":"CaseStudies/2019/StackAtScale/","text":"STACK at Scale: The Open University The Open University. Tim Lowe, School of Mathematics and Statistics, Tim Hunt, Information Technology. Introduction Figure: The Open University. The Open University is the UK\u2019s largest academic institution. In 2017/18 there were approximately 175,000 students studying with the University, mainly part time, making approximately 65,000 full-time equivalent students. Students combine their study with work, family, caring and other responsibilities. Students study from home, at a distance, guided by the University\u2019s Moodle-based VLE and using a combination of online and printed materials. Students are supported by a tutor who provides individual support to a group of typically 20 students and usually offers a combination of face-to-face and online tutorial support. The School of Mathematics and Statistics offers a number of undergraduate qualifications in mathematics (with a total intake of approximately 1300 each year) and a taught MSc, which is the largest such course in the UK. In addition, students throughout the University can take one or more mathematics modules in support of their main subject of study. There are approximately 13,000 student-module combinations within mathematics and statistics each year. STACK is an ideal tool to support the distance-learning of mathematics, as it enables students to practice key techniques from home whilst receiving immediate feedback on their answers. Students can attempt different randomised variants of questions to support their learning and development. Execution Figure: A typical OU STACK question. STACK was first used in the curriculum in 2014 with the launch of a new introductory calculus module: MST124 \"Essential Mathematics I\", which is currently studied by approximately 2,800 students per year. Since then, STACK has been taken up by many modules at all levels. The main use is for formative \u201cpractice quizzes\u201d allowing students to practice the important techniques taught. At lower levels, it is also used for summative assignments, which both encourage students to use the formative quizzes to prepare for the assignment and practice their mathematics, and help students keep on pace with their study by providing deadlines. At the postgraduate level, a series of linked-STACK questions has been developed to guide students through more complex mathematical arguments in the calculus of variations [1]. The School of Mathematics and Statistics have been supporting colleagues in the School of Engineering and Innovation who use STACK to support their teaching of mathematically-based topics. The School is also using STACK to support students between formal module study, and in preparation for study as a key component of online \u201cRevise and Refresh\u201d support materials. STACK is currently used in at least 10 modules providing at total of 330 CATS credits and reaching over 6,500 students annually. Over one million STACK questions are answered by students each year, which is approximately 18% of all quiz questions answered by OU students. Server STACK is supported by the University Information Technology department as part of the Moodle installation. This consists of 11 load-shared Apache Web Servers supported by 2 MaximaPool servers to service the use of Maxima by STACK. Despite the high level of use, STACK has been robust in performance with no unplanned service outages during the period of use. All question authors are strongly encouraged to include Question tests as part of each STACK question, which helps ensure that the integrity of the questions is maintained over time. Before each STACK upgrade, IT checks the question tests of all STACK questions to ensure none are affected by the upgrade. If any tests fail, the questions are corrected by the appropriate module staff before the upgrade is applied to the live system. Feedback Students\u2019 engagement with the quizzes is often demonstrated by comments posted in online forums, for example questioning details of the worked solution provided. Students are often not content with just being able to answer every question in a quiz, but continue to try to correctly answer the quiz in the minimum time. Student feedback on the use of STACK quizzes has been positive, with many choosing to praise them in the unprompted open comments of the university module feedback survey. Conversely, negative comments are received where a module does not have STACK quizzes. Typical student comments include the following: I do value the practice quizzes because you do get practice, the feedback explanations are very good and detailed. [I] have done two runs of the practice quiz which has made a big difference for me and will become something I will be doing much more as [it] helps so much. I have been doing the practice quiz every morning now for 2 weeks ... I managed 100% on one of the quizzes and over 90% now on all of them so my confidence level is going up! The practice quizzes were excellent and I think absolutely essential for consolidating your understanding of the subject. What's Next The School currently plans to introduce STACK quizzes into additional modules as they are updated. Future plans include extending the use of STACK to further, higher level modules and to expand the use of STACK to support students in checking their preparedness for the study of various modules. References [1] T. W. Lowe and B. M. Mestel. Using STACK to support student learning at masters level: a case study. Teaching Mathematics and its Applications: An International Journal of the IMA, 2019. Technical Integration of STACK Into ILIAS STACK for Engineering Mathematics and the Abacus Material Bank","title":"STACK at Scale: The Open University"},{"location":"CaseStudies/2019/StackAtScale/#stack-at-scale-the-open-university","text":"","title":"STACK at Scale: The Open University"},{"location":"CaseStudies/2019/StackAtScale/#the-open-university","text":"Tim Lowe, School of Mathematics and Statistics, Tim Hunt, Information Technology.","title":"The Open University."},{"location":"CaseStudies/2019/StackAtScale/#introduction","text":"Figure: The Open University. The Open University is the UK\u2019s largest academic institution. In 2017/18 there were approximately 175,000 students studying with the University, mainly part time, making approximately 65,000 full-time equivalent students. Students combine their study with work, family, caring and other responsibilities. Students study from home, at a distance, guided by the University\u2019s Moodle-based VLE and using a combination of online and printed materials. Students are supported by a tutor who provides individual support to a group of typically 20 students and usually offers a combination of face-to-face and online tutorial support. The School of Mathematics and Statistics offers a number of undergraduate qualifications in mathematics (with a total intake of approximately 1300 each year) and a taught MSc, which is the largest such course in the UK. In addition, students throughout the University can take one or more mathematics modules in support of their main subject of study. There are approximately 13,000 student-module combinations within mathematics and statistics each year. STACK is an ideal tool to support the distance-learning of mathematics, as it enables students to practice key techniques from home whilst receiving immediate feedback on their answers. Students can attempt different randomised variants of questions to support their learning and development.","title":"Introduction"},{"location":"CaseStudies/2019/StackAtScale/#execution","text":"Figure: A typical OU STACK question. STACK was first used in the curriculum in 2014 with the launch of a new introductory calculus module: MST124 \"Essential Mathematics I\", which is currently studied by approximately 2,800 students per year. Since then, STACK has been taken up by many modules at all levels. The main use is for formative \u201cpractice quizzes\u201d allowing students to practice the important techniques taught. At lower levels, it is also used for summative assignments, which both encourage students to use the formative quizzes to prepare for the assignment and practice their mathematics, and help students keep on pace with their study by providing deadlines. At the postgraduate level, a series of linked-STACK questions has been developed to guide students through more complex mathematical arguments in the calculus of variations [1]. The School of Mathematics and Statistics have been supporting colleagues in the School of Engineering and Innovation who use STACK to support their teaching of mathematically-based topics. The School is also using STACK to support students between formal module study, and in preparation for study as a key component of online \u201cRevise and Refresh\u201d support materials. STACK is currently used in at least 10 modules providing at total of 330 CATS credits and reaching over 6,500 students annually. Over one million STACK questions are answered by students each year, which is approximately 18% of all quiz questions answered by OU students.","title":"Execution"},{"location":"CaseStudies/2019/StackAtScale/#server","text":"STACK is supported by the University Information Technology department as part of the Moodle installation. This consists of 11 load-shared Apache Web Servers supported by 2 MaximaPool servers to service the use of Maxima by STACK. Despite the high level of use, STACK has been robust in performance with no unplanned service outages during the period of use. All question authors are strongly encouraged to include Question tests as part of each STACK question, which helps ensure that the integrity of the questions is maintained over time. Before each STACK upgrade, IT checks the question tests of all STACK questions to ensure none are affected by the upgrade. If any tests fail, the questions are corrected by the appropriate module staff before the upgrade is applied to the live system.","title":"Server"},{"location":"CaseStudies/2019/StackAtScale/#feedback","text":"Students\u2019 engagement with the quizzes is often demonstrated by comments posted in online forums, for example questioning details of the worked solution provided. Students are often not content with just being able to answer every question in a quiz, but continue to try to correctly answer the quiz in the minimum time. Student feedback on the use of STACK quizzes has been positive, with many choosing to praise them in the unprompted open comments of the university module feedback survey. Conversely, negative comments are received where a module does not have STACK quizzes. Typical student comments include the following: I do value the practice quizzes because you do get practice, the feedback explanations are very good and detailed. [I] have done two runs of the practice quiz which has made a big difference for me and will become something I will be doing much more as [it] helps so much. I have been doing the practice quiz every morning now for 2 weeks ... I managed 100% on one of the quizzes and over 90% now on all of them so my confidence level is going up! The practice quizzes were excellent and I think absolutely essential for consolidating your understanding of the subject.","title":"Feedback"},{"location":"CaseStudies/2019/StackAtScale/#whats-next","text":"The School currently plans to introduce STACK quizzes into additional modules as they are updated. Future plans include extending the use of STACK to further, higher level modules and to expand the use of STACK to support students in checking their preparedness for the study of various modules.","title":"What's Next"},{"location":"CaseStudies/2019/StackAtScale/#references","text":"[1] T. W. Lowe and B. M. Mestel. Using STACK to support student learning at masters level: a case study. Teaching Mathematics and its Applications: An International Journal of the IMA, 2019. Technical Integration of STACK Into ILIAS STACK for Engineering Mathematics and the Abacus Material Bank","title":"References"},{"location":"CaseStudies/2019/optes/","text":"optes: Optimising Self-study With STACK DHBW Mannheim Miriam Weigel, Katja Derr, Reinhold H\u00fcbl Abstract The optes project uses STACK in their pre-course, designed to help students improve their self-studying skills for their first year at university. The tests were developed and maintained at DHBW Mannheim. Here, students take a diagnostic test, and based on their results are given access to various learning modules, comprising text, graphs, animations, examples and exercises. An analysis of data gathered from the first evaluation phase of the project shows that the pre-course is effective at bridging gaps in school knowledge: at-risk students who end up scoring highly in the pre-course show improved performance in their first year mathematics courses. Introduction Students entering higher education are a diverse group and many students have considerable gaps in school knowledge, putting additional pressure on their first year at university. This particularly applies to mathematics, as basic skills in this subject are considered a prerequisite to successfully complete a course in STEM subjects. As a consequence, many universities provide preparatory courses in mathematics, either face-to-face, web-based, or in blended learning scenarios. The joint research project optes , funded by the German Federal Ministry of Education and Research (BMBF), develops and evaluates learning materials and tools that help students \u201crefresh\u201d their basic knowledge in mathematics and support the development of learning strategies. optes stands for \u201cOptimierung der Selbststudiumsphase\u201d, which translates to \"optimisation of the self-study phase\". Over the course of eight years, optes developed a comprehensive web-based pre-course consisting of diagnostic tests, learning modules and concepts for web-based student support, and tested it at the participating universities. The partner universities include Baden-Wuerttemberg Cooperative State University (DHBW) Karlsruhe, DHBW Mannheim, DHBW Mosbach, University of Applied Sciences and Arts Ostwestfalen-Lippe, Universit\u00e4t Hamburg; Cooperating universities: Julius-Maximilians-Universit\u00e4t W\u00fcrzburg, University of Education Heidelberg. Why Use STACK? The project put a strong focus on the development of self-tests that enable learners to apply their knowledge and provide them with meaningful feedback. This required a sophisticated CAA system, especially one that allowed students to enter an algebraic input. Since optes results are published under Creative Commons or General Public licenses, it was also important that the system was open source. To find the most suitable CAA system, the researchers analysed and compared many existing mathematical tools and in 2013, STACK was chosen. One of the reasons for choosing STACK, is that STACK uses the Learning Management System (LMS) Moodle and the Computer Algebra System (CAS) Maxima, both of which are supported by large communities. This gave the researchers confidence that STACK would also be used and developed further. Additionally, STACK is flexible enough to allow researchers to design very different types of mathematical problems. The only barrier was that STACK was not available for the LMS ILIAS at the time, a system widely used in Germany. However a crowd funding initiative was successful in gathering enough funds to implement STACK into ILIAS. Execution The partner university DHBW Mannheim was responsible for the development of tests and self-assessments. Here, a very basic version of the pre-course was implemented in 2013, and based on repeated evaluations, the different tests and learning modules were successively built and improved upon [2]. While some learning resources already existed in the form of printed scripts and paper versions of tests, the complete course material had to be rewritten and typed into ILIAS. In 2019, the course held ten interactive learning modules, with more than 1500 mathematics test items, 140 of which use STACK. Figure 1 shows an overview of the course structure as executed at DHBW Mannheim since 2014. The programme runs in the months leading up to a new semester, and starts with a diagnostic self-test covering the entire pre-course's syllabus. See also recommendations by SEFI mathematics working group [6], and cosh [1]. Depending on their diagnostics test results, students may access the different learning modules. Each course provides text, graphs, animations, examples and exercises, and at the end of each module, students can take a subject-related test consisting of 10 to 15 randomised questions. Students who want additional support can enrol in e-tutored courses, where their learning process is structured and monitored by e-tutors. Students can then discuss problems and test results with peers and e-tutors, and are required to upload completed exercise sheets. During induction week, all participating first year students take a final test at the University\u2019s computer laboratories. Since 2014, more than 2800 students have participated in the diagnostic pre-test and the pre-course at DHBW Mannheim. This corresponds to approximately 560 students per year, which is around 80% of the cohort. Figure: Course design at DHBW Mannheim. While the diagnostic self-test aims at informing learners of their level of knowledge in relation to the curriculum, the self-tests provided in the ten different courses are designed to encourage learners to independently practice their skills. Question Construction Figure 2 shows an example of an optes question in ILIAS. Students can click the checkmark next to the input box to have their answers validated by the system. On top of the question, the student can click to pop-out an explanation of the input syntax. The question is graded by clicking on \u201cR\u00fcckmeldung anfordern\u201d, which means \"Request feedback\". In this example, the student is asked to give an example of a function with three given zeroes. There are no other constraints, and in particular the function can also have more zeroes. The given zeroes are randomly generated, so the student can restart the test to try a variant of the problem with different constants. Figure: An optes question about giving an example of a function with given zeroes. optes questions focus on providing good feedback to students [8]. Feedback incorporates partial marks, if the student for example entered a function with only one or two of the given zeroes, and visuals, by for example graphing the student's answer (in red) against a correct answer (in blue). The student is also shown the value of their function at the three given points and given a model solution. optes questions are great examples of effective use of STACK's feedback features. Figure: Feedback to the example question shown above. Results The major goal of the optes project was to improve students\u2018 self-study abilities in mathematics related subjects. Using data collected from the first evaluations phase of the project, the researchers studied the influence of taking the pre-course on different variables. They found that the biggest factor in study success was a student's previous knowledge and secondary school scores. However, they also found that the pre-course could be very effective at improving first-year performance. Of the students whose performance were at risk, those who scored highly in the pre-course also did better in their first year of study. These were the students with poor prior study success or little domain-related knowledge. Self-test engagement was also found to have significance, as they were related to both pre-course gains and first-year performance. Challenges A major advantage of learning management systems is their ability to provide automated feedback to students. Instructors are hence relieved from the load of marking hundreds of exercises, and students appreciate the immediate response of the system. However, writing feedback for web-based mathematical problems is time-consuming, and these efforts may grow exponentially when the questions have multiple correct answers. To help soften this burden, it is important to share STACK questions, not only across pre-course projects but also across universities and e-learning platforms. Enablers A major enabler for the project was the initiative to integrate STACK into ILIAS. If this crowd funding initiative had failed, optes may have had to choose a less suited CAA system. Furthermore, a lot of institutional support enabled this project. While all resources developed by optes are Open Educational Resources (OER), the implementation of the learning material at third party universities or educational institutions demanded staff and technical infrastructure to install ILIAS and STACK. Staff and technical support helped administer the pre-course and adapt the learning material to each university\u2019s needs. Furthermore, the e-tutor system was enabled by lecturers and older students who took the time to learn to use STACK so they could help pre-course participants as e-tutors. What's Next? Since 2019, the rollout of optes to other universities and institutions has begun, and as more and more lecturers use the optes resources, the STACK community in Germany continues to grow. This community is largely represented by the working group \"Mathe digital\". Lecturers are encouraged to develop and contribute their own questions, resulting in a growing and improving database of available STACK questions. The researchers continue to evaluate the data from the project. When this analysis is finished, it will be possible to better identify the strengths and weaknesses of the course structure. Like all projects funded by the German BMBF programme \"Quality pact for teaching\", optes will be finished by the end of 2020. The developed concepts and course material, however, will be used and developed further at the optes partner universities and at all universities and institutions that share the material. Future plans include incorporating adaptive testing and expanding the work to other subjects and topics, such as mathematics for business and psychology courses. References [1] COSH Cooperation Schule Hochschule. Mindestanforderungskatalog mathematik. 2014. [2] K. Derr. Identifying consistent variables in a heterogeneous data set. Electronic Journal of e-Learning EJEL, 15(1):82-93, 2017. [3] K. Derr, R. Hubl, and M. Z. Ahmed. Prior knowledge in mathematics and study success in engineering. informational value of learner data collected from a web-based pre-course. European Journal of Engineering Education, 10(3):1-16, 2018. [4] C. J. Sangwin and I. Jones. Asymmetry in student achievement on multiple choice and constructed response items in reversible mathematics processes. Educational Studies in Mathematics, 94:205-222, 2017. [5] B. Alpers. A framework for mathematics curricula in engineering education. 2013. [6] M. Weigel, K. Derr, R. H\u007fubl, and T. Podgayetskaya. Stack-aufgaben im formativen eassessment: Einsatzmoglichkeiten des feedbacks. Zenodo, 2019. [7] M. Weigel, K. Derr, R. H\u007fubl, E. Mechelke-Schwede, and T. Podgayetskaya. Inhaltliche und technische aspekte des automatisierten feedback. einsatz des fragetyps stack im formativen eassessment. Beitrage zum Mathematikunterricht 2017, 1185-1192, 2017. Innovating Education in Maseno, Kenya Technical Integration of STACK Into ILIAS","title":"optes: Optimising Self-study With STACK"},{"location":"CaseStudies/2019/optes/#optes-optimising-self-study-with-stack","text":"","title":"optes: Optimising Self-study With STACK"},{"location":"CaseStudies/2019/optes/#dhbw-mannheim","text":"Miriam Weigel, Katja Derr, Reinhold H\u00fcbl","title":"DHBW Mannheim"},{"location":"CaseStudies/2019/optes/#abstract","text":"The optes project uses STACK in their pre-course, designed to help students improve their self-studying skills for their first year at university. The tests were developed and maintained at DHBW Mannheim. Here, students take a diagnostic test, and based on their results are given access to various learning modules, comprising text, graphs, animations, examples and exercises. An analysis of data gathered from the first evaluation phase of the project shows that the pre-course is effective at bridging gaps in school knowledge: at-risk students who end up scoring highly in the pre-course show improved performance in their first year mathematics courses.","title":"Abstract"},{"location":"CaseStudies/2019/optes/#introduction","text":"Students entering higher education are a diverse group and many students have considerable gaps in school knowledge, putting additional pressure on their first year at university. This particularly applies to mathematics, as basic skills in this subject are considered a prerequisite to successfully complete a course in STEM subjects. As a consequence, many universities provide preparatory courses in mathematics, either face-to-face, web-based, or in blended learning scenarios. The joint research project optes , funded by the German Federal Ministry of Education and Research (BMBF), develops and evaluates learning materials and tools that help students \u201crefresh\u201d their basic knowledge in mathematics and support the development of learning strategies. optes stands for \u201cOptimierung der Selbststudiumsphase\u201d, which translates to \"optimisation of the self-study phase\". Over the course of eight years, optes developed a comprehensive web-based pre-course consisting of diagnostic tests, learning modules and concepts for web-based student support, and tested it at the participating universities. The partner universities include Baden-Wuerttemberg Cooperative State University (DHBW) Karlsruhe, DHBW Mannheim, DHBW Mosbach, University of Applied Sciences and Arts Ostwestfalen-Lippe, Universit\u00e4t Hamburg; Cooperating universities: Julius-Maximilians-Universit\u00e4t W\u00fcrzburg, University of Education Heidelberg.","title":"Introduction"},{"location":"CaseStudies/2019/optes/#why-use-stack","text":"The project put a strong focus on the development of self-tests that enable learners to apply their knowledge and provide them with meaningful feedback. This required a sophisticated CAA system, especially one that allowed students to enter an algebraic input. Since optes results are published under Creative Commons or General Public licenses, it was also important that the system was open source. To find the most suitable CAA system, the researchers analysed and compared many existing mathematical tools and in 2013, STACK was chosen. One of the reasons for choosing STACK, is that STACK uses the Learning Management System (LMS) Moodle and the Computer Algebra System (CAS) Maxima, both of which are supported by large communities. This gave the researchers confidence that STACK would also be used and developed further. Additionally, STACK is flexible enough to allow researchers to design very different types of mathematical problems. The only barrier was that STACK was not available for the LMS ILIAS at the time, a system widely used in Germany. However a crowd funding initiative was successful in gathering enough funds to implement STACK into ILIAS.","title":"Why Use STACK?"},{"location":"CaseStudies/2019/optes/#execution","text":"The partner university DHBW Mannheim was responsible for the development of tests and self-assessments. Here, a very basic version of the pre-course was implemented in 2013, and based on repeated evaluations, the different tests and learning modules were successively built and improved upon [2]. While some learning resources already existed in the form of printed scripts and paper versions of tests, the complete course material had to be rewritten and typed into ILIAS. In 2019, the course held ten interactive learning modules, with more than 1500 mathematics test items, 140 of which use STACK. Figure 1 shows an overview of the course structure as executed at DHBW Mannheim since 2014. The programme runs in the months leading up to a new semester, and starts with a diagnostic self-test covering the entire pre-course's syllabus. See also recommendations by SEFI mathematics working group [6], and cosh [1]. Depending on their diagnostics test results, students may access the different learning modules. Each course provides text, graphs, animations, examples and exercises, and at the end of each module, students can take a subject-related test consisting of 10 to 15 randomised questions. Students who want additional support can enrol in e-tutored courses, where their learning process is structured and monitored by e-tutors. Students can then discuss problems and test results with peers and e-tutors, and are required to upload completed exercise sheets. During induction week, all participating first year students take a final test at the University\u2019s computer laboratories. Since 2014, more than 2800 students have participated in the diagnostic pre-test and the pre-course at DHBW Mannheim. This corresponds to approximately 560 students per year, which is around 80% of the cohort. Figure: Course design at DHBW Mannheim. While the diagnostic self-test aims at informing learners of their level of knowledge in relation to the curriculum, the self-tests provided in the ten different courses are designed to encourage learners to independently practice their skills.","title":"Execution"},{"location":"CaseStudies/2019/optes/#question-construction","text":"Figure 2 shows an example of an optes question in ILIAS. Students can click the checkmark next to the input box to have their answers validated by the system. On top of the question, the student can click to pop-out an explanation of the input syntax. The question is graded by clicking on \u201cR\u00fcckmeldung anfordern\u201d, which means \"Request feedback\". In this example, the student is asked to give an example of a function with three given zeroes. There are no other constraints, and in particular the function can also have more zeroes. The given zeroes are randomly generated, so the student can restart the test to try a variant of the problem with different constants. Figure: An optes question about giving an example of a function with given zeroes. optes questions focus on providing good feedback to students [8]. Feedback incorporates partial marks, if the student for example entered a function with only one or two of the given zeroes, and visuals, by for example graphing the student's answer (in red) against a correct answer (in blue). The student is also shown the value of their function at the three given points and given a model solution. optes questions are great examples of effective use of STACK's feedback features. Figure: Feedback to the example question shown above.","title":"Question Construction"},{"location":"CaseStudies/2019/optes/#results","text":"The major goal of the optes project was to improve students\u2018 self-study abilities in mathematics related subjects. Using data collected from the first evaluations phase of the project, the researchers studied the influence of taking the pre-course on different variables. They found that the biggest factor in study success was a student's previous knowledge and secondary school scores. However, they also found that the pre-course could be very effective at improving first-year performance. Of the students whose performance were at risk, those who scored highly in the pre-course also did better in their first year of study. These were the students with poor prior study success or little domain-related knowledge. Self-test engagement was also found to have significance, as they were related to both pre-course gains and first-year performance.","title":"Results"},{"location":"CaseStudies/2019/optes/#challenges","text":"A major advantage of learning management systems is their ability to provide automated feedback to students. Instructors are hence relieved from the load of marking hundreds of exercises, and students appreciate the immediate response of the system. However, writing feedback for web-based mathematical problems is time-consuming, and these efforts may grow exponentially when the questions have multiple correct answers. To help soften this burden, it is important to share STACK questions, not only across pre-course projects but also across universities and e-learning platforms.","title":"Challenges"},{"location":"CaseStudies/2019/optes/#enablers","text":"A major enabler for the project was the initiative to integrate STACK into ILIAS. If this crowd funding initiative had failed, optes may have had to choose a less suited CAA system. Furthermore, a lot of institutional support enabled this project. While all resources developed by optes are Open Educational Resources (OER), the implementation of the learning material at third party universities or educational institutions demanded staff and technical infrastructure to install ILIAS and STACK. Staff and technical support helped administer the pre-course and adapt the learning material to each university\u2019s needs. Furthermore, the e-tutor system was enabled by lecturers and older students who took the time to learn to use STACK so they could help pre-course participants as e-tutors.","title":"Enablers"},{"location":"CaseStudies/2019/optes/#whats-next","text":"Since 2019, the rollout of optes to other universities and institutions has begun, and as more and more lecturers use the optes resources, the STACK community in Germany continues to grow. This community is largely represented by the working group \"Mathe digital\". Lecturers are encouraged to develop and contribute their own questions, resulting in a growing and improving database of available STACK questions. The researchers continue to evaluate the data from the project. When this analysis is finished, it will be possible to better identify the strengths and weaknesses of the course structure. Like all projects funded by the German BMBF programme \"Quality pact for teaching\", optes will be finished by the end of 2020. The developed concepts and course material, however, will be used and developed further at the optes partner universities and at all universities and institutions that share the material. Future plans include incorporating adaptive testing and expanding the work to other subjects and topics, such as mathematics for business and psychology courses.","title":"What's Next?"},{"location":"CaseStudies/2019/optes/#references","text":"[1] COSH Cooperation Schule Hochschule. Mindestanforderungskatalog mathematik. 2014. [2] K. Derr. Identifying consistent variables in a heterogeneous data set. Electronic Journal of e-Learning EJEL, 15(1):82-93, 2017. [3] K. Derr, R. Hubl, and M. Z. Ahmed. Prior knowledge in mathematics and study success in engineering. informational value of learner data collected from a web-based pre-course. European Journal of Engineering Education, 10(3):1-16, 2018. [4] C. J. Sangwin and I. Jones. Asymmetry in student achievement on multiple choice and constructed response items in reversible mathematics processes. Educational Studies in Mathematics, 94:205-222, 2017. [5] B. Alpers. A framework for mathematics curricula in engineering education. 2013. [6] M. Weigel, K. Derr, R. H\u007fubl, and T. Podgayetskaya. Stack-aufgaben im formativen eassessment: Einsatzmoglichkeiten des feedbacks. Zenodo, 2019. [7] M. Weigel, K. Derr, R. H\u007fubl, E. Mechelke-Schwede, and T. Podgayetskaya. Inhaltliche und technische aspekte des automatisierten feedback. einsatz des fragetyps stack im formativen eassessment. Beitrage zum Mathematikunterricht 2017, 1185-1192, 2017. Innovating Education in Maseno, Kenya Technical Integration of STACK Into ILIAS","title":"References"},{"location":"CaseStudies/2020/MINTFIT/","text":"Diagnostics Testing With STACK University of Technology, Hamburg Helena Barbas https://orcid.org/0000-0002-2384-8042 Abstract The MINTFIT Math Test is an online test for high school students, or anyone interested in a university STEM degree programme. It is provided by the MINTFIT project based in the universities HafenCity Universit\u00e4t Hamburg (HCU), Universit\u00e4t Hamburg (UHH), University of Applied Sciences Hamburg (HAW Hamburg), University Medical Center Hamburg-Eppendorf (UKE) and University of Technology Hamburg (TUHH) and funded by the Hamburg Ministry of Science, Research, Equalities and Districts (Beh\u00f6rde f\u00fcr Wissenschaft, Forschung, Gleichstellung und Bezirke Hamburg, BWFGB). The MINTFIT Math Test, as well as the MINTFIT online tests in physics, chemistry and informatics, run on a Moodle system. The STACK plugin offers many benefits to the Math Test, both when used at home and in different university settings. Introduction The MINTFIT Math Test is a free diagnostic online test that lets participants check their mathematics skills for a successful start to a STEM degree programme. It is part of the MINTFIT tests and courses programme on the subjects mathematics, physics, chemistry and informatics, accessible on the MINTFIT platform https://www.mintfit.hamburg/ . Participants get instant feedback on their results after finishing the Math Test. They can then use two online mathematics bridging courses (OMB+ and viaMINT) to fill the gaps in their mathematics knowledge as identified by the test. The MINTFIT Math Test is available in German and in English. For more information see [1]. Figure: After taking the MINTFIT test, students are advised on which topics to revise. STACK offers many advantages in the setting of diagnostics testing for both participants and organisers. A STACK question's potential response tree helps diagnose the errors committed by the participants, as it is possible to compare the entered solution with incorrect solutions that arise from known common mistakes. It is also possible to provide partial credit for partially correct answers, or for errors carried forward. Additionally, it is possible to generate many random variants of a question. If for example, the question is to find the derivative of a polynomial, the system can randomly draw its coefficients from a specified set. Variants that are either too difficult or too easy can then be deleted by hand. At the universities in Hamburg, the MINTFIT Math Test is used in exam-like situations as a part of university entrance tests, a module requirement or as an opportunity to collect bonus points for the first term exams. The possibility to generate different questions of the same difficulty level is invaluable here. Figure: Students are given partial credit for partially correct answers, and specific feedback on their mistakes. Execution The STACK questions in the MINTFIT Math Test were written by a scientific assistant (the author) and a student helper in 2014/2015, supported by an IT assistant. New STACK questions were easily generated by for example copying an existing question with a similar structure and looking up the coding structure of Maxima. This way, with just a small starting set of exemplary questions, it was possible to quickly get comfortable with STACK without any help from other sources or training. The questions in the MINTFIT Math Test can be done by mental arithmetic or by calculating using pen and paper \u2013 a calculator is not necessary and should not be used (neither at home nor in exam-like situations). However, since the general approach of MINTFIT and the Math Test particularly is the voluntariness of its users, participants are not controlled (with the exception of some settings, like the university entrance test, where they are seated in an exam room). However, they are informed before starting the test that their results are representative for their math skills only if they complete it without using a calculator or looking the answers up on a webpage like Wolfram Alpha. About 50 questions in the question pool of the Math Test are implemented with STACK. The MINTFIT Math Test has been accessible since June 2015. Results It is difficult to measure the precise impact of the MINTFIT Math Test on students' study skills. Nonetheless, there is student feedback from a form offered after the test. Of all those who answered the question: \"Do you think that the test is helpful for you or freshmen in general?\", 66% answered with a clear \"yes\". Answers were given in a range from 1 (\"yes\") to 5 (\"absolutely not\"), with a mean response of 1.5. Of all those who answered the question \"Do you feel fairly rated?\", 61% answered \"yes\". With possible answers as in the previous question, this one had a mean answer of 1.62. Challenges The main challenges of using STACK were of technical nature. Keeping up with the updates of Moodle and STACK means you have to keep a close eye on the appearance of the test. Moodle itself offers many possibilities, so one needs time to make the optimal adjustments there. Enablers MINTFIT is a project by the universities HafenCity Universit\u00e4t Hamburg (HCU), Universit\u00e4t Hamburg (UHH), University of Applied Sciences Hamburg (HAW Hamburg), University Medical Center Hamburg-Eppendorf (UKE) and the University of Technology Hamburg (TUHH) in Hamburg, Germany. It is funded by the Hamburg Ministry of Science, Research, Equalities and Districts (Beh\u00f6rde f\u00fcr Wissenschaft, Forschung, Gleichstellung und Bezirke Hamburg, BWFGB). What's Next? The MINTFIT test and courses programme will be completed with regard to the content by the end of 2020. From 2021 on, the service is going to be maintained for current and future applications, and tests and courses will be refined and enhanced. References [1] Barbas, H.; Schramm, T.: The Hamburg Online Math Test MINTFIT for prospective Students of STEM Degree Programs . MSOR Connections, S. 43-51, 2018. Institutional Support for STACK in Edinburgh Extra-Occupational Bridging Courses for Non-Traditional Students","title":"Diagnostics Testing With STACK"},{"location":"CaseStudies/2020/MINTFIT/#diagnostics-testing-with-stack","text":"","title":"Diagnostics Testing With STACK"},{"location":"CaseStudies/2020/MINTFIT/#university-of-technology-hamburg","text":"Helena Barbas https://orcid.org/0000-0002-2384-8042","title":"University of Technology, Hamburg"},{"location":"CaseStudies/2020/MINTFIT/#abstract","text":"The MINTFIT Math Test is an online test for high school students, or anyone interested in a university STEM degree programme. It is provided by the MINTFIT project based in the universities HafenCity Universit\u00e4t Hamburg (HCU), Universit\u00e4t Hamburg (UHH), University of Applied Sciences Hamburg (HAW Hamburg), University Medical Center Hamburg-Eppendorf (UKE) and University of Technology Hamburg (TUHH) and funded by the Hamburg Ministry of Science, Research, Equalities and Districts (Beh\u00f6rde f\u00fcr Wissenschaft, Forschung, Gleichstellung und Bezirke Hamburg, BWFGB). The MINTFIT Math Test, as well as the MINTFIT online tests in physics, chemistry and informatics, run on a Moodle system. The STACK plugin offers many benefits to the Math Test, both when used at home and in different university settings.","title":"Abstract"},{"location":"CaseStudies/2020/MINTFIT/#introduction","text":"The MINTFIT Math Test is a free diagnostic online test that lets participants check their mathematics skills for a successful start to a STEM degree programme. It is part of the MINTFIT tests and courses programme on the subjects mathematics, physics, chemistry and informatics, accessible on the MINTFIT platform https://www.mintfit.hamburg/ . Participants get instant feedback on their results after finishing the Math Test. They can then use two online mathematics bridging courses (OMB+ and viaMINT) to fill the gaps in their mathematics knowledge as identified by the test. The MINTFIT Math Test is available in German and in English. For more information see [1]. Figure: After taking the MINTFIT test, students are advised on which topics to revise. STACK offers many advantages in the setting of diagnostics testing for both participants and organisers. A STACK question's potential response tree helps diagnose the errors committed by the participants, as it is possible to compare the entered solution with incorrect solutions that arise from known common mistakes. It is also possible to provide partial credit for partially correct answers, or for errors carried forward. Additionally, it is possible to generate many random variants of a question. If for example, the question is to find the derivative of a polynomial, the system can randomly draw its coefficients from a specified set. Variants that are either too difficult or too easy can then be deleted by hand. At the universities in Hamburg, the MINTFIT Math Test is used in exam-like situations as a part of university entrance tests, a module requirement or as an opportunity to collect bonus points for the first term exams. The possibility to generate different questions of the same difficulty level is invaluable here. Figure: Students are given partial credit for partially correct answers, and specific feedback on their mistakes.","title":"Introduction"},{"location":"CaseStudies/2020/MINTFIT/#execution","text":"The STACK questions in the MINTFIT Math Test were written by a scientific assistant (the author) and a student helper in 2014/2015, supported by an IT assistant. New STACK questions were easily generated by for example copying an existing question with a similar structure and looking up the coding structure of Maxima. This way, with just a small starting set of exemplary questions, it was possible to quickly get comfortable with STACK without any help from other sources or training. The questions in the MINTFIT Math Test can be done by mental arithmetic or by calculating using pen and paper \u2013 a calculator is not necessary and should not be used (neither at home nor in exam-like situations). However, since the general approach of MINTFIT and the Math Test particularly is the voluntariness of its users, participants are not controlled (with the exception of some settings, like the university entrance test, where they are seated in an exam room). However, they are informed before starting the test that their results are representative for their math skills only if they complete it without using a calculator or looking the answers up on a webpage like Wolfram Alpha. About 50 questions in the question pool of the Math Test are implemented with STACK. The MINTFIT Math Test has been accessible since June 2015.","title":"Execution"},{"location":"CaseStudies/2020/MINTFIT/#results","text":"It is difficult to measure the precise impact of the MINTFIT Math Test on students' study skills. Nonetheless, there is student feedback from a form offered after the test. Of all those who answered the question: \"Do you think that the test is helpful for you or freshmen in general?\", 66% answered with a clear \"yes\". Answers were given in a range from 1 (\"yes\") to 5 (\"absolutely not\"), with a mean response of 1.5. Of all those who answered the question \"Do you feel fairly rated?\", 61% answered \"yes\". With possible answers as in the previous question, this one had a mean answer of 1.62.","title":"Results"},{"location":"CaseStudies/2020/MINTFIT/#challenges","text":"The main challenges of using STACK were of technical nature. Keeping up with the updates of Moodle and STACK means you have to keep a close eye on the appearance of the test. Moodle itself offers many possibilities, so one needs time to make the optimal adjustments there.","title":"Challenges"},{"location":"CaseStudies/2020/MINTFIT/#enablers","text":"MINTFIT is a project by the universities HafenCity Universit\u00e4t Hamburg (HCU), Universit\u00e4t Hamburg (UHH), University of Applied Sciences Hamburg (HAW Hamburg), University Medical Center Hamburg-Eppendorf (UKE) and the University of Technology Hamburg (TUHH) in Hamburg, Germany. It is funded by the Hamburg Ministry of Science, Research, Equalities and Districts (Beh\u00f6rde f\u00fcr Wissenschaft, Forschung, Gleichstellung und Bezirke Hamburg, BWFGB).","title":"Enablers"},{"location":"CaseStudies/2020/MINTFIT/#whats-next","text":"The MINTFIT test and courses programme will be completed with regard to the content by the end of 2020. From 2021 on, the service is going to be maintained for current and future applications, and tests and courses will be refined and enhanced.","title":"What's Next?"},{"location":"CaseStudies/2020/MINTFIT/#references","text":"[1] Barbas, H.; Schramm, T.: The Hamburg Online Math Test MINTFIT for prospective Students of STEM Degree Programs . MSOR Connections, S. 43-51, 2018. Institutional Support for STACK in Edinburgh Extra-Occupational Bridging Courses for Non-Traditional Students","title":"References"},{"location":"CaseStudies/2020/OTH/","text":"Extra-Occupational Bridging Courses for Non-Traditional Students OTH Amberg-Weiden Stephan Bach Abstract The Ostbayerische Technische Hochschule Amberg-Weiden (OTH - Technical University of Applied Sciences) offers extra-occupational mathematical bridging courses for non-traditional students with little prior knowledge. In a blended-learning scenario, the self-study component includes quizzes with STACK questions. These questions were implemented with a specific focus on the needs of non-traditional students, e.g. providing support for dealing with input syntax and using partial crediting. The questions use several of STACK's input types, including multiple-choice questions, which help establish successful mathematical practice. Both lecturers and students emphasize the importance of STACK for the program's success. Introduction Figure: A statue near OTH Amberg-Weiden. In Germany, there are various opportunities to enrol at universities to study a vocational qualification instead of a higher education degree.\u00b9 For example, people with certain professional degrees, such as technicians, get a general university entrance qualification. Often these students do not have the mathematical prior knowledge which is expected by universities in STEM and business fields. Furthermore, the widespread bridging courses are usually not enough for this audience, and they require more extensive extra-occupational mathematics courses. At the Ostbayerische Technische Hochschule (OTH) Amberg-Weiden there is a long tradition of preparation courses for students with vocational backgrounds. Over time these courses have been adapted to changes in the legal framework and were further developed between 2016 and 2018 into the program BeVorStudium. The joint project \"OTH mind\", funded by the German Federal Ministry of Education and Research, developed a blended learning scenario that included STACK quizzes. A majority of participants are in their mid-twenties, have a vocational education in the technical area and aim for studies like mechanical or electrical engineering or computer science. Institutions who are offering preparation courses for this audience face several challenges. One is the high number of topics to be covered in just a few months. Another is the limited number of time slots for in-person courses, with participants typically having a full-time job. This makes the self-study component an important part of the course. STACK is well-suited for the self-study environment, helping students apply new notions to routine problems and get individual feedback. Execution BeVorStudium consists of two mathematics modules (plus one module in physics). Mathematics I contains topics typically included in middle grade syllabi, in particular elementary algebra. Mathematics II deals with important content from senior grades, especially calculus. In-person courses take place every other weekend, combined with an online based self-study component in between. Students are encouraged to complete regular online quizzes with STACK questions, discussed in detail in [2]. Each quiz consists of six to ten normally multi-part STACK questions. When designing the quizzes, the following criteria were followed to meet the needs of non-traditional students: Input support . Some participants, being out of school for many years, consistently struggle with the input syntax. Therefore quizzes always provide syntax hints, and make use of STACK's tools for syntax validation. For example, answers are not accepted unless they are of the same type (e.g. equation, number, etc.) as the model answer. Partial credits . Partial credit is used extensively to keep students motivated, and reward correct ideas where possible. Specific feedback . Questions put an emphasis on \"specific feedback\" rather than \"general feedback\". Specific feedback addresses individual mistakes, and provides positive feedback on correct ideas. If a question includes general feedback too, this usually provides an illustration of the correct answer or a hint to the approach but not a model solution. Questions and model solutions can be discussed in class, which, according to the lecturer, usually takes a significant amount of \"well invested\" time. Variety of input types. In mathematical practice it is important to have a variety of material, approaches and perspectives [3]. To support this idea, the quizzes use a variety of input types. Besides a majority of questions with algebraic input there are also interactive JSX-Graphs and regular multiple-choice questions (MCQs). Figure: A question about differentiating. The student is given partial credits for finding a correct numerator and incorrect denominator. Multiple-Choice Questions Although there are a number of problems connected to the use of MCQs in the assessment of STEM subjects - for example, when dealing with reversible mathematical processes - there are situations when this question format is more appropriate than others [4, 5]. In the preparation program, BeVorStudium MCQs serve various purposes: Avoiding syntax issues. As mentioned previously, some participants struggle with input syntax. MCQs give students the option to just focus on the (new) mathematics first, without worrying about the syntax. Addressing different learning objectives . While questions with algebraic input often assess mathematical skills, MCQs are suitable for the assessment of conceptual and procedural knowledge as well as conceptual understanding. Establishing high quality practice . Different input types help establish a variety of perspectives and connections in practice (see above) and meet the needs of different types of learners. Figure: In this question, students are asked to select all odd functions. The functions can be randomly generated and the feedback is specific to the student's individual selection. Since Moodle has built-in support for MCQs, it might seem unnecessary to use STACK for these questions. However, STACK comes with its own set of MCQ input types. Besides having a consistent layout in all questions, STACK's MCQs have several features that improve the didactical quality of the questions: Developing interesting question formats . STACK enables authors to implement multiple-choice formats which are recommended for university level assessment [6] like multiple True/False or matching questions. Using typical STACK features . Many STACK features such as randomization, partial crediting and in particular differentiated feedback can also be used in MCQs. For example, it is possible to give feedback on options of a checkbox question which are not chosen, or to point out contradictions between certain options. Implementing multi-part questions . There are typical mathematics problems which not only require a numerical or algebraic answer but also some verbal addition (\"What is the type of the extremum?\", \"Is this answer unique?\", \"What is the monotonic behaviour of the function?\" etc.). These questions are implemented well through STACK MCQ. Efficiency . Using STACK-MCQs can be very efficient, especially when using Maxima plots. An implemented question can be used as a template for similar questions that use another class of functions or another set of propositions. Figure: A matching question that uses Maxima plots. Results The experience at the OTH Amberg-Weiden is that non-traditional students value in-person classes. It is therefore important to maintain a close connection between online quizzes and in-person lectures. By doing so, a majority of students also complete the STACK quizzes. During the trial period of the course in 2018 on average 97.2% (Mathematics I, N=9) and 62.5% (Mathematics II, N=16) of active participants\u00b2 completed the STACK quizzes. These percentages were similar in subsequent years. The integration of STACK questions led to an increased amount of time used for self-study. In the 2018 evaluation of the module Mathematics II, eight out of ten respondents said they invested more than three hours per week on self-study - in addition to a full-time job and extensive in person lectures. Both students and lecturers acknowledge the importance of STACK as a part of the preparation program. Individual feedback of alumni shows that some participants pass their math exam at the end of the first term with a good or even very good result. What's next? After three years of using STACK within BeVorStudium, questions have been consistently improved. There are however some approaches for further development: Extending the specific feedback. The specific feedback still mainly focuses on deficits (\"You have done something wrong\"), and should be extended to address correct ideas as well. Making exercises problem oriented . Problem orientation is a principle of successful mathematical practice [3], and means to give exercises a superordinate perspective. This can be achieved by adding reflective MCQs. Considering different approaches . Currently most of the questions focus on the result rather than the approach. Implementing questions that focus on the approach could help students better understand mathematical methods and identify mistakes. This could be implemented by asking for certain extensions or using the \"Equivalence reasoning\" input type. References [1] Kultusministerkonferenz. Hochschulzugang f\u00fcr beruflich qualifizierte Bewerber ohne schulische Hochschulzugangsberechtigung. https://www.kmk.org/fileadmin/veroeffentlichungen_beschluesse/2009/2009_03_06-Hochschulzugang-erful-qualifizierte-Bewerber.pdf , 2009. [2] S. Bach. STACK-Fragen zur Unterst\u00fctzung der Selbstlernphasen in einem Studien-vorbereitungsangebot f\u00fcr beruflich Qualifizierte. In: Contributions to the 1st International STACK conference 2018, DOI: 10.5281/zenodo.2563803, 2019. [3] H. Winter. Begriff und Bedeutung des \u00dcbens im Mathematikunterricht. In: Mathematik lehren, 2, pp. 4-16, 1984. [4] C. J. Sangwin, I. Jones. Asymmetry in student achievement on multiple-choice and constructed-response items in reversible mathematics processes. In: Educational Studies in Mathematics, 94, pp. 205--222, DOI: 10.1007/s10649-016-9725-4, 2016. [5] S. Bach. Using multiple-choice questions in STACK -- reasons and examples. In: Contributions to the 3rd International STACK Conference 2020, DOI: 10.5281/zenodo.3945809, 2020. [6] M. A. Lindner, B. Strobel, O. K\u00f6ller. multiple-choice Pr\u00fcfungen an Hochschulen? Ein Literatur\u00fcberblick und Pl\u00e4doyer f\u00fcr mehr praxisorientierte Forschung. In: Zeitschrift f\u00fcr P\u00e4dagogische Psychologie, 29 (3-4), pp. 133-149, 2015. \u00b9 The legal framework for the current arrangement was given by a decision of the Standing Conference of the Ministers of Education and Cultural Affairs (KMK) in 2009 [1]. \u00b2 Active participants are considered to be those who attended at least half of the lectures. Diagnostics Testing via STACK Using STACK in Real Analysis","title":"Extra-Occupational Bridging Courses for Non-Traditional Students"},{"location":"CaseStudies/2020/OTH/#extra-occupational-bridging-courses-for-non-traditional-students","text":"","title":"Extra-Occupational Bridging Courses for Non-Traditional Students"},{"location":"CaseStudies/2020/OTH/#oth-amberg-weiden","text":"Stephan Bach","title":"OTH Amberg-Weiden"},{"location":"CaseStudies/2020/OTH/#abstract","text":"The Ostbayerische Technische Hochschule Amberg-Weiden (OTH - Technical University of Applied Sciences) offers extra-occupational mathematical bridging courses for non-traditional students with little prior knowledge. In a blended-learning scenario, the self-study component includes quizzes with STACK questions. These questions were implemented with a specific focus on the needs of non-traditional students, e.g. providing support for dealing with input syntax and using partial crediting. The questions use several of STACK's input types, including multiple-choice questions, which help establish successful mathematical practice. Both lecturers and students emphasize the importance of STACK for the program's success.","title":"Abstract"},{"location":"CaseStudies/2020/OTH/#introduction","text":"Figure: A statue near OTH Amberg-Weiden. In Germany, there are various opportunities to enrol at universities to study a vocational qualification instead of a higher education degree.\u00b9 For example, people with certain professional degrees, such as technicians, get a general university entrance qualification. Often these students do not have the mathematical prior knowledge which is expected by universities in STEM and business fields. Furthermore, the widespread bridging courses are usually not enough for this audience, and they require more extensive extra-occupational mathematics courses. At the Ostbayerische Technische Hochschule (OTH) Amberg-Weiden there is a long tradition of preparation courses for students with vocational backgrounds. Over time these courses have been adapted to changes in the legal framework and were further developed between 2016 and 2018 into the program BeVorStudium. The joint project \"OTH mind\", funded by the German Federal Ministry of Education and Research, developed a blended learning scenario that included STACK quizzes. A majority of participants are in their mid-twenties, have a vocational education in the technical area and aim for studies like mechanical or electrical engineering or computer science. Institutions who are offering preparation courses for this audience face several challenges. One is the high number of topics to be covered in just a few months. Another is the limited number of time slots for in-person courses, with participants typically having a full-time job. This makes the self-study component an important part of the course. STACK is well-suited for the self-study environment, helping students apply new notions to routine problems and get individual feedback.","title":"Introduction"},{"location":"CaseStudies/2020/OTH/#execution","text":"BeVorStudium consists of two mathematics modules (plus one module in physics). Mathematics I contains topics typically included in middle grade syllabi, in particular elementary algebra. Mathematics II deals with important content from senior grades, especially calculus. In-person courses take place every other weekend, combined with an online based self-study component in between. Students are encouraged to complete regular online quizzes with STACK questions, discussed in detail in [2]. Each quiz consists of six to ten normally multi-part STACK questions. When designing the quizzes, the following criteria were followed to meet the needs of non-traditional students: Input support . Some participants, being out of school for many years, consistently struggle with the input syntax. Therefore quizzes always provide syntax hints, and make use of STACK's tools for syntax validation. For example, answers are not accepted unless they are of the same type (e.g. equation, number, etc.) as the model answer. Partial credits . Partial credit is used extensively to keep students motivated, and reward correct ideas where possible. Specific feedback . Questions put an emphasis on \"specific feedback\" rather than \"general feedback\". Specific feedback addresses individual mistakes, and provides positive feedback on correct ideas. If a question includes general feedback too, this usually provides an illustration of the correct answer or a hint to the approach but not a model solution. Questions and model solutions can be discussed in class, which, according to the lecturer, usually takes a significant amount of \"well invested\" time. Variety of input types. In mathematical practice it is important to have a variety of material, approaches and perspectives [3]. To support this idea, the quizzes use a variety of input types. Besides a majority of questions with algebraic input there are also interactive JSX-Graphs and regular multiple-choice questions (MCQs). Figure: A question about differentiating. The student is given partial credits for finding a correct numerator and incorrect denominator.","title":"Execution"},{"location":"CaseStudies/2020/OTH/#multiple-choice-questions","text":"Although there are a number of problems connected to the use of MCQs in the assessment of STEM subjects - for example, when dealing with reversible mathematical processes - there are situations when this question format is more appropriate than others [4, 5]. In the preparation program, BeVorStudium MCQs serve various purposes: Avoiding syntax issues. As mentioned previously, some participants struggle with input syntax. MCQs give students the option to just focus on the (new) mathematics first, without worrying about the syntax. Addressing different learning objectives . While questions with algebraic input often assess mathematical skills, MCQs are suitable for the assessment of conceptual and procedural knowledge as well as conceptual understanding. Establishing high quality practice . Different input types help establish a variety of perspectives and connections in practice (see above) and meet the needs of different types of learners. Figure: In this question, students are asked to select all odd functions. The functions can be randomly generated and the feedback is specific to the student's individual selection. Since Moodle has built-in support for MCQs, it might seem unnecessary to use STACK for these questions. However, STACK comes with its own set of MCQ input types. Besides having a consistent layout in all questions, STACK's MCQs have several features that improve the didactical quality of the questions: Developing interesting question formats . STACK enables authors to implement multiple-choice formats which are recommended for university level assessment [6] like multiple True/False or matching questions. Using typical STACK features . Many STACK features such as randomization, partial crediting and in particular differentiated feedback can also be used in MCQs. For example, it is possible to give feedback on options of a checkbox question which are not chosen, or to point out contradictions between certain options. Implementing multi-part questions . There are typical mathematics problems which not only require a numerical or algebraic answer but also some verbal addition (\"What is the type of the extremum?\", \"Is this answer unique?\", \"What is the monotonic behaviour of the function?\" etc.). These questions are implemented well through STACK MCQ. Efficiency . Using STACK-MCQs can be very efficient, especially when using Maxima plots. An implemented question can be used as a template for similar questions that use another class of functions or another set of propositions. Figure: A matching question that uses Maxima plots.","title":"Multiple-Choice Questions"},{"location":"CaseStudies/2020/OTH/#results","text":"The experience at the OTH Amberg-Weiden is that non-traditional students value in-person classes. It is therefore important to maintain a close connection between online quizzes and in-person lectures. By doing so, a majority of students also complete the STACK quizzes. During the trial period of the course in 2018 on average 97.2% (Mathematics I, N=9) and 62.5% (Mathematics II, N=16) of active participants\u00b2 completed the STACK quizzes. These percentages were similar in subsequent years. The integration of STACK questions led to an increased amount of time used for self-study. In the 2018 evaluation of the module Mathematics II, eight out of ten respondents said they invested more than three hours per week on self-study - in addition to a full-time job and extensive in person lectures. Both students and lecturers acknowledge the importance of STACK as a part of the preparation program. Individual feedback of alumni shows that some participants pass their math exam at the end of the first term with a good or even very good result.","title":"Results"},{"location":"CaseStudies/2020/OTH/#whats-next","text":"After three years of using STACK within BeVorStudium, questions have been consistently improved. There are however some approaches for further development: Extending the specific feedback. The specific feedback still mainly focuses on deficits (\"You have done something wrong\"), and should be extended to address correct ideas as well. Making exercises problem oriented . Problem orientation is a principle of successful mathematical practice [3], and means to give exercises a superordinate perspective. This can be achieved by adding reflective MCQs. Considering different approaches . Currently most of the questions focus on the result rather than the approach. Implementing questions that focus on the approach could help students better understand mathematical methods and identify mistakes. This could be implemented by asking for certain extensions or using the \"Equivalence reasoning\" input type.","title":"What's next?"},{"location":"CaseStudies/2020/OTH/#references","text":"[1] Kultusministerkonferenz. Hochschulzugang f\u00fcr beruflich qualifizierte Bewerber ohne schulische Hochschulzugangsberechtigung. https://www.kmk.org/fileadmin/veroeffentlichungen_beschluesse/2009/2009_03_06-Hochschulzugang-erful-qualifizierte-Bewerber.pdf , 2009. [2] S. Bach. STACK-Fragen zur Unterst\u00fctzung der Selbstlernphasen in einem Studien-vorbereitungsangebot f\u00fcr beruflich Qualifizierte. In: Contributions to the 1st International STACK conference 2018, DOI: 10.5281/zenodo.2563803, 2019. [3] H. Winter. Begriff und Bedeutung des \u00dcbens im Mathematikunterricht. In: Mathematik lehren, 2, pp. 4-16, 1984. [4] C. J. Sangwin, I. Jones. Asymmetry in student achievement on multiple-choice and constructed-response items in reversible mathematics processes. In: Educational Studies in Mathematics, 94, pp. 205--222, DOI: 10.1007/s10649-016-9725-4, 2016. [5] S. Bach. Using multiple-choice questions in STACK -- reasons and examples. In: Contributions to the 3rd International STACK Conference 2020, DOI: 10.5281/zenodo.3945809, 2020. [6] M. A. Lindner, B. Strobel, O. K\u00f6ller. multiple-choice Pr\u00fcfungen an Hochschulen? Ein Literatur\u00fcberblick und Pl\u00e4doyer f\u00fcr mehr praxisorientierte Forschung. In: Zeitschrift f\u00fcr P\u00e4dagogische Psychologie, 29 (3-4), pp. 133-149, 2015. \u00b9 The legal framework for the current arrangement was given by a decision of the Standing Conference of the Ministers of Education and Cultural Affairs (KMK) in 2009 [1]. \u00b2 Active participants are considered to be those who attended at least half of the lectures. Diagnostics Testing via STACK Using STACK in Real Analysis","title":"References"},{"location":"CaseStudies/2021/HELM/","text":"Translating the HELM workbooks to STACK University of Edinburgh Konstantina Zerva, Ilyas Nicholson, Adri\u00e1n Do\u00f1a Mateo Context HELM (Helping Engineers Learn Mathematics) is a collection of 50 workbooks developed by five English universities \u2013 Loughborough, Hull, Reading, Sunderland and Manchester \u2013 that covers the curriculum of first- and second-year mathematics courses for engineering undergraduates. They were designed as flexible learning resources and have been used by an estimate of 12,000 students in 55 UK higher and further education sites [1]. During the ongoing pandemic, as more and more teaching moves to online spaces, the universities of Edinburgh and Loughborough, with the help of several other institutions, have undertaken an effort of translating the HELM materials into Moodle quizzes. This effort was supported with funding from the U21 Global Educational Enhancement Fund [2], which mainly enabled interns (including Ilyas and Adri\u00e1n) to be employed on the project. The newly-created Moodle quizzes very much follow the spirit of the original workbooks but provide the added value of interactivity through STACK questions. The result will be released as an Open Educational Resource (OER) on the University of Edinburgh website. Execution So far, about half of the workbooks have been made into Moodle quizzes. Most of the quizzes corresponding to workbooks 1\u201319 and 35\u201339 were created during the summer of 2020. These include all the exposition and worked examples as description boxes, and STACK versions of most of the tasks and exercises in each workbook. The materials covered by these quizzes include: Basic algebra and elementary functions Linear algebra Complex numbers Calculus and differential equations Probability Feedback from students and lecturers was gathered and acted upon during an extensive revision of the material during the summer of 2021, prior to their public release. This also ensured consistency of style and resulted in the creation of new quizzes and addition of interactive graphs to some questions using JSXGraph. Currently, there are over 90 quizzes with an average of 6\u20138 STACK questions each. Most questions have algebraic or numerical inputs, but some are implemented as multiple choice questions, which better suit the nature of the original HELM exercise. Except where it was not possible, question statements were randomised so that students can practice with different versions of the same exercise. Special care was taken to set up relevant tests, to ensure each question is working as expected and to flag issues in future edits. The following screenshots provide some highlights from the HELM quizzes. Interactive plot with JSXGraph. Students can change the number of rectangles in the left Riemann sum to help them understand the definition of an integral an answer the question. Interactive plot with JSXGraph. Students can pan and zoom to explore how the Newton\u2013Raphson method works. HELM task as a STACK question. Part (b) is assessed with the SysEquiv answer test to allow for different equivalent forms of the correct equation. Putting the quizzes to work The HELM quizzes have been used in the Engineering Mathematics 1A and 1B (360 students) and Mathematics for Natural Sciences 1A and 1B (130 students) courses at the University of Edinburgh during the 2020/21 academic year. The courses also had online lectures and tutorials, and the HELM quizzes were mostly used for self-study. Each week, 3 or 4 quizzes were made available to students, which would serve as an introduction to the topics to be covered. These were intended as formative feedback and thus did not impact the student\u2019s final grade, but they could be used as practice for the assessed quiz due at the beginning of the following week. Student reception The students\u2019 engagement with the HELM materials was encouraging. In the Engineering Mathematics courses, each quiz typically received between 250 and 300 complete attempts on the week it was released. Feedback was overwhelmingly positive \u2013 some students found the HELM quizzes to be the most valuable part of the course. They particularly appreciated being able to work at their own pace and how the quizzes assumed little or no previous knowledge, a trait inherited from the original workbooks. Students also pointed to some areas that needed improvement, such as worked solutions, which were addressed during the 2021 summer revision. Conclusion Bringing new life to the HELM workbooks in the form of STACK quizzes has proved to be a very fruitful activity. The upfront effort to develop STACK questions has added great value to the online learning experience, through question randomisation and immediate feedback. The quizzes created so far cover most of the contents of first year engineering mathematics, applicable also to other subjects, and demonstrate how STACK can be used to teach a wide variety of topics. The work is nevertheless far from over. Around half of the HELM workbooks are yet to be translated into Moodle. Several other universities are interested in using the existing materials in their courses, and further progress will be made prioritising the workbooks that would be of most use to course organisers. In addition to this, it would be interesting to explore the use of interactive graphs as question inputs, which would enable certain types of \u2018sketch\u2019 questions in the original workbooks to be transferred to STACK. Lastly, the quizzes will soon be released as an OER, which will allow students all over the world to use them for self-study. References [1] https://www.lboro.ac.uk/departments/mlsc/student-resources/helm-workbooks/past-present-future/ [2] https://universitas21.com/news-and-events/news/u21s-new-global-education-enhancement-fund-winners-announced Using STACK in Real Analysis Question Answering in STACK Applying String Similarity","title":"Translating the HELM workbooks to STACK"},{"location":"CaseStudies/2021/HELM/#translating-the-helm-workbooks-to-stack","text":"","title":"Translating the HELM workbooks to STACK"},{"location":"CaseStudies/2021/HELM/#university-of-edinburgh","text":"Konstantina Zerva, Ilyas Nicholson, Adri\u00e1n Do\u00f1a Mateo","title":"University of Edinburgh"},{"location":"CaseStudies/2021/HELM/#context","text":"HELM (Helping Engineers Learn Mathematics) is a collection of 50 workbooks developed by five English universities \u2013 Loughborough, Hull, Reading, Sunderland and Manchester \u2013 that covers the curriculum of first- and second-year mathematics courses for engineering undergraduates. They were designed as flexible learning resources and have been used by an estimate of 12,000 students in 55 UK higher and further education sites [1]. During the ongoing pandemic, as more and more teaching moves to online spaces, the universities of Edinburgh and Loughborough, with the help of several other institutions, have undertaken an effort of translating the HELM materials into Moodle quizzes. This effort was supported with funding from the U21 Global Educational Enhancement Fund [2], which mainly enabled interns (including Ilyas and Adri\u00e1n) to be employed on the project. The newly-created Moodle quizzes very much follow the spirit of the original workbooks but provide the added value of interactivity through STACK questions. The result will be released as an Open Educational Resource (OER) on the University of Edinburgh website.","title":"Context"},{"location":"CaseStudies/2021/HELM/#execution","text":"So far, about half of the workbooks have been made into Moodle quizzes. Most of the quizzes corresponding to workbooks 1\u201319 and 35\u201339 were created during the summer of 2020. These include all the exposition and worked examples as description boxes, and STACK versions of most of the tasks and exercises in each workbook. The materials covered by these quizzes include: Basic algebra and elementary functions Linear algebra Complex numbers Calculus and differential equations Probability Feedback from students and lecturers was gathered and acted upon during an extensive revision of the material during the summer of 2021, prior to their public release. This also ensured consistency of style and resulted in the creation of new quizzes and addition of interactive graphs to some questions using JSXGraph. Currently, there are over 90 quizzes with an average of 6\u20138 STACK questions each. Most questions have algebraic or numerical inputs, but some are implemented as multiple choice questions, which better suit the nature of the original HELM exercise. Except where it was not possible, question statements were randomised so that students can practice with different versions of the same exercise. Special care was taken to set up relevant tests, to ensure each question is working as expected and to flag issues in future edits. The following screenshots provide some highlights from the HELM quizzes. Interactive plot with JSXGraph. Students can change the number of rectangles in the left Riemann sum to help them understand the definition of an integral an answer the question. Interactive plot with JSXGraph. Students can pan and zoom to explore how the Newton\u2013Raphson method works. HELM task as a STACK question. Part (b) is assessed with the SysEquiv answer test to allow for different equivalent forms of the correct equation.","title":"Execution"},{"location":"CaseStudies/2021/HELM/#putting-the-quizzes-to-work","text":"The HELM quizzes have been used in the Engineering Mathematics 1A and 1B (360 students) and Mathematics for Natural Sciences 1A and 1B (130 students) courses at the University of Edinburgh during the 2020/21 academic year. The courses also had online lectures and tutorials, and the HELM quizzes were mostly used for self-study. Each week, 3 or 4 quizzes were made available to students, which would serve as an introduction to the topics to be covered. These were intended as formative feedback and thus did not impact the student\u2019s final grade, but they could be used as practice for the assessed quiz due at the beginning of the following week.","title":"Putting the quizzes to work"},{"location":"CaseStudies/2021/HELM/#student-reception","text":"The students\u2019 engagement with the HELM materials was encouraging. In the Engineering Mathematics courses, each quiz typically received between 250 and 300 complete attempts on the week it was released. Feedback was overwhelmingly positive \u2013 some students found the HELM quizzes to be the most valuable part of the course. They particularly appreciated being able to work at their own pace and how the quizzes assumed little or no previous knowledge, a trait inherited from the original workbooks. Students also pointed to some areas that needed improvement, such as worked solutions, which were addressed during the 2021 summer revision.","title":"Student reception"},{"location":"CaseStudies/2021/HELM/#conclusion","text":"Bringing new life to the HELM workbooks in the form of STACK quizzes has proved to be a very fruitful activity. The upfront effort to develop STACK questions has added great value to the online learning experience, through question randomisation and immediate feedback. The quizzes created so far cover most of the contents of first year engineering mathematics, applicable also to other subjects, and demonstrate how STACK can be used to teach a wide variety of topics. The work is nevertheless far from over. Around half of the HELM workbooks are yet to be translated into Moodle. Several other universities are interested in using the existing materials in their courses, and further progress will be made prioritising the workbooks that would be of most use to course organisers. In addition to this, it would be interesting to explore the use of interactive graphs as question inputs, which would enable certain types of \u2018sketch\u2019 questions in the original workbooks to be transferred to STACK. Lastly, the quizzes will soon be released as an OER, which will allow students all over the world to use them for self-study.","title":"Conclusion"},{"location":"CaseStudies/2021/HELM/#references","text":"[1] https://www.lboro.ac.uk/departments/mlsc/student-resources/helm-workbooks/past-present-future/ [2] https://universitas21.com/news-and-events/news/u21s-new-global-education-enhancement-fund-winners-announced Using STACK in Real Analysis Question Answering in STACK Applying String Similarity","title":"References"},{"location":"CaseStudies/2021/Warwick/","text":"Using STACK in Real Analysis University of Warwick Siri Chongchitnan Context The onset of the Covid-19 pandemic in 2020 urgently forced us to rethink how we assess mathematics at university level. In the summer of 2020, we turned to STACK with the goal of creating self-assessed online quizzes in real analysis that would supplement traditional problem sheets. We wanted to see how far STACK could be used in a heavily proof-based pure mathematics undergraduate course. Time line Coding phase: June - August 2020 Testing phase: September - December 2020 Launch: January to March 2021 Feedback and data analysis: April 2021 We worked on the module Analysis II - a core first-year module for maths undergraduates at Warwick. The intake was about 400. This is second course in real analysis follows from the foundation in numbers, sequences and series in Analysis I. Teaching materials, including online quizzes, were to be created on the Moodle virtual learning environment. Here is the weekly scope of the course given over 10 weeks. \\epsilon-\\delta definition of continuity Sequential definition of continuity Continuity on an interval, Intermediate Value Theorem Limits Inverse Function Theorem Differentiation, Carath\u00e9odory\u2019s theorem Mean Value Theorem, L\u2019H\u00f4pital\u2019s Rule Taylor\u2019s Theorem, Lagrange form of the remainder Radius of convergence Differentiation of power series Our goal was to create one set of STACK assessment for each week\u2019s material. Each set should take around 30-40 minutes to complete. Execution In the previous year, students had to submit problem sheets weekly, However, Covid-related uncertainties meant that we had to cut this number down to only 4 problem sheets, which counted for 10% of the final grade. To supplement the above, we created 11 sets of STACK quizzes, two of which were not counted (one on syntax training, and one on Analysis I revision). They were practice quizzes, in the sense that students could do them an unlimited number of times before the deadline, each attempt building on the last. Each quiz had a pass mark of around 85% (not uniform across the quizzes). Passing 6 out of 9 quizzes gave the student a flat 5% for the module. We used STACK to create over 40 multi-part questions over 4 weeks. We are grateful for George Kinnear\u2019s talk on JSXGraph at previous STACK conferences, and to Chris Sangwin and Robbie Bickerton, both of whom gave us inspirations to apply their scaffolding and proof-comprehension techniques to Analysis II. We used STACK in conjunction with Moodle-type questions (STACK integrated seamlessly with our Moodle virtual learning environment). We particularly found JSXGraph helpful in creating interactive graphics that visualise and explain tricky analysis concepts better than static media could. Highlights include the questions shown in these figures. \u03b5-\u03b4 definition of continuity visualised with JSXgraph and slider. Counterexamples in analysis can be visualised with JSXgraph\u2019s zoom function (e.g. to explore local behaviour of a function). A proof of the Chain Rule is implemented using Moodle\u2019s \u2018drag and drop\u2019 question type together with STACK-coded scaffolded proof. Results We set the pass mark for each assignment quite high (>80%) but most students achieved >90%. On average students submitted between 2 and 3 attempts per quiz, with over 90% of students passing all quizzes. These engagement statistics are all encouraging. Student feedback When asked: \u201cApart from the lecture notes and videos, what other resources are useful for the understanding of Analysis II?\u201d, we found that almost 90% of respondents rated the quizzes as useful. As many students rated the problem sheets as useful. This is evidence that when implemented properly, the learning gains from STACK quizzes are comparable to those of traditional pen-and-paper assignments. When asked to \u201cName one thing about the module which has had the most impact on your learning in this course\u201d, a number of students thought the STACK quizzes were the most impactful element of the course. Some comments include: \u201cThe quizzes were helpful and the infinite attempts ensured that I did not feel pressured while doing them, allowing me to focus on understanding the content.\" \u201cThe quizzes have been a very useful interactive learning tool.\" \u201cThe alternating assessment format between quizzes and written assignments is nice and helped reduce stress.\" Summary STACK can be successfully applied to a wide range of mathematics content, including pure mathematics at university level as our work has demonstrated. We have shown that it is possible to turn proofs in existing lecture notes and problem sheets into interactive online quizzes, even in pure proof-heavy courses like ours. The interactivity in the STACK quizzes also meant that students understood the proofs much more clearly than when the proofs were recited during lectures. Although STACK was the primary tool for question creation, we also found it useful to mix STACK with other native Moodle-type questions for a varied diet. Creating questions on STACK is an ideal co-creation project which can be done as a summer internship. There are long-term benefits for everyone involved. All in all, we found STACK to be highly flexible and adaptable to help us achieve our teaching-and-learning goals. At Warwick we are continuing to expand the use of STACK to other maths modules. Extra-Occupational Bridging Courses for Non-Traditional Students Translating the HELM workbooks to STACK","title":"Using STACK in Real Analysis"},{"location":"CaseStudies/2021/Warwick/#using-stack-in-real-analysis","text":"","title":"Using STACK in Real Analysis"},{"location":"CaseStudies/2021/Warwick/#university-of-warwick","text":"Siri Chongchitnan","title":"University of Warwick"},{"location":"CaseStudies/2021/Warwick/#context","text":"The onset of the Covid-19 pandemic in 2020 urgently forced us to rethink how we assess mathematics at university level. In the summer of 2020, we turned to STACK with the goal of creating self-assessed online quizzes in real analysis that would supplement traditional problem sheets. We wanted to see how far STACK could be used in a heavily proof-based pure mathematics undergraduate course.","title":"Context"},{"location":"CaseStudies/2021/Warwick/#time-line","text":"Coding phase: June - August 2020 Testing phase: September - December 2020 Launch: January to March 2021 Feedback and data analysis: April 2021 We worked on the module Analysis II - a core first-year module for maths undergraduates at Warwick. The intake was about 400. This is second course in real analysis follows from the foundation in numbers, sequences and series in Analysis I. Teaching materials, including online quizzes, were to be created on the Moodle virtual learning environment. Here is the weekly scope of the course given over 10 weeks. \\epsilon-\\delta definition of continuity Sequential definition of continuity Continuity on an interval, Intermediate Value Theorem Limits Inverse Function Theorem Differentiation, Carath\u00e9odory\u2019s theorem Mean Value Theorem, L\u2019H\u00f4pital\u2019s Rule Taylor\u2019s Theorem, Lagrange form of the remainder Radius of convergence Differentiation of power series Our goal was to create one set of STACK assessment for each week\u2019s material. Each set should take around 30-40 minutes to complete.","title":"Time line"},{"location":"CaseStudies/2021/Warwick/#execution","text":"In the previous year, students had to submit problem sheets weekly, However, Covid-related uncertainties meant that we had to cut this number down to only 4 problem sheets, which counted for 10% of the final grade. To supplement the above, we created 11 sets of STACK quizzes, two of which were not counted (one on syntax training, and one on Analysis I revision). They were practice quizzes, in the sense that students could do them an unlimited number of times before the deadline, each attempt building on the last. Each quiz had a pass mark of around 85% (not uniform across the quizzes). Passing 6 out of 9 quizzes gave the student a flat 5% for the module. We used STACK to create over 40 multi-part questions over 4 weeks. We are grateful for George Kinnear\u2019s talk on JSXGraph at previous STACK conferences, and to Chris Sangwin and Robbie Bickerton, both of whom gave us inspirations to apply their scaffolding and proof-comprehension techniques to Analysis II. We used STACK in conjunction with Moodle-type questions (STACK integrated seamlessly with our Moodle virtual learning environment). We particularly found JSXGraph helpful in creating interactive graphics that visualise and explain tricky analysis concepts better than static media could. Highlights include the questions shown in these figures. \u03b5-\u03b4 definition of continuity visualised with JSXgraph and slider. Counterexamples in analysis can be visualised with JSXgraph\u2019s zoom function (e.g. to explore local behaviour of a function). A proof of the Chain Rule is implemented using Moodle\u2019s \u2018drag and drop\u2019 question type together with STACK-coded scaffolded proof.","title":"Execution"},{"location":"CaseStudies/2021/Warwick/#results","text":"We set the pass mark for each assignment quite high (>80%) but most students achieved >90%. On average students submitted between 2 and 3 attempts per quiz, with over 90% of students passing all quizzes. These engagement statistics are all encouraging.","title":"Results"},{"location":"CaseStudies/2021/Warwick/#student-feedback","text":"When asked: \u201cApart from the lecture notes and videos, what other resources are useful for the understanding of Analysis II?\u201d, we found that almost 90% of respondents rated the quizzes as useful. As many students rated the problem sheets as useful. This is evidence that when implemented properly, the learning gains from STACK quizzes are comparable to those of traditional pen-and-paper assignments. When asked to \u201cName one thing about the module which has had the most impact on your learning in this course\u201d, a number of students thought the STACK quizzes were the most impactful element of the course. Some comments include: \u201cThe quizzes were helpful and the infinite attempts ensured that I did not feel pressured while doing them, allowing me to focus on understanding the content.\" \u201cThe quizzes have been a very useful interactive learning tool.\" \u201cThe alternating assessment format between quizzes and written assignments is nice and helped reduce stress.\"","title":"Student feedback"},{"location":"CaseStudies/2021/Warwick/#summary","text":"STACK can be successfully applied to a wide range of mathematics content, including pure mathematics at university level as our work has demonstrated. We have shown that it is possible to turn proofs in existing lecture notes and problem sheets into interactive online quizzes, even in pure proof-heavy courses like ours. The interactivity in the STACK quizzes also meant that students understood the proofs much more clearly than when the proofs were recited during lectures. Although STACK was the primary tool for question creation, we also found it useful to mix STACK with other native Moodle-type questions for a varied diet. Creating questions on STACK is an ideal co-creation project which can be done as a summer internship. There are long-term benefits for everyone involved. All in all, we found STACK to be highly flexible and adaptable to help us achieve our teaching-and-learning goals. At Warwick we are continuing to expand the use of STACK to other maths modules. Extra-Occupational Bridging Courses for Non-Traditional Students Translating the HELM workbooks to STACK","title":"Summary"},{"location":"CaseStudies/2022/HonoursComplexVariables/","text":"Use of STACK in Honours Complex Variables Context Complex analysis is a classical branch of pure mathematics, and one of the high points of human intellectual achievement. The University of Edinburgh complex analysis course, Honours Complex Variables , is typically taken by around 250 students annually, mostly in Year 3 of Mathematics BSc/MMath degrees. The course covers the following topics: holomorphic functions, the Cauchy-Riemann equations, and multivalued functions; conformal maps, the extended complex plane, Riemann sphere, and M\u00f6bius transformations; Cauchy's Integral Theorem, and the (Generalized) Cauchy Integral Theorem; Liouville's Theorem and the Maximum Modulus Principle; Taylor and Laurent Series; zeros, singularities, residues, and the Cauchy Residue Theorem; and evaluation of real integrals using contour integrals. The course content is based on an established set of course notes (around 80 pages) written by Dr Richard Gratwick, the current course organiser. The notes contain the background theory, proofs, examples and some exercises for the students to practise. Students were expected to work on them while they were studying each lecture's content. In addition to the exercises there are also tasks used in face to face workshops. Execution Traditionally, the course would have had three 50-minute whole-class lectures and one 50-minute workshop each week. In the academic year 2021-22, the course was redesigned in response to constraints imposed by pandemic restrictions. The course ran with two 50-minute synchronous digital lectures each week, in which the lecturer used a form of flipped classroom with polling in Zoom, and one 50-minute in-person workshop. The notes were converted from a static PDF to a collection of quizzes in the STACK service. Each week the students had 3-4 STACK quizzes, and taking into consideration the design of the quizzes, we estimate that the students would need 1-2 hours to work through each of them. So, each week we expect the students to spend 10-12 hours on the course in total (contact hours, quizzes, workshop, assignments). The STACK quizzes were used for practise and they didn't contribute towards the final mark of the course. This redesign was influenced by the previous work at the University of Edinburgh developing two fully online courses Fundamentals of Algebra and Calculus (FAC) and Introductory Mathematics and its Applications (IMA) [1]. The resources for Honours Complex Variables were created by Richard Gratwick, Steven O\u2019Hagan, the postgraduate intern Ivona Gjeroska and the undergraduate interns Maddy Baron and Xie Jin Ng, in collaboration with Giampaolo D\u2019Alessandro (University of Southampton). The redesign aimed to be future-proof in the sense that materials created should be suitable for reuse in subsequent years, with iterated improvements, even when a return to fully on-campus teaching is possible. Results A typical pattern of content from the resource is shown in following figure. We see a definition followed a short discussion and video clip of a worked example by the lecturer. Then we have a STACK question inviting the student to check their own understanding of the material. In addition, each unit of work started with a video of the lecturer giving a high-level overview and motivation of the material to come. Figure: Example of content of a typical quiz. Here are some examples of notable questions created for this course. Figure: A question asking to construct the harmonic conjugate of a function. The fully worked solution appears immediately after the students submit their answer. Figure: A Taylor series question. Figure: A question asking to classify singularities.The classification of each singularity appears as a drop-down list. Figure: A multipart STACK question on trigonometric integrals. In the future, such sessions could easily translate to on-campus activities using peer instruction, which had been an established practice in the School before the pandemic. Students' engagement Student feedback on the course was overwhelmingly positive, with one student responding to the end-of-course survey as follows. \u201cGenuinely this course has been the perfect mix of activities for my learning, I\u2019d go as far say to the best organised course I\u2019ve taken in SoM, certainly this year anyway. The notes being delivered in stack are great and much more engaging than a pdf (the supplementary pdf is much more easy to navigate for finding Theorems etc. however), which actually makes me do all the reading before lectures so I gain so much more from them. Stack is good in part because of the instant feedback on most exercises which are immediately relevant to what you\u2019re learning, but also because it breaks the material up well. Stack being the main resource works in perfectly with the 2 lectures delivered a week and the tutorial. SoM should considering delivering all courses in this fashion.\u201d The course organiser, Richard Gratwick, said: \u201cI believe the redesign of this course has been highly successful, and I like to consider the mode of delivery as a prototype for courses of the future. The motivation was to reflect on the innovations forced upon on us during the pandemic and attempt to implement in a considered way those that proved valuable. Recording short videos of examples and calculations allowed me to present these items \u201cdynamically\u201d, rather than as plain text, but freed up time in synchronous lectures for me to engage with more conceptual high-level discussion of the material. The Stack questions for self-assessment were largely based on exercises included in the previous version of the written notes, but students engaged with them much more regularly when they were presented in the online workbooks \u2013 my impression was that in previous years these written exercises were largely ignored. Challenges Redesigning a 3rd Year course, so that it contains a substantial amount of online components, was a challenging procedure. Authoring questions from scratch: a lot of the STACK questions had to be created completely from scratch because we didn't have any similar questions used in other courses. Deciding how to deliver each part of the course: it required careful though to decide which of the questions included in the lecture notes to have as exercise for students to solve or as a written example or as a worked example in a video. Some parts of the course can not be assessed automatically. After some consideration the lecturer decided to move some of the easy workshop questions into STACK and used the workshop time to address more complicated questions. Conclusions Online assessment it typically used for larger classes in early years of a university mathematics degree, such as calculus or linear algebra. These courses have a strong methods component. As the subject progresses, especially where there is a focus on mathematical proof, it is harder to write online questions which assess the key concepts. As a community we are gaining experience in using quizzes to structure learning materials (rather then traditional lectures), and in supporting more advanced courses. For example the University of Warwick used self-assessed online quizzes in real analysis that would supplement traditional problem sheets. In this course we have demonstrated that STACK can be successfully applied to a higher-level course to promote students' engagement with the content of the course. This is not as straightforward as in calculus and linear algebra, but nevertheless with careful design of materials it is possible to support students online with STACK in advanced courses such as complex analysis. Question Answering in STACK Applying String Similarity Developing a Fully Online Course","title":"Use of STACK in Honours Complex Variables"},{"location":"CaseStudies/2022/HonoursComplexVariables/#use-of-stack-in-honours-complex-variables","text":"","title":"Use of STACK in Honours Complex Variables"},{"location":"CaseStudies/2022/HonoursComplexVariables/#context","text":"Complex analysis is a classical branch of pure mathematics, and one of the high points of human intellectual achievement. The University of Edinburgh complex analysis course, Honours Complex Variables , is typically taken by around 250 students annually, mostly in Year 3 of Mathematics BSc/MMath degrees. The course covers the following topics: holomorphic functions, the Cauchy-Riemann equations, and multivalued functions; conformal maps, the extended complex plane, Riemann sphere, and M\u00f6bius transformations; Cauchy's Integral Theorem, and the (Generalized) Cauchy Integral Theorem; Liouville's Theorem and the Maximum Modulus Principle; Taylor and Laurent Series; zeros, singularities, residues, and the Cauchy Residue Theorem; and evaluation of real integrals using contour integrals. The course content is based on an established set of course notes (around 80 pages) written by Dr Richard Gratwick, the current course organiser. The notes contain the background theory, proofs, examples and some exercises for the students to practise. Students were expected to work on them while they were studying each lecture's content. In addition to the exercises there are also tasks used in face to face workshops.","title":"Context"},{"location":"CaseStudies/2022/HonoursComplexVariables/#execution","text":"Traditionally, the course would have had three 50-minute whole-class lectures and one 50-minute workshop each week. In the academic year 2021-22, the course was redesigned in response to constraints imposed by pandemic restrictions. The course ran with two 50-minute synchronous digital lectures each week, in which the lecturer used a form of flipped classroom with polling in Zoom, and one 50-minute in-person workshop. The notes were converted from a static PDF to a collection of quizzes in the STACK service. Each week the students had 3-4 STACK quizzes, and taking into consideration the design of the quizzes, we estimate that the students would need 1-2 hours to work through each of them. So, each week we expect the students to spend 10-12 hours on the course in total (contact hours, quizzes, workshop, assignments). The STACK quizzes were used for practise and they didn't contribute towards the final mark of the course. This redesign was influenced by the previous work at the University of Edinburgh developing two fully online courses Fundamentals of Algebra and Calculus (FAC) and Introductory Mathematics and its Applications (IMA) [1]. The resources for Honours Complex Variables were created by Richard Gratwick, Steven O\u2019Hagan, the postgraduate intern Ivona Gjeroska and the undergraduate interns Maddy Baron and Xie Jin Ng, in collaboration with Giampaolo D\u2019Alessandro (University of Southampton). The redesign aimed to be future-proof in the sense that materials created should be suitable for reuse in subsequent years, with iterated improvements, even when a return to fully on-campus teaching is possible.","title":"Execution"},{"location":"CaseStudies/2022/HonoursComplexVariables/#results","text":"A typical pattern of content from the resource is shown in following figure. We see a definition followed a short discussion and video clip of a worked example by the lecturer. Then we have a STACK question inviting the student to check their own understanding of the material. In addition, each unit of work started with a video of the lecturer giving a high-level overview and motivation of the material to come. Figure: Example of content of a typical quiz. Here are some examples of notable questions created for this course. Figure: A question asking to construct the harmonic conjugate of a function. The fully worked solution appears immediately after the students submit their answer. Figure: A Taylor series question. Figure: A question asking to classify singularities.The classification of each singularity appears as a drop-down list. Figure: A multipart STACK question on trigonometric integrals. In the future, such sessions could easily translate to on-campus activities using peer instruction, which had been an established practice in the School before the pandemic.","title":"Results"},{"location":"CaseStudies/2022/HonoursComplexVariables/#students-engagement","text":"Student feedback on the course was overwhelmingly positive, with one student responding to the end-of-course survey as follows. \u201cGenuinely this course has been the perfect mix of activities for my learning, I\u2019d go as far say to the best organised course I\u2019ve taken in SoM, certainly this year anyway. The notes being delivered in stack are great and much more engaging than a pdf (the supplementary pdf is much more easy to navigate for finding Theorems etc. however), which actually makes me do all the reading before lectures so I gain so much more from them. Stack is good in part because of the instant feedback on most exercises which are immediately relevant to what you\u2019re learning, but also because it breaks the material up well. Stack being the main resource works in perfectly with the 2 lectures delivered a week and the tutorial. SoM should considering delivering all courses in this fashion.\u201d The course organiser, Richard Gratwick, said: \u201cI believe the redesign of this course has been highly successful, and I like to consider the mode of delivery as a prototype for courses of the future. The motivation was to reflect on the innovations forced upon on us during the pandemic and attempt to implement in a considered way those that proved valuable. Recording short videos of examples and calculations allowed me to present these items \u201cdynamically\u201d, rather than as plain text, but freed up time in synchronous lectures for me to engage with more conceptual high-level discussion of the material. The Stack questions for self-assessment were largely based on exercises included in the previous version of the written notes, but students engaged with them much more regularly when they were presented in the online workbooks \u2013 my impression was that in previous years these written exercises were largely ignored.","title":"Students' engagement"},{"location":"CaseStudies/2022/HonoursComplexVariables/#challenges","text":"Redesigning a 3rd Year course, so that it contains a substantial amount of online components, was a challenging procedure. Authoring questions from scratch: a lot of the STACK questions had to be created completely from scratch because we didn't have any similar questions used in other courses. Deciding how to deliver each part of the course: it required careful though to decide which of the questions included in the lecture notes to have as exercise for students to solve or as a written example or as a worked example in a video. Some parts of the course can not be assessed automatically. After some consideration the lecturer decided to move some of the easy workshop questions into STACK and used the workshop time to address more complicated questions.","title":"Challenges"},{"location":"CaseStudies/2022/HonoursComplexVariables/#conclusions","text":"Online assessment it typically used for larger classes in early years of a university mathematics degree, such as calculus or linear algebra. These courses have a strong methods component. As the subject progresses, especially where there is a focus on mathematical proof, it is harder to write online questions which assess the key concepts. As a community we are gaining experience in using quizzes to structure learning materials (rather then traditional lectures), and in supporting more advanced courses. For example the University of Warwick used self-assessed online quizzes in real analysis that would supplement traditional problem sheets. In this course we have demonstrated that STACK can be successfully applied to a higher-level course to promote students' engagement with the content of the course. This is not as straightforward as in calculus and linear algebra, but nevertheless with careful design of materials it is possible to support students online with STACK in advanced courses such as complex analysis. Question Answering in STACK Applying String Similarity Developing a Fully Online Course","title":"Conclusions"},{"location":"CaseStudies/2022/StringSimilarity/","text":"Question Answering in STACK Applying String Similarity Hochschule Esslingen Achim. Eichhorn and Andreas Helfrich-Schkarbanenko Abstract We present a method to evaluate fill-in-the-blank student answers in STACK using a string metric. To increase the quality of the evaluation, we use two lists: allowlist and denylist instead of a single teacher's answer. We also show a STACK question equipped with a string metric, by evaluating its use in mathematics courses. String similarity The fill-in-the-blank questions are important from a didactic point of view. But they can be hardly implemented, since typing and spelling errors, synonyms and geuine alternatives have to be taken into account when evaluating the students' answers. To automatically mark fill-in-the-blank questions we used one of the string metrics for measuring the distance between two strings: the Damerau-Levenshtein distance [1, 2], which plays an important role in natural language processing. Informally, this distance is the minimum number of single-character edits (insertion, deletion, substitution, transition) required to change one string sequence into the other. Note that this distance is a metric in mathematical sense, in particular it satisfies the triangle inequality. This enables a suitable string evaluation. To increase the quality of the assessment, we extended the basic metric function by the adding the components: allowlist and denylist. To have a relative measure of the difference between two strings, we convert the distance to similarity . Applying the similarity on allowlist and denylist we define an acceptance domain for the students' answers. Here we need an empirically determined threshold parameter. Note that the presented method is, strictly speaking, not only based on the strings, but also on semantics, because by introducing the denylist and allowlist respectively, a (trivial) semantic graph consisting of two clusters is set up. For the sake of simplicity, the evaluation of a student's answer does not take place by means of a semantic distance, but using the string distance to the respective cluster as a whole (single linkage, minimum distance, nearest neighbour, see for example [3]). The Mathematics If the Damerau-Levenshtein distance between strings a and b is \\mathbf{d}(a,b) \\in [0,\\max\\{ |a|, |b| \\}] then the similarity is defined as \\mathbf{s}(a,b) := 1- \\frac{\\mathbf{d}(a,b)}{\\max\\{ |a|, |b| \\}} Given lists \\mbox{allowlist} = \\{ TA_1, TA_1, TA_1, \\cdots \\} \\mbox{denylist} = \\{ WA_1, WA_1, WA_1, \\cdots \\} then \\mathbf{s}(a,\\mbox{list}) := \\max_{k=1,\\cdots, K} \\mathbf{s}(a,b_k) We then have an acceptance domain in which \\left( \\mathbf{s}(a,\\mbox{allowlist}) > \\mathbf{s}(a,\\mbox{denylist}) \\right) \\wedge \\left( \\mathbf{s}(a,\\mbox{allowlist}) > \\theta \\right) for some chosen similarity tollerance \\theta . Here are some examples using the strings \"Circle\", \"Triangle\" and \"Rectangle\", together with their Damerau-Levenshtein distance / similarity. Figure: illustrating the Damerau-Levenshtein distance / similarity of example stings. Experiments We asked students for a suitable solution method by using a fill-in-the-blank question when given a differential equation, see subtask a). This task was used in the winter semester 2021/22 as part of a mini-test for the lecture Mathematics 2. It was completed by 53 students and all student answers were scored error-free. Figure: An example question with a string input. We implemented a string metric directly in the computer algebra system MAXIMA and placed the corresponding function in the Question Variables field of the STACK question concerned. The corresponding XML file can be downloaded from this link (June 2022). In the bottom figure we see 18 different student answers (in German) which are positioned in a coordinate system according to both similarities and are classified without errors. The radii of the disks represent the number of equal student answers. In total, this task was processed 263 times. The acceptance domain for correct answers is white-marked. Figure: Results of running the sample task. Note that for this STACK question and the given allowlist resp. denylist, only the consideration of the allowlist similarity would be sufficient for the evaluation. However, there are situations where the denylist is necessary. The authors would like to thank Stiftung Innovation in der Hochschullehre for supporting the project \"Digitalisierung Didaktisch Denken\". Implemention notes This feature has been added to STACK 4.0 in 2022 as an answer test. References [1] F. J. Damerau: A technique for computer detection and correction of spelling errors, Communications of the ACM, 7 (3): 171-176 (1964) [2] Vladimir I. Levenshtein: Binary codes capable of correcting deletions, insertions, and reversals, Soviet Physics Doklady, 10 (8): 707-710, (1966) [3] A. Eichhorn, A. Helfrich-Schkarbanenko: Question Answering in STACK Applying String Similarity. Private communication, (2022) Translating the HELM workbooks to STACK Use of STACK in Honours Complex Variables","title":"Question Answering in STACK Applying String Similarity"},{"location":"CaseStudies/2022/StringSimilarity/#question-answering-in-stack-applying-string-similarity","text":"","title":"Question Answering in STACK Applying String Similarity"},{"location":"CaseStudies/2022/StringSimilarity/#hochschule-esslingen","text":"Achim. Eichhorn and Andreas Helfrich-Schkarbanenko","title":"Hochschule Esslingen"},{"location":"CaseStudies/2022/StringSimilarity/#abstract","text":"We present a method to evaluate fill-in-the-blank student answers in STACK using a string metric. To increase the quality of the evaluation, we use two lists: allowlist and denylist instead of a single teacher's answer. We also show a STACK question equipped with a string metric, by evaluating its use in mathematics courses.","title":"Abstract"},{"location":"CaseStudies/2022/StringSimilarity/#string-similarity","text":"The fill-in-the-blank questions are important from a didactic point of view. But they can be hardly implemented, since typing and spelling errors, synonyms and geuine alternatives have to be taken into account when evaluating the students' answers. To automatically mark fill-in-the-blank questions we used one of the string metrics for measuring the distance between two strings: the Damerau-Levenshtein distance [1, 2], which plays an important role in natural language processing. Informally, this distance is the minimum number of single-character edits (insertion, deletion, substitution, transition) required to change one string sequence into the other. Note that this distance is a metric in mathematical sense, in particular it satisfies the triangle inequality. This enables a suitable string evaluation. To increase the quality of the assessment, we extended the basic metric function by the adding the components: allowlist and denylist. To have a relative measure of the difference between two strings, we convert the distance to similarity . Applying the similarity on allowlist and denylist we define an acceptance domain for the students' answers. Here we need an empirically determined threshold parameter. Note that the presented method is, strictly speaking, not only based on the strings, but also on semantics, because by introducing the denylist and allowlist respectively, a (trivial) semantic graph consisting of two clusters is set up. For the sake of simplicity, the evaluation of a student's answer does not take place by means of a semantic distance, but using the string distance to the respective cluster as a whole (single linkage, minimum distance, nearest neighbour, see for example [3]).","title":"String similarity"},{"location":"CaseStudies/2022/StringSimilarity/#the-mathematics","text":"If the Damerau-Levenshtein distance between strings a and b is \\mathbf{d}(a,b) \\in [0,\\max\\{ |a|, |b| \\}] then the similarity is defined as \\mathbf{s}(a,b) := 1- \\frac{\\mathbf{d}(a,b)}{\\max\\{ |a|, |b| \\}} Given lists \\mbox{allowlist} = \\{ TA_1, TA_1, TA_1, \\cdots \\} \\mbox{denylist} = \\{ WA_1, WA_1, WA_1, \\cdots \\} then \\mathbf{s}(a,\\mbox{list}) := \\max_{k=1,\\cdots, K} \\mathbf{s}(a,b_k) We then have an acceptance domain in which \\left( \\mathbf{s}(a,\\mbox{allowlist}) > \\mathbf{s}(a,\\mbox{denylist}) \\right) \\wedge \\left( \\mathbf{s}(a,\\mbox{allowlist}) > \\theta \\right) for some chosen similarity tollerance \\theta . Here are some examples using the strings \"Circle\", \"Triangle\" and \"Rectangle\", together with their Damerau-Levenshtein distance / similarity. Figure: illustrating the Damerau-Levenshtein distance / similarity of example stings.","title":"The Mathematics"},{"location":"CaseStudies/2022/StringSimilarity/#experiments","text":"We asked students for a suitable solution method by using a fill-in-the-blank question when given a differential equation, see subtask a). This task was used in the winter semester 2021/22 as part of a mini-test for the lecture Mathematics 2. It was completed by 53 students and all student answers were scored error-free. Figure: An example question with a string input. We implemented a string metric directly in the computer algebra system MAXIMA and placed the corresponding function in the Question Variables field of the STACK question concerned. The corresponding XML file can be downloaded from this link (June 2022). In the bottom figure we see 18 different student answers (in German) which are positioned in a coordinate system according to both similarities and are classified without errors. The radii of the disks represent the number of equal student answers. In total, this task was processed 263 times. The acceptance domain for correct answers is white-marked. Figure: Results of running the sample task. Note that for this STACK question and the given allowlist resp. denylist, only the consideration of the allowlist similarity would be sufficient for the evaluation. However, there are situations where the denylist is necessary. The authors would like to thank Stiftung Innovation in der Hochschullehre for supporting the project \"Digitalisierung Didaktisch Denken\".","title":"Experiments"},{"location":"CaseStudies/2022/StringSimilarity/#implemention-notes","text":"This feature has been added to STACK 4.0 in 2022 as an answer test.","title":"Implemention notes"},{"location":"CaseStudies/2022/StringSimilarity/#references","text":"[1] F. J. Damerau: A technique for computer detection and correction of spelling errors, Communications of the ACM, 7 (3): 171-176 (1964) [2] Vladimir I. Levenshtein: Binary codes capable of correcting deletions, insertions, and reversals, Soviet Physics Doklady, 10 (8): 707-710, (1966) [3] A. Eichhorn, A. Helfrich-Schkarbanenko: Question Answering in STACK Applying String Similarity. Private communication, (2022) Translating the HELM workbooks to STACK Use of STACK in Honours Complex Variables","title":"References"},{"location":"Events/2022-11-16-BookQuiz/","text":"Using STACK to put the \"book inside the quiz\" This event is associated with the Eurasmus+ IDIAM project. We have been using, and evaluating, an organising principle for online learning materials which is increasingly guiding our thinking in the development of university mathematics courses. Essentially we have taken the book and put it inside automatically assessed online quizzes. In doing this, we embrace the potential provided by new technology to implement evidence-based practices such as spaced retrieval practice. This workshop discusses details of this innovation, and demonstrates examples of courses in which we have implemented it. When: Wednesday 16th November 2022. Where: The University of Edinburgh, James Clerk Maxwell building (for in-person attendees) and online. 9:30 am - 12:30 pm, JCMB - Room 5323 13.00 pm - 17.00pm, JCMB - Room 5326 Program 9:30-10:00 Opening 10:00-11:00 Designing materials with STACK & \"putting the book inside the quiz\", George Kinnear 11:00-11:15 Coffee break 11:15-12:15 Discussion of case studies of use: HELM project, Konstantina Zerva Introductory Mathematics and its Applications, Robert Bickerton Complex analysis (Honours Complex Variables), Richard Gratwick 12:15-13:15 Lunch 13:00-15:00 STACK authoring workshops: - Getting your first question working (no STACK experience required). - Testing and maintaining STACK questions. Sign up You are welcome to attend the event in person. To register please email Konstantina Zerva . Lunch will be provided for every participant attending in-person. Please specify any special dietry requirements you have. Demonstration materials associated with this event will be online here: https://stack-demo.maths.ed.ac.uk/demo/course/view.php?id=176 Links to the recordings Morning talks: https://ed-ac-uk.zoom.us/rec/share/7qRa6xCbEAZr4iFKMD_fBEgp-7LfaGQPxGYNbmY8F53aa3r2TMen4bAvHWPqq8ch._16wt4GzJNRH0hx7 Afternoon workshop: https://ed-ac-uk.zoom.us/rec/share/8endrAjD4C95N3pW-tmN5ZySNI19zvfrreE-Nk2aSazIToC-1IeR59RsFayOHGH6.LtKOedIaaORNUe-D?startTime=1668605212000","title":"Using STACK to put the \"book inside the quiz\""},{"location":"Events/2022-11-16-BookQuiz/#using-stack-to-put-the-book-inside-the-quiz","text":"This event is associated with the Eurasmus+ IDIAM project. We have been using, and evaluating, an organising principle for online learning materials which is increasingly guiding our thinking in the development of university mathematics courses. Essentially we have taken the book and put it inside automatically assessed online quizzes. In doing this, we embrace the potential provided by new technology to implement evidence-based practices such as spaced retrieval practice. This workshop discusses details of this innovation, and demonstrates examples of courses in which we have implemented it. When: Wednesday 16th November 2022. Where: The University of Edinburgh, James Clerk Maxwell building (for in-person attendees) and online. 9:30 am - 12:30 pm, JCMB - Room 5323 13.00 pm - 17.00pm, JCMB - Room 5326","title":"Using STACK to put the \"book inside the quiz\""},{"location":"Events/2022-11-16-BookQuiz/#program","text":"9:30-10:00 Opening 10:00-11:00 Designing materials with STACK & \"putting the book inside the quiz\", George Kinnear 11:00-11:15 Coffee break 11:15-12:15 Discussion of case studies of use: HELM project, Konstantina Zerva Introductory Mathematics and its Applications, Robert Bickerton Complex analysis (Honours Complex Variables), Richard Gratwick 12:15-13:15 Lunch 13:00-15:00 STACK authoring workshops: - Getting your first question working (no STACK experience required). - Testing and maintaining STACK questions.","title":"Program"},{"location":"Events/2022-11-16-BookQuiz/#sign-up","text":"You are welcome to attend the event in person. To register please email Konstantina Zerva . Lunch will be provided for every participant attending in-person. Please specify any special dietry requirements you have. Demonstration materials associated with this event will be online here: https://stack-demo.maths.ed.ac.uk/demo/course/view.php?id=176","title":"Sign up"},{"location":"Events/2022-11-16-BookQuiz/#links-to-the-recordings","text":"Morning talks: https://ed-ac-uk.zoom.us/rec/share/7qRa6xCbEAZr4iFKMD_fBEgp-7LfaGQPxGYNbmY8F53aa3r2TMen4bAvHWPqq8ch._16wt4GzJNRH0hx7 Afternoon workshop: https://ed-ac-uk.zoom.us/rec/share/8endrAjD4C95N3pW-tmN5ZySNI19zvfrreE-Nk2aSazIToC-1IeR59RsFayOHGH6.LtKOedIaaORNUe-D?startTime=1668605212000","title":"Links to the recordings"},{"location":"Events/2022-12-08-JSXgraphSTACK/","text":"Using JSX graphs in STACK This event is associated with the Eurasmus+ IDIAM project. JSXGraph is a cross-browser library for displaying interactive geometry, function plotting, graphs, and data visualization in a web browser https://jsxgraph.org/wp/index.html . Mathematical and physical phenomena can be better understood and explored via visualization. This workshop will provide hands-on practise on how to create JSXGraphs, which you can embend in your educational resources (e.g. in markdown editor) and how to use JSXGraph in STACK assessments. When: Thursday 8th December 2022. Where: The University of Edinburgh, James Clerk Maxwell building, Room 5323 (for in-person attendees) and online. Times below are GMT. Zoom link for online participation: Join Zoom Meeting https://ed-ac-uk.zoom.us/j/86838815060 Meeting ID: 868 3881 5060 Passcode: iWRxP3Lk Program 9:30-10:00 Pre-meeting coffee 10:00-10:10 Opening 10:10-11:00 Presentation: Math visualization with JSXGraph - an overview, Alfred Wassermann 11:00-11:20 Coffee break 11:20-13:00 Programming Workshop: \"Create your first JSXgraph\", Alfred Wassermann 13:00-14:00 Lunch 14:00-14:40 Presentation: Using JSXgraph in STACK questions, Jonas Alexander Lache 14:40-15:00 Coffee break 15:00-16:30 Workshop: How to use JSXGraph in STACK, Wigand Rathmann and Jonas Julius Harang The workshop will cover: - Create a graph which follows the randomisation. - Create a graph with binding of variables (the graph is part of the answer). Sign up You are welcome to attend the event in person. To register please email Konstantina Zerva . Lunch will be provided for every participant attending in-person. Please specify any special dietry requirements you have. Demonstration materials associated with this event will be online here: https://stack-demo.maths.ed.ac.uk/demo/course/view.php?id=176 Links to the recordings Morning session: https://ed-ac-uk.zoom.us/rec/share/LCcw1po5f7gpRk1qkm0cLX4m8R0QLL5olBWsGW75FavnnF5Yx_DZhyNLV-BnUtus.7Q6FsDBSWC0PzLOZ?startTime=1670493588000 Afternoon session: https://ed-ac-uk.zoom.us/rec/share/LCcw1po5f7gpRk1qkm0cLX4m8R0QLL5olBWsGW75FavnnF5Yx_DZhyNLV-BnUtus.7Q6FsDBSWC0PzLOZ?startTime=1670508198000","title":"Using JSX graphs in STACK"},{"location":"Events/2022-12-08-JSXgraphSTACK/#using-jsx-graphs-in-stack","text":"This event is associated with the Eurasmus+ IDIAM project. JSXGraph is a cross-browser library for displaying interactive geometry, function plotting, graphs, and data visualization in a web browser https://jsxgraph.org/wp/index.html . Mathematical and physical phenomena can be better understood and explored via visualization. This workshop will provide hands-on practise on how to create JSXGraphs, which you can embend in your educational resources (e.g. in markdown editor) and how to use JSXGraph in STACK assessments. When: Thursday 8th December 2022. Where: The University of Edinburgh, James Clerk Maxwell building, Room 5323 (for in-person attendees) and online. Times below are GMT. Zoom link for online participation: Join Zoom Meeting https://ed-ac-uk.zoom.us/j/86838815060 Meeting ID: 868 3881 5060 Passcode: iWRxP3Lk","title":"Using JSX graphs in STACK"},{"location":"Events/2022-12-08-JSXgraphSTACK/#program","text":"9:30-10:00 Pre-meeting coffee 10:00-10:10 Opening 10:10-11:00 Presentation: Math visualization with JSXGraph - an overview, Alfred Wassermann 11:00-11:20 Coffee break 11:20-13:00 Programming Workshop: \"Create your first JSXgraph\", Alfred Wassermann 13:00-14:00 Lunch 14:00-14:40 Presentation: Using JSXgraph in STACK questions, Jonas Alexander Lache 14:40-15:00 Coffee break 15:00-16:30 Workshop: How to use JSXGraph in STACK, Wigand Rathmann and Jonas Julius Harang The workshop will cover: - Create a graph which follows the randomisation. - Create a graph with binding of variables (the graph is part of the answer).","title":"Program"},{"location":"Events/2022-12-08-JSXgraphSTACK/#sign-up","text":"You are welcome to attend the event in person. To register please email Konstantina Zerva . Lunch will be provided for every participant attending in-person. Please specify any special dietry requirements you have. Demonstration materials associated with this event will be online here: https://stack-demo.maths.ed.ac.uk/demo/course/view.php?id=176","title":"Sign up"},{"location":"Events/2022-12-08-JSXgraphSTACK/#links-to-the-recordings","text":"Morning session: https://ed-ac-uk.zoom.us/rec/share/LCcw1po5f7gpRk1qkm0cLX4m8R0QLL5olBWsGW75FavnnF5Yx_DZhyNLV-BnUtus.7Q6FsDBSWC0PzLOZ?startTime=1670493588000 Afternoon session: https://ed-ac-uk.zoom.us/rec/share/LCcw1po5f7gpRk1qkm0cLX4m8R0QLL5olBWsGW75FavnnF5Yx_DZhyNLV-BnUtus.7Q6FsDBSWC0PzLOZ?startTime=1670508198000","title":"Links to the recordings"},{"location":"Events/2023-04-AdvancedSTACK/","text":"Using STACK in more advanced courses This event is associated with the Eurasmus+ IDIAM project. When: April 2023 - TBC. Where: The University of Edinburgh, James Clerk Maxwell building.","title":"Using STACK in more advanced courses"},{"location":"Events/2023-04-AdvancedSTACK/#using-stack-in-more-advanced-courses","text":"This event is associated with the Eurasmus+ IDIAM project. When: April 2023 - TBC. Where: The University of Edinburgh, James Clerk Maxwell building.","title":"Using STACK in more advanced courses"},{"location":"Events/2023-06-19-AfricanSTACKConference/","text":"African STACK Conference for Undergraduate Mathematics The first African STACK Conference for Undergraduate Mathematics will take place at Masinde Muliro University of Science and Technology (MMUST) from 19 to 23 June 2023. The conference aims to enable African educators with experience on STACK to define a roadmap for transformation of African maths education. Since 2019, African universities started incorporating STACK assessments to their undergraduate courses, particularly to deal with issues of large class sizes (some classes are over 1,200 students) with a single lecturer and no additional human resources. A concerted effort was started by groups of universities, with the support of IDEMS International , to promote STACK in the region through open resources and question banks, which are slowly spreading throughout the continent, with the objective of full curriculum coverage. The conference will provide a platform for lecturers to present their experiences incorporating STACK to undergraduate courses, their methodologies and impact found. Key stakeholders will have an opportunity to extend their collaboration and accelerate the integration of STACK. The conference will include a 2-day STACK workshop, 2 days of paper and poster presentations, and a final day roundtable discussion with key stakeholders or an additional workshop. Registration is now open Please fill in the registration form below to attend the conference. We will write to you shortly after receiving your application with payment details. Limited funding may be available for partial or full waivers and financial support for additional expenses. Due to limited funding this will only be possible in exceptional circumstances and places at the conference are not guaranteed if support is requested. Decisions will be made on a case-by-case basis. If you require financial support to attend the conference, please submit your registration form no later than 8th May 2023. Fees For Kenyan participants: KES15,000 (a KES5,000 discount is available for Kenya Mathematical Society members) For other African participants: USD150 For other international participants: USD300 Register Now Submit an abstract The conference will include a combination of 30-minutes Paper Presentations and 15-minutes Poster Presentations. Please submit an abstract (maximum 4000 characters) in the form below. Deadline for submissions is 13th March 2023. Submit an Abstract Keynote Speakers Prof Chris Sangwin, The University of Edinburgh, Chairperson of the STACK International Advisory Board Prof George Lawi, Masinde Muliro University for Science and Technology Dr David Stern, IDEMS International, member of the STACK International Advisory Board Dr Michael Obiero Oyengo, Maseno University, Kenya, member of the STACK International Advisory Board and vice-chair of the Kenya Mathematical Society Dr James Kaleli Musyoka, Maseno University, Kenya, vice-president of the International Association for Statistics Education Confirmed Invited Speakers Dr Idrissa Said Amour, University of Dar es Salaam, Tanzania Dr Abdu Mohammed Seid, Bahir Dar University, Ethiopia Dr Georg Osang, IDEMS International Mr Santiago Borio, IDEMS International Dr Jared Ongaro, University of Nairobi, Kenya Dr Mary Ochieng, Strathmore University, Kenya Dr Donnie Kasyoki Munyao, Maseno University, Kenya Mr Juma Zevick, IDEMS International Mr Wastalas Montognon, IDEMS International Dr Danilo Lewanski, University of Trieste, Italy, Universit\u00e9 de Gen\u00e8ve, Switzerland, SAMI Organising Committee Prof George Lawi (MMUST) Dr Achiles Nyongesa (MMUST) Dr Everlyne Odero (MMUST) Dr Frankline Tireito (MMUST) Mr Santiago Borio (IDEMS International) Dr Michael Obiero (Maseno University) Ms Christine Laetitia (INNODEMS) Mr Juma Zevick (IDEMS International) Dr Danilo Lewanski (University of Trieste, Universit\u00e9 de Gen\u00e8ve, SAMI) Supported by MMUST Maseno University Kenya Mathematical Society IDEMS International INNODEMS SAMI Swiss National Science Foundation Universit\u00e9 de Gen\u00e8ve","title":"African STACK Conference for Undergraduate Mathematics"},{"location":"Events/2023-06-19-AfricanSTACKConference/#african-stack-conference-for-undergraduate-mathematics","text":"The first African STACK Conference for Undergraduate Mathematics will take place at Masinde Muliro University of Science and Technology (MMUST) from 19 to 23 June 2023. The conference aims to enable African educators with experience on STACK to define a roadmap for transformation of African maths education. Since 2019, African universities started incorporating STACK assessments to their undergraduate courses, particularly to deal with issues of large class sizes (some classes are over 1,200 students) with a single lecturer and no additional human resources. A concerted effort was started by groups of universities, with the support of IDEMS International , to promote STACK in the region through open resources and question banks, which are slowly spreading throughout the continent, with the objective of full curriculum coverage. The conference will provide a platform for lecturers to present their experiences incorporating STACK to undergraduate courses, their methodologies and impact found. Key stakeholders will have an opportunity to extend their collaboration and accelerate the integration of STACK. The conference will include a 2-day STACK workshop, 2 days of paper and poster presentations, and a final day roundtable discussion with key stakeholders or an additional workshop.","title":"African STACK Conference for Undergraduate Mathematics"},{"location":"Events/2023-06-19-AfricanSTACKConference/#registration-is-now-open","text":"Please fill in the registration form below to attend the conference. We will write to you shortly after receiving your application with payment details. Limited funding may be available for partial or full waivers and financial support for additional expenses. Due to limited funding this will only be possible in exceptional circumstances and places at the conference are not guaranteed if support is requested. Decisions will be made on a case-by-case basis. If you require financial support to attend the conference, please submit your registration form no later than 8th May 2023.","title":"Registration is now open"},{"location":"Events/2023-06-19-AfricanSTACKConference/#fees","text":"For Kenyan participants: KES15,000 (a KES5,000 discount is available for Kenya Mathematical Society members) For other African participants: USD150 For other international participants: USD300 Register Now","title":"Fees"},{"location":"Events/2023-06-19-AfricanSTACKConference/#submit-an-abstract","text":"The conference will include a combination of 30-minutes Paper Presentations and 15-minutes Poster Presentations. Please submit an abstract (maximum 4000 characters) in the form below. Deadline for submissions is 13th March 2023. Submit an Abstract","title":"Submit an abstract"},{"location":"Events/2023-06-19-AfricanSTACKConference/#keynote-speakers","text":"Prof Chris Sangwin, The University of Edinburgh, Chairperson of the STACK International Advisory Board Prof George Lawi, Masinde Muliro University for Science and Technology Dr David Stern, IDEMS International, member of the STACK International Advisory Board Dr Michael Obiero Oyengo, Maseno University, Kenya, member of the STACK International Advisory Board and vice-chair of the Kenya Mathematical Society Dr James Kaleli Musyoka, Maseno University, Kenya, vice-president of the International Association for Statistics Education","title":"Keynote Speakers"},{"location":"Events/2023-06-19-AfricanSTACKConference/#confirmed-invited-speakers","text":"Dr Idrissa Said Amour, University of Dar es Salaam, Tanzania Dr Abdu Mohammed Seid, Bahir Dar University, Ethiopia Dr Georg Osang, IDEMS International Mr Santiago Borio, IDEMS International Dr Jared Ongaro, University of Nairobi, Kenya Dr Mary Ochieng, Strathmore University, Kenya Dr Donnie Kasyoki Munyao, Maseno University, Kenya Mr Juma Zevick, IDEMS International Mr Wastalas Montognon, IDEMS International Dr Danilo Lewanski, University of Trieste, Italy, Universit\u00e9 de Gen\u00e8ve, Switzerland, SAMI","title":"Confirmed Invited Speakers"},{"location":"Events/2023-06-19-AfricanSTACKConference/#organising-committee","text":"Prof George Lawi (MMUST) Dr Achiles Nyongesa (MMUST) Dr Everlyne Odero (MMUST) Dr Frankline Tireito (MMUST) Mr Santiago Borio (IDEMS International) Dr Michael Obiero (Maseno University) Ms Christine Laetitia (INNODEMS) Mr Juma Zevick (IDEMS International) Dr Danilo Lewanski (University of Trieste, Universit\u00e9 de Gen\u00e8ve, SAMI)","title":"Organising Committee"},{"location":"Events/2023-06-19-AfricanSTACKConference/#supported-by","text":"","title":"Supported by"},{"location":"Legal/Accessibility/","text":"Accessibility We believe online assessment should be available and accessible to all. We strive to comply with the Web Content Accessibility Guidelines (WCAG) 2.1 on www.stack-assessment.org (\"the website\") at most of level AA requirements. This statement covers the STACK website, and does not cover the STACK interface for teachers and students. Steps taken The main website www.stack-assessment.org , functions at 200% zoom, is responsive and usable on most common browsers and resolutions; browsers tested on: Chrome, Firefox, Safari, Edge, resolutions tested on: common resolutions for laptop, tablet and mobile, ensures all non-text elements have alternative text, never uses colour as the sole means of conveying information, Known issues The website is not compatible with Internet Explorer 11. The website has not yet been tested with applications that increase/decrease text size only. The website has not yet been tested with screen readers. The navigation bar cannot be navigated with only keyboard beyond two levels. The user map on /CaseStudies/Overview is not navigable by keyboard. Some elements have a colour contrast ratio of less than 4:5:1, in particular the navigation bar. The documentation website \"docs.stack-assessment.org\" has not yet been tested for accessibility. For comments or suggestions regarding to accessibility, please email Chris Sangwin at C.J.Sangwin@ed.ac.uk","title":"Accessibility"},{"location":"Legal/Accessibility/#accessibility","text":"We believe online assessment should be available and accessible to all. We strive to comply with the Web Content Accessibility Guidelines (WCAG) 2.1 on www.stack-assessment.org (\"the website\") at most of level AA requirements. This statement covers the STACK website, and does not cover the STACK interface for teachers and students.","title":"Accessibility"},{"location":"Legal/Accessibility/#steps-taken","text":"The main website www.stack-assessment.org , functions at 200% zoom, is responsive and usable on most common browsers and resolutions; browsers tested on: Chrome, Firefox, Safari, Edge, resolutions tested on: common resolutions for laptop, tablet and mobile, ensures all non-text elements have alternative text, never uses colour as the sole means of conveying information,","title":"Steps taken"},{"location":"Legal/Accessibility/#known-issues","text":"The website is not compatible with Internet Explorer 11. The website has not yet been tested with applications that increase/decrease text size only. The website has not yet been tested with screen readers. The navigation bar cannot be navigated with only keyboard beyond two levels. The user map on /CaseStudies/Overview is not navigable by keyboard. Some elements have a colour contrast ratio of less than 4:5:1, in particular the navigation bar. The documentation website \"docs.stack-assessment.org\" has not yet been tested for accessibility. For comments or suggestions regarding to accessibility, please email Chris Sangwin at C.J.Sangwin@ed.ac.uk","title":"Known issues"},{"location":"Legal/Licenses/","text":"Licenses The contents of stack-assessment.org and docs.stack-assessment.org is Licensed under the Creative Commons Attribution-ShareAlike 4.0 International License . The following are related licenses for STACK, stack-assessment.org and docs.stack-assessment.org (\"the website\"). STACK STACK is licensed under the GNU General Public License Version 3. The STACK documentation, contained in the subdirectories of doc/ and on docs.stack-assessment.org, is Licensed under the Creative Commons Attribution-ShareAlike 4.0 International License . GitHub Pages The website is hosted on GitHub pages . Please see the GitHub terms of service . MkDocs The website is built with MkDocs , licensed under a BSD license. mdx_math The website uses the mdx_math markdown compiler . python-markdown-math license. Bootstrap stack-assessment.org uses Bootstrap , licensed under a MIT License. Bootstrap MkDocs Theme Bootstrap is integrated into MkDocs using the mkdocs-bootstrap theme, licensed under a BSD 2-Clause \"Simplified\" License. Material Theme docs.stack-assessment.org uses the Material theme, licensed under a MIT License.","title":"Licenses"},{"location":"Legal/Licenses/#licenses","text":"The contents of stack-assessment.org and docs.stack-assessment.org is Licensed under the Creative Commons Attribution-ShareAlike 4.0 International License . The following are related licenses for STACK, stack-assessment.org and docs.stack-assessment.org (\"the website\").","title":"Licenses"},{"location":"Legal/Licenses/#stack","text":"STACK is licensed under the GNU General Public License Version 3. The STACK documentation, contained in the subdirectories of doc/ and on docs.stack-assessment.org, is Licensed under the Creative Commons Attribution-ShareAlike 4.0 International License .","title":"STACK"},{"location":"Legal/Licenses/#github-pages","text":"The website is hosted on GitHub pages . Please see the GitHub terms of service .","title":"GitHub Pages"},{"location":"Legal/Licenses/#mkdocs","text":"The website is built with MkDocs , licensed under a BSD license.","title":"MkDocs"},{"location":"Legal/Licenses/#mdx_math","text":"The website uses the mdx_math markdown compiler . python-markdown-math license.","title":"mdx_math"},{"location":"Legal/Licenses/#bootstrap","text":"stack-assessment.org uses Bootstrap , licensed under a MIT License.","title":"Bootstrap"},{"location":"Legal/Licenses/#bootstrap-mkdocs-theme","text":"Bootstrap is integrated into MkDocs using the mkdocs-bootstrap theme, licensed under a BSD 2-Clause \"Simplified\" License.","title":"Bootstrap MkDocs Theme"},{"location":"Legal/Licenses/#material-theme","text":"docs.stack-assessment.org uses the Material theme, licensed under a MIT License.","title":"Material Theme"},{"location":"Legal/PrivacyStatement/","text":"Privacy Statement This statement was last revised on 13/5/2022. How we collect your data This website is hosted on GitHub Pages. GitHub may collect User Personal Information from visitors to this website, including logs of visitor IP addresses, to comply with legal obligations, and to maintain the security and integrity of the Website and the Service. Please see GitHub's privacy statement for information on how your data is used and stored by GitHub. We do not otherwise collect any personal information about you when you visit this website. Privacy policies of other websites This statement refers only to this website (www.stack-assessment.org), and not to any other STACK websites, or any third party sites linked to on this website. You are encouraged to review privacy statements on other websites when you visit them. Changes to our privacy policy The date of the latest revision is shown at the top of the page. We may change this privacy statement at any time and for any reason. You are encouraged to regularly review this statement. How to contact us If you have questions about our privacy policy, please email Professor Chris Sangwin at C.J.Sangwin@ed.ac.uk .","title":"Privacy Statement"},{"location":"Legal/PrivacyStatement/#privacy-statement","text":"This statement was last revised on 13/5/2022.","title":"Privacy Statement"},{"location":"Legal/PrivacyStatement/#how-we-collect-your-data","text":"This website is hosted on GitHub Pages. GitHub may collect User Personal Information from visitors to this website, including logs of visitor IP addresses, to comply with legal obligations, and to maintain the security and integrity of the Website and the Service. Please see GitHub's privacy statement for information on how your data is used and stored by GitHub. We do not otherwise collect any personal information about you when you visit this website.","title":"How we collect your data"},{"location":"Legal/PrivacyStatement/#privacy-policies-of-other-websites","text":"This statement refers only to this website (www.stack-assessment.org), and not to any other STACK websites, or any third party sites linked to on this website. You are encouraged to review privacy statements on other websites when you visit them.","title":"Privacy policies of other websites"},{"location":"Legal/PrivacyStatement/#changes-to-our-privacy-policy","text":"The date of the latest revision is shown at the top of the page. We may change this privacy statement at any time and for any reason. You are encouraged to regularly review this statement.","title":"Changes to our privacy policy"},{"location":"Legal/PrivacyStatement/#how-to-contact-us","text":"If you have questions about our privacy policy, please email Professor Chris Sangwin at C.J.Sangwin@ed.ac.uk .","title":"How to contact us"}]}